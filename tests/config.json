{
    "models": [
      {
        "model_name": "gpt2",
        "model_class": "GPT2LMHeadModel",
        "n_head": 12,
        "n_embd": 768,
        "n_layer": 12
      },
      {
        "model_name": "Salesforce/codegen-350M-mono",
        "model_class": "CodeGenForCausalLM",
        "n_head": 16,
        "n_embd": 1024,
        "n_layer": 20
      },
      {
        "model_name": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
        "model_class": "LlamaForCausalLM",
        "num_key_value_heads": 4,
        "num_attention_heads": 32,
        "hidden_size": 2048,
        "n_layer": 22
      },
      {
        "model_name": "Felladrin/Minueza-32M-Base",
        "model_class": "MistralForCausalLM",
        "num_key_value_heads": 4,
        "num_attention_heads": 12,
        "hidden_size": 312,
        "n_layer": 10
      },
      {
        "model_name": "wtang06/mpt-125m-c4",
        "model_class": "MPTForCausalLM",
        "n_heads": 8,
        "d_model": 768,
        "n_layer": 12
      }
    ]
  }
  
# -----------------------------------------------------------------------------
#
# Copyright (c) Qualcomm Technologies, Inc. and/or its subsidiaries.
# SPDX-License-Identifier: BSD-3-Clause
#
# -----------------------------------------------------------------------------

"""Reference data for the finetune tests from SDK version - 1.21.0.23"""

# A dictionary to hold all reference data for all test sets.
REFERENCE_DATA = {
    # Scenario 1: Single-device llama 3.2-1B training on Alpaca dataset.
    "llama_3.2_1B_config_alpaca_single_device": {
        "description": "Baseline for Llama on Alpaca single-device",
        "train_step_losses": [
            1.5110896825790405,
            1.2206485271453857,
            1.9950776100158691,
            2.091615676879883,
            0.9182446599006653,
            1.1993569135665894,
            0.36413607001304626,
            1.6241482496261597,
            0.8270177245140076,
            0.7749958634376526,
            1.73696768283844,
            2.120077610015869,
            2.061460256576538,
            0.8267984390258789,
            0.8105809688568115,
            1.7627557516098022,
            1.6819559335708618,
            1.3528242111206055,
            2.0654125213623047,
            3.156151294708252,
        ],
        "eval_step_losses": [
            1.4607517719268799,
            0.24302150309085846,
            1.0471211671829224,
            1.642044186592102,
            1.3949533700942993,
            2.8850066661834717,
            1.0366586446762085,
            1.8661959171295166,
            3.81632924079895,
            0.6577113270759583,
        ],
        "train_step_metrics": [
            4.531666278839111,
            3.389385223388672,
            7.352773189544678,
            8.09798812866211,
            2.504889488220215,
            3.3179824352264404,
            1.43927001953125,
            5.074095249176025,
            2.286489486694336,
            2.1705832481384277,
            5.680093288421631,
            8.33178424835205,
            7.857433319091797,
            2.2859883308410645,
            2.2492144107818604,
            5.828476905822754,
            5.376060962677002,
            3.8683345317840576,
            7.8885498046875,
            23.480052947998047,
        ],
        "eval_step_metrics": [  # steps 0-9
            4.309197902679443,
            1.27509605884552,
            2.8494362831115723,
            5.1657185554504395,
            4.034786224365234,
            17.9036865234375,
            2.819779396057129,
            6.463661193847656,
            45.437110900878906,
            1.9303690195083618,
        ],
    },
    # Scenario 2: Single-device llama 3.2-1B training on GSM8k dataset.
    "llama_3.2_1B_config_gsm8k_single_device": {
        "description": "Baseline for Llama on GSM8k single-device",
        "train_step_losses": [
            2.250361204147339,
            2.3252110481262207,
            1.9360781908035278,
            1.5984115600585938,
            1.9874038696289062,
            1.4579044580459595,
            1.8975679874420166,
            1.2175723314285278,
            1.6473736763000488,
            1.537960410118103,
            1.4019465446472168,
            1.5310447216033936,
            1.6878201961517334,
            1.3849903345108032,
            1.7976438999176025,
            1.4060133695602417,
            1.646375060081482,
            1.2835280895233154,
            0.8465587496757507,
            1.5783095359802246,
        ],
        "eval_step_losses": [
            1.707140326499939,
            1.7226355075836182,
            1.1531383991241455,
            2.0035903453826904,
            1.3362350463867188,
            1.3013248443603516,
            1.2195535898208618,
            1.3454742431640625,
            1.3299248218536377,
            1.3073854446411133,
        ],
        "train_step_metrics": [
            9.49116325378418,
            10.228837966918945,
            6.93151330947876,
            4.945170879364014,
            7.296566009521484,
            4.296945571899414,
            6.66965389251709,
            3.378974676132202,
            5.193322658538818,
            4.655086040496826,
            4.063101291656494,
            4.623003959655762,
            5.407680034637451,
            3.994786262512207,
            6.0354108810424805,
            4.0796589851379395,
            5.188138961791992,
            3.60935115814209,
            2.3316092491149902,
            4.846755504608154,
        ],
        "eval_step_metrics": [  # steps 0-9
            5.5131731033325195,
            5.599266052246094,
            3.1681201457977295,
            7.415632247924805,
            3.8046915531158447,
            3.674160957336426,
            3.3856759071350098,
            3.8400065898895264,
            3.7807586193084717,
            3.69649600982666,
        ],
    },
    # Scenario 3: Single-device google-bert/bert-base-uncased training on IMDB dataset.
    "bert_base_uncased_config_imdb_single_device": {
        "description": "Baseline for google-bert/bert-base-uncased on IMDB single-device",
        "train_step_losses": [
            0.390625,
            0.51220703125,
            0.9208984375,
            0.4052734375,
            1.1640625,
            0.6533203125,
            0.5087890625,
            0.76171875,
            0.63525390625,
            0.50146484375,
            0.5439453125,
            0.947265625,
            0.89013671875,
            0.80419921875,
            0.6533203125,
            0.4580078125,
            0.92041015625,
            0.7412109375,
            0.7197265625,
            0.62158203125,
        ],
        "eval_step_losses": [
            0.6044921875,
            0.798828125,
            0.9072265625,
            0.70361328125,
            0.59912109375,
            0.66357421875,
            0.6962890625,
            0.75390625,
            0.61328125,
            0.6806640625,
        ],
        "train_step_metrics": [
            1.0,
            1.0,
            0.5,
            0.49999988079071045,
            0.49999988079071045,
            0.5,
            0.5000002384185791,
            0.5000002384185791,
            0.6250002384185791,
            0.6249998807907104,
            0.625,
            0.6000000238418579,
            0.5833332538604736,
            0.5714285373687744,
            0.5714285373687744,
            0.5714285373687744,
            0.5625,
            0.555555522441864,
            0.5055557489395142,
            0.5101010203361511,
        ],
        "eval_step_metrics": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0],
    },
    # Scenario 4: Distributed google-bert/bert-base-uncased training  (world_size=2)
    "bert_base_uncased_config_imdb_distributed_ws2": {
        "description": "Baseline for distributed training with 2 devices",
        "world_size": 2,
        "rank_data": {
            0: {  # Data for Rank 0
                "train_step_losses": [],
                "eval_step_losses": [],
                "train_step_metrics": [],
                "eval_step_metrics": [],
            },
            1: {  # Data for Rank 1
                "train_step_losses": [],
                "eval_step_losses": [],
                "train_step_metrics": [],
                "eval_step_metrics": [],
            },
        },
    },
}

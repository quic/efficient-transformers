[project]
name = "QEfficient"
dynamic = ["version"]
description = """
    QEfficient is the library interface for the Hugging Face Transformer \
    models for efficient inference on Qualcomm Cloud AI 100"""
readme = "README.md"
license = { file = "LICENSE" }
authors = [{ name = "Qualcomm Cloud AI ML Team" }]
keywords = ["transformers", "Cloud AI 100", "Inference"]
classifiers = [
    "Programming Language :: Python :: 3",
    "Development Status :: 5 - Development/Unstable",
    "Intended Audience :: Developers",
    "Intended Audience :: Education",
    "Operating System :: Linux",
    "Programming Language :: Python :: 3.10",
    "Topic :: Scientific/Engineering :: Artificial Intelligence for Inference Accelerator",
]
requires-python = ">=3.8,<3.11"
dependencies = [
    "huggingface-hub==0.34.0",
    "hf_transfer==0.1.9",
    "peft==0.13.2",
    "datasets==2.20.0",
    "fsspec==2023.6.0",
    "multidict==6.0.4",
    "urllib3<2",
    "sentencepiece==0.2.0",
    "onnx==1.18.0",
    "onnxruntime==1.22",
    "numpy==1.26.4",
    "protobuf==6.31.0",
    "onnxscript==0.2.5",
    "pillow===10.4.0",
    "sympy",
    "fire",
    "py7zr",
]

[project.optional-dependencies]
test = ["pytest","pytest-mock"]
docs = ["Sphinx==7.1.2","sphinx-rtd-theme==2.0.0","myst-parser==3.0.1","sphinx-multiversion"]
quality = ["black", "ruff", "hf_doc_builder@git+https://github.com/huggingface/doc-builder.git"]
infer = [
    "transformers==4.55.0",
    "torch==2.7.0; platform_machine=='aarch64'",
    # Specifying torch cpu package URL per python version, update the list once pytorch releases whl for python>3.11
    "torch@https://download.pytorch.org/whl/cpu/torch-2.4.1%2Bcpu-cp38-cp38-linux_x86_64.whl ; python_version=='3.8' and platform_machine=='x86_64'",
    "torch@https://download.pytorch.org/whl/cpu/torch-2.7.0%2Bcpu-cp39-cp39-manylinux_2_28_x86_64.whl ; python_version=='3.9' and platform_machine=='x86_64'",
    "torch@https://download.pytorch.org/whl/cpu/torch-2.7.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl ; python_version=='3.10' and platform_machine=='x86_64'",
]
ft = [
    "accelerate @ file:///opt/qti-aic/integrations/accelerate/py310/accelerate-1.10.1-py3-none-any.whl ; python_version=='3.10' and platform_machine=='x86_64'",
    "accelerate @ file:///opt/qti-aic/integrations/accelerate/py311/accelerate-1.10.1-py3-none-any.whl ; python_version=='3.11' and platform_machine=='x86_64'",
    "tensorboard ; python_version>='3.10' and python_version<'3.12' and platform_machine=='x86_64'",
    "transformers==4.55.0 ; python_version>='3.10' and python_version<'3.12' and platform_machine=='x86_64'",
    "torch@https://download.pytorch.org/whl/cpu/torch-2.9.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl ; python_version=='3.10' and platform_machine=='x86_64'",
    "torch@https://download.pytorch.org/whl/cpu/torch-2.9.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl ; python_version=='3.11' and platform_machine=='x86_64'",
    "torchmetrics==1.7.0 ; python_version>='3.10' and python_version<'3.12' and platform_machine=='x86_64'",
    "torch_qaic @ file:///opt/qti-aic/integrations/torch_qaic/py310/torch_qaic-0.1.0-cp310-cp310-linux_x86_64.whl ; python_version=='3.10' and platform_machine=='x86_64'",
    "torch_qaic @ file:///opt/qti-aic/integrations/torch_qaic/py311/torch_qaic-0.1.0-cp310-cp310-linux_x86_64.whl ; python_version=='3.11' and platform_machine=='x86_64'",
]

[build-system]
requires = ["setuptools>=62.0.0"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
include = ["QEfficient*"]
namespaces = false

[tool.setuptools.dynamic.version]
attr = "QEfficient.__version__"

[tool.ruff]
line-length = 120
# Enable the isort rules.
lint.extend-select = ["I"]
target-version = "py310"

[tool.pytest.ini_options]
addopts = "-W ignore -s -v"
junit_logging = "all"
doctest_optionflags = "NUMBER NORMALIZE_WHITESPACE ELLIPSIS"

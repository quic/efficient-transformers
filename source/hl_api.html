<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>High Level API &mdash; efficient-transformers main documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/my_theme.css?v=547657ed" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=d01aebe5"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Low Level API" href="ll_api.html" />
    <link rel="prev" title="QEfficient.cloud.infer" href="cli_api.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            efficient-transformers
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction Qualcomm <code class="docutils literal notranslate"><span class="pre">efficient-transformers</span></code> library</a></li>
<li class="toctree-l1"><a class="reference internal" href="validate.html">Validated Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="validate.html#models-coming-soon">Models Coming Soon</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Pre-requisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html#linux-installation">Linux Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html#sanity-check">Sanity Check</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quick start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Transformed models and QPC storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html#command-line-interface">Command Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html#python-api">Python API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Command Line Interface Use (CLI)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cli_api.html"><code class="docutils literal notranslate"><span class="pre">QEfficient.cloud.infer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="cli_api.html#module-QEfficient.cloud.execute.main"><code class="docutils literal notranslate"><span class="pre">QEfficient.cloud.execute</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="cli_api.html#qefficient-cloud-compile"><code class="docutils literal notranslate"><span class="pre">QEfficient.cloud.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="cli_api.html#qefficient-cloud-export"><code class="docutils literal notranslate"><span class="pre">QEfficient.cloud.export</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">High Level API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-QEfficient.transformers.models.modeling_auto"><code class="docutils literal notranslate"><span class="pre">QEFFAutoModelForCausalLM</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM"><code class="docutils literal notranslate"><span class="pre">QEFFAutoModelForCausalLM</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.compile"><code class="docutils literal notranslate"><span class="pre">QEFFAutoModelForCausalLM.compile()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.export"><code class="docutils literal notranslate"><span class="pre">QEFFAutoModelForCausalLM.export()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.from_pretrained"><code class="docutils literal notranslate"><span class="pre">QEFFAutoModelForCausalLM.from_pretrained()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.generate"><code class="docutils literal notranslate"><span class="pre">QEFFAutoModelForCausalLM.generate()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.tokenizer"><code class="docutils literal notranslate"><span class="pre">QEFFAutoModelForCausalLM.tokenizer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.transform"><code class="docutils literal notranslate"><span class="pre">QEFFAutoModelForCausalLM.transform()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-QEfficient.exporter.export_hf_to_cloud_ai_100"><code class="docutils literal notranslate"><span class="pre">export</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#QEfficient.exporter.export_hf_to_cloud_ai_100.qualcomm_efficient_converter"><code class="docutils literal notranslate"><span class="pre">qualcomm_efficient_converter()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-QEfficient.compile.compile_helper"><code class="docutils literal notranslate"><span class="pre">compile</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#QEfficient.compile.compile_helper.compile"><code class="docutils literal notranslate"><span class="pre">compile()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-QEfficient.generation.text_generation_inference"><code class="docutils literal notranslate"><span class="pre">Execute</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#QEfficient.generation.text_generation_inference.CloudAI100ExecInfo"><code class="docutils literal notranslate"><span class="pre">CloudAI100ExecInfo</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#QEfficient.generation.text_generation_inference.cloud_ai_100_exec_kv"><code class="docutils literal notranslate"><span class="pre">cloud_ai_100_exec_kv()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ll_api.html">Low Level API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Blogs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="blogs.html">Train anywhere, Infer on Qualcomm Cloud AI 100</a></li>
<li class="toctree-l1"><a class="reference internal" href="blogs.html#how-to-quadruple-llm-decoding-performance-with-speculative-decoding-spd-and-microscaling-mx-formats-on-qualcomm-cloud-ai-100">How to Quadruple LLM Decoding Performance with Speculative Decoding (SpD) and Microscaling (MX) Formats on Qualcomm® Cloud AI 100</a></li>
<li class="toctree-l1"><a class="reference internal" href="blogs.html#power-efficient-acceleration-for-large-language-models-qualcomm-cloud-ai-sdk">Power-efficient acceleration for large language models – Qualcomm Cloud AI SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="blogs.html#qualcomm-cloud-ai-100-accelerates-large-language-model-inference-by-2x-using-microscaling-mx-formats">Qualcomm Cloud AI 100 Accelerates Large Language Model Inference by ~2x Using Microscaling (Mx) Formats</a></li>
<li class="toctree-l1"><a class="reference internal" href="blogs.html#qualcomm-cloud-ai-introduces-efficient-transformers-one-api-infinite-possibilities">Qualcomm Cloud AI Introduces Efficient Transformers: One API, Infinite Possibilities</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reference.html">Qualcomm Cloud AI home</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html#qualcomm-cloud-ai-sdk-download">Qualcomm Cloud AI SDK download</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html#qualcomm-cloud-ai-api-reference">Qualcomm Cloud AI API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html#user-guide">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html#ocp-microscaling-formats-mx-specification">OCP Microscaling Formats (MX) Specification</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">efficient-transformers</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">High Level API</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/source/hl_api.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p><strong>This page give you an overview about the all the APIs that you might need to integrate the <code class="docutils literal notranslate"><span class="pre">QEfficient</span></code> into your python applications.</strong></p>
<section id="high-level-api">
<h1>High Level API<a class="headerlink" href="#high-level-api" title="Permalink to this heading"></a></h1>
<section id="module-QEfficient.transformers.models.modeling_auto">
<span id="qeffautomodelforcausallm"></span><h2><code class="docutils literal notranslate"><span class="pre">QEFFAutoModelForCausalLM</span></code><a class="headerlink" href="#module-QEfficient.transformers.models.modeling_auto" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">QEfficient.transformers.models.modeling_auto.</span></span><span class="sig-name descname"><span class="pre">QEFFAutoModelForCausalLM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained_model_name_or_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/QEfficient/transformers/models/modeling_auto.html#QEFFAutoModelForCausalLM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM" title="Permalink to this definition"></a></dt>
<dd><p>The QEFF class is designed for manipulating any causal language model from the HuggingFace hub.
Although it is possible to initialize the class directly, we highly recommend using the <code class="docutils literal notranslate"><span class="pre">from_pretrained</span></code> method for initialization.
Please note that the QEFF class is also a part of the <code class="docutils literal notranslate"><span class="pre">QEfficient</span></code> module.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">Mandatory</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">model (nn.Module)<span class="colon">:</span></dt>
<dd class="field-odd"><p>PyTorch model</p>
</dd>
<dt class="field-even">pretrained_model_name_or_path (str)<span class="colon">:</span></dt>
<dd class="field-even"><p>We recommend passing name of the model as input here, as you are not using <cite>from_pretrained</cite> method. This name will be used for deciding path of the <code class="docutils literal notranslate"><span class="pre">ONNX/qpc</span></code> files generated during <code class="docutils literal notranslate"><span class="pre">export</span></code>, <code class="docutils literal notranslate"><span class="pre">compilation</span></code> stages.</p>
</dd>
</dl>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">QEfficient</span> <span class="kn">import</span> <span class="n">QEFFAutoModelForCausalLM</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_cores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_group</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_card_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mxfp6</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mxint8</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mos</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aic_enable_depth_first</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="../_modules/QEfficient/transformers/models/modeling_auto.html#QEFFAutoModelForCausalLM.compile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.compile" title="Permalink to this definition"></a></dt>
<dd><p>This method compiles the exported <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> model using the Cloud AI 100 Platform SDK compiler binary found at <code class="docutils literal notranslate"><span class="pre">/opt/qti-aic/exec/qaic-exec</span></code> and generates a <code class="docutils literal notranslate"><span class="pre">qpc</span></code> package.
If the model has not been exported yet, this method will handle the export process.
The generated <code class="docutils literal notranslate"><span class="pre">qpc</span></code> can be found under the directory <code class="docutils literal notranslate"><span class="pre">efficient-transformers/qeff_models/{self.model_card_name}/qpc</span></code>.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">Mandatory</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">num_cores (int)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Number of cores used to compile the model.</p>
</dd>
<dt class="field-even">device_group (List[int])<span class="colon">:</span></dt>
<dd class="field-even"><p>If this is a list of more that one integers, tensor-slicing is invoked.</p>
</dd>
</dl>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">Optional</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">model_card_name (Optional[str], optional)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Name of the model, Mandatory if <code class="docutils literal notranslate"><span class="pre">self.pretrained_model_name_or_path</span></code> is a path. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-even">batch_size (int, optional)<span class="colon">:</span></dt>
<dd class="field-even"><p>Batch size. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">1</span></code>.</p>
</dd>
<dt class="field-odd">prompt_len (int, optional)<span class="colon">:</span></dt>
<dd class="field-odd"><p>The length of the Prefill prompt should be less that <code class="docutils literal notranslate"><span class="pre">prompt_len</span></code>. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">32</span></code>.</p>
</dd>
<dt class="field-even">ctx_len (int, optional)<span class="colon">:</span></dt>
<dd class="field-even"><p>Maximum <code class="docutils literal notranslate"><span class="pre">ctx</span></code> that the compiled model can remember. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">128</span></code>.</p>
</dd>
<dt class="field-odd">mxfp6 (bool, optional)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether to use <code class="docutils literal notranslate"><span class="pre">mxfp6</span></code> compression for weights. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">mxint8 (bool, optional)<span class="colon">:</span></dt>
<dd class="field-even"><p>Whether to use <code class="docutils literal notranslate"><span class="pre">mxint8</span></code> compression for KV cache. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">False</span></code>.</p>
</dd>
<dt class="field-odd">mos (int, optional)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Effort level to reduce on-chip memory. Defaults to -1, meaning no effort. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">-1</span></code>.</p>
</dd>
<dt class="field-even">aic_enable_depth_first (bool, optional)<span class="colon">:</span></dt>
<dd class="field-even"><p>Enables DFS with default memory size. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">False</span></code>.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="field-list simple">
<dt class="field-odd">str<span class="colon">:</span></dt>
<dd class="field-odd"><p>Path of the compiled <code class="docutils literal notranslate"><span class="pre">qpc</span></code> package.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.export">
<span class="sig-name descname"><span class="pre">export</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_card_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="../_modules/QEfficient/transformers/models/modeling_auto.html#QEFFAutoModelForCausalLM.export"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.export" title="Permalink to this definition"></a></dt>
<dd><p>Exports the model to <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> format using <code class="docutils literal notranslate"><span class="pre">torch.onnx.export</span></code>.
The model should already be transformed i.e. <code class="docutils literal notranslate"><span class="pre">self.is_transformed</span></code> should be <code class="docutils literal notranslate"><span class="pre">True</span></code>.
Otherwise, this will raise an <code class="docutils literal notranslate"><span class="pre">AssertionError</span></code>.
We currently don’t support exporting non-transformed models. Please refer to the <code class="docutils literal notranslate"><span class="pre">convert_to_cloud_bertstyle</span></code> function in the <strong>Low-Level API</strong> for a legacy function that supports this.”</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">Optional</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">model_card_name (Optional[str])<span class="colon">:</span></dt>
<dd class="field-odd"><p>Name of the model card. Mandatory when model is initialized with path for <code class="docutils literal notranslate"><span class="pre">pretrained_model_name_or_path</span></code> argument during initialization. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None.</span></code></p>
</dd>
</dl>
</dd>
<dt>Raises:</dt><dd><dl class="field-list simple">
<dt class="field-odd">AttributeError<span class="colon">:</span></dt>
<dd class="field-odd"><p>If <code class="docutils literal notranslate"><span class="pre">pretrained_model_name_or_path</span></code> is a path, this function needs model card name of the model so that it can distinguish between directories while saving the <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> files generated. So, user needs to pass <code class="docutils literal notranslate"><span class="pre">model_card_name</span></code> as a valid <code class="docutils literal notranslate"><span class="pre">string</span></code> in that case, Otherwise this will raise the error.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="field-list simple">
<dt class="field-odd">str<span class="colon">:</span></dt>
<dd class="field-odd"><p>Path of the generated <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> graph.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.from_pretrained">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pretrained_model_name_or_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.from_pretrained" title="Permalink to this definition"></a></dt>
<dd><p>This method serves as the easiest entry point into using QEfficient. The interface is designed to be similar to transformers.AutoModelForCausalLM.
Once the model is initialized, you can use other methods such as export, compile, and generate on the same object.</p>
<p>Accepts All the parameters that are acceptable by <code class="docutils literal notranslate"><span class="pre">transformers.AutoModelForCausalLM</span></code>
There are few additional parameters that this method can take.</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">Mandatory</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">transform (bool)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Whether to optimize model for KV retention; default is <code class="docutils literal notranslate"><span class="pre">True</span></code>. Pass <code class="docutils literal notranslate"><span class="pre">False</span></code> to get BertStyle model.</p>
</dd>
<dt class="field-even">model_card_name (str)<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="docutils literal notranslate"><span class="pre">HuggingFace</span></code> model card name or name of the model if custom, used for deciding directory name while saving <code class="docutils literal notranslate"><span class="pre">ONNX/qpc</span></code> files.</p>
</dd>
</dl>
<p>Example usage:</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">QEfficient</span> <span class="kn">import</span> <span class="n">QEFFAutoModelForCausalLM</span>

<span class="c1"># Initialize the model using from_pretrained similar to transformers.AutoModelForCausalLM</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">QEFFAutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>

<span class="c1"># Now you can directly compile the model for Cloud AI 100</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">num_cores</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">device_group</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Considering you have a Cloud AI 100 Standard SKU</span>

<span class="c1"># You can now execute the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Hi there!!&quot;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">runtime</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'AI_100'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/QEfficient/transformers/models/modeling_auto.html#QEFFAutoModelForCausalLM.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.generate" title="Permalink to this definition"></a></dt>
<dd><p>This method generates output until <code class="docutils literal notranslate"><span class="pre">eos</span></code> or <code class="docutils literal notranslate"><span class="pre">generation_len</span></code> by executing the compiled <code class="docutils literal notranslate"><span class="pre">qpc</span></code> on <code class="docutils literal notranslate"><span class="pre">Cloud</span> <span class="pre">AI</span> <span class="pre">100</span></code> Hardware cards.
This is a sequential execution based on the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> of the compiled model and the number of prompts passed.
If the number of prompts cannot be divided by the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>, the last unfulfilled batch will be dropped.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">Mandatory</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">prompts (List[str])<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of prompts to run the execution.</p>
</dd>
</dl>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">optional</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">runtime (str, optional)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Only <code class="docutils literal notranslate"><span class="pre">AI_100</span></code> runtime is supported as of now; <code class="docutils literal notranslate"><span class="pre">ONNXRT</span></code> and <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code> coming soon. Defaults to “AI_100”.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.tokenizer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tokenizer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">PreTrainedTokenizer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">PreTrainedTokenizerFast</span></em><a class="headerlink" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.tokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Returns the tokenizer for given model based on <code class="docutils literal notranslate"><span class="pre">self.pretrained_model_name_or_path</span></code>.
Loads the tokenizer if required.</p>
<dl class="simple">
<dt>Returns:</dt><dd><dl class="field-list simple">
<dt class="field-odd">Union[PreTrainedTokenizer, PreTrainedTokenizerFast]<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tokenizer from <code class="docutils literal notranslate"><span class="pre">transformers</span></code> for the given model.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/QEfficient/transformers/models/modeling_auto.html#QEFFAutoModelForCausalLM.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.transform" title="Permalink to this definition"></a></dt>
<dd><p>This method applies all relevant optimization transforms on the model and toggles the <code class="docutils literal notranslate"><span class="pre">self.is_transformed</span></code> attribute to True. If the model is already transformed, the method will simply return.
Please note that this method does not require any input arguments.”</p>
<dl class="simple">
<dt>Returns:</dt><dd><dl class="field-list simple">
<dt class="field-odd">obj<span class="colon">:</span></dt>
<dd class="field-odd"><p>Same object with transformed <code class="docutils literal notranslate"><span class="pre">self.model</span></code></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-QEfficient.exporter.export_hf_to_cloud_ai_100">
<span id="export"></span><h2><code class="docutils literal notranslate"><span class="pre">export</span></code><a class="headerlink" href="#module-QEfficient.exporter.export_hf_to_cloud_ai_100" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="QEfficient.exporter.export_hf_to_cloud_ai_100.qualcomm_efficient_converter">
<span class="sig-prename descclassname"><span class="pre">QEfficient.exporter.export_hf_to_cloud_ai_100.</span></span><span class="sig-name descname"><span class="pre">qualcomm_efficient_converter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kv</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">QEFFBaseModel</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_model_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PreTrainedTokenizer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">PreTrainedTokenizerFast</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onnx_dir_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hf_token</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kv</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">form_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cloud'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/QEfficient/exporter/export_hf_to_cloud_ai_100.html#qualcomm_efficient_converter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#QEfficient.exporter.export_hf_to_cloud_ai_100.qualcomm_efficient_converter" title="Permalink to this definition"></a></dt>
<dd><p>This method is an alias for <code class="docutils literal notranslate"><span class="pre">QEfficient.export</span></code>.</p>
<p>Usage 1: This method can be used by passing <code class="docutils literal notranslate"><span class="pre">model_name</span></code> and <code class="docutils literal notranslate"><span class="pre">local_model_dir</span></code> or <code class="docutils literal notranslate"><span class="pre">cache_dir</span></code> if required for loading from local dir.
This will download the model from <code class="docutils literal notranslate"><span class="pre">HuggingFace</span></code> and export it to <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> graph and returns generated files path check below.</p>
<p>Usage 2: You can pass <code class="docutils literal notranslate"><span class="pre">model_name</span></code> and <code class="docutils literal notranslate"><span class="pre">model_kv</span></code> as an object of <code class="docutils literal notranslate"><span class="pre">QEfficient.QEFFAutoModelForCausalLM</span></code>, In this case will directly export the <code class="docutils literal notranslate"><span class="pre">model_kv.model</span></code> to <code class="docutils literal notranslate"><span class="pre">ONNX</span></code></p>
<p>We will be deprecating this function and it will be replaced by <code class="docutils literal notranslate"><span class="pre">QEffAutoModelForCausalLM.export</span></code>.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">Mandatory</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">model_name (str)<span class="colon">:</span></dt>
<dd class="field-odd"><p>The name of the model to be used.</p>
</dd>
</dl>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">Optional</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">model_kv (torch.nn.Module)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Transformed <code class="docutils literal notranslate"><span class="pre">KV</span> <span class="pre">torch</span> <span class="pre">model</span></code> to be used. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-even">local_model_dir (str)<span class="colon">:</span></dt>
<dd class="field-even"><p>Path of local model. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-odd">tokenizer (Union[PreTrainedTokenizer, PreTrainedTokenizerFast])<span class="colon">:</span></dt>
<dd class="field-odd"><p>Model tokenizer. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-even">cache_dir (str)<span class="colon">:</span></dt>
<dd class="field-even"><p>Path of the <code class="docutils literal notranslate"><span class="pre">cache</span></code> directory. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-odd">onnx_dir_path (str)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Path to store <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> file. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-even">hf_token (str)<span class="colon">:</span></dt>
<dd class="field-even"><p>HuggingFace token to access gated models. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">is</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-odd">seq_len (int)<span class="colon">:</span></dt>
<dd class="field-odd"><p>The length of the sequence. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">is</span> <span class="pre">128</span></code>.</p>
</dd>
<dt class="field-even">kv (bool)<span class="colon">:</span></dt>
<dd class="field-even"><p>If false, it will export to Bert style. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">is</span> <span class="pre">True</span></code>.</p>
</dd>
<dt class="field-odd">form_factor (str)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Form factor of the hardware, currently only <code class="docutils literal notranslate"><span class="pre">cloud</span></code> is accepted. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">cloud</span></code>.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="field-list simple">
<dt class="field-odd">Tuple[str, str]<span class="colon">:</span></dt>
<dd class="field-odd"><p>Path to Base <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> dir and path to generated <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> model</p>
</dd>
</dl>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">QEfficient</span>
<span class="n">base_path</span><span class="p">,</span> <span class="n">onnx_model_path</span> <span class="o">=</span> <span class="n">QEfficient</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-QEfficient.compile.compile_helper">
<span id="compile"></span><h2><code class="docutils literal notranslate"><span class="pre">compile</span></code><a class="headerlink" href="#module-QEfficient.compile.compile_helper" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="QEfficient.compile.compile_helper.compile">
<span class="sig-prename descclassname"><span class="pre">QEfficient.compile.compile_helper.</span></span><span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onnx_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qpc_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_cores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_group</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aic_enable_depth_first</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mos</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mxfp6</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mxint8</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_io_file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="../_modules/QEfficient/compile/compile_helper.html#compile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#QEfficient.compile.compile_helper.compile" title="Permalink to this definition"></a></dt>
<dd><p>Compiles the given <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> model using Cloud AI 100 platform SDK compiler and saves the compiled <code class="docutils literal notranslate"><span class="pre">qpc</span></code> package at <code class="docutils literal notranslate"><span class="pre">qpc_path</span></code>.
Generates tensor-slicing configuration if multiple devices are passed in <code class="docutils literal notranslate"><span class="pre">device_group</span></code>.</p>
<p>This function will be deprecated soon and will be replaced by <code class="docutils literal notranslate"><span class="pre">QEFFAutoModelForCausalLM.compile</span></code>.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">Mandatory</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">onnx_path (str)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Generated <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> Model Path.</p>
</dd>
<dt class="field-even">qpc_path (str)<span class="colon">:</span></dt>
<dd class="field-even"><p>Path for saving compiled qpc binaries.</p>
</dd>
<dt class="field-odd">num_cores (int)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Number of cores to compile the model on.</p>
</dd>
</dl>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">Optional</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">device_group (List[int])<span class="colon">:</span></dt>
<dd class="field-odd"><p>Used for finding the number of devices to compile for. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None.</span></code></p>
</dd>
<dt class="field-even">aic_enable_depth_first (bool)<span class="colon">:</span></dt>
<dd class="field-even"><p>Enables <code class="docutils literal notranslate"><span class="pre">DFS</span></code> with default memory size. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">False.</span></code></p>
</dd>
<dt class="field-odd">mos (int)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Effort level to reduce the on-chip memory. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">-1.</span></code></p>
</dd>
<dt class="field-even">batch_size (int)<span class="colon">:</span></dt>
<dd class="field-even"><p>Batch size to compile the model for. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">1.</span></code></p>
</dd>
<dt class="field-odd">full_batch_size (int)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Set full batch size to enable continuous batching mode. <code class="docutils literal notranslate"><span class="pre">Default</span> <span class="pre">to</span> <span class="pre">None</span></code></p>
</dd>
<dt class="field-even">prompt_len (int)<span class="colon">:</span></dt>
<dd class="field-even"><p>Prompt length for the model to compile. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">32</span></code></p>
</dd>
<dt class="field-odd">ctx_len (int)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Maximum context length to compile the model. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">128</span></code></p>
</dd>
<dt class="field-even">mxfp6 (bool)<span class="colon">:</span></dt>
<dd class="field-even"><p>Enable compilation for <code class="docutils literal notranslate"><span class="pre">MXFP6</span></code> precision.  <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">True.</span></code></p>
</dd>
<dt class="field-odd">mxint8 (bool)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Compress Present/Past KV to <code class="docutils literal notranslate"><span class="pre">MXINT8</span></code> using <code class="docutils literal notranslate"><span class="pre">CustomIO</span></code> config. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">False.</span></code></p>
</dd>
<dt class="field-even">custom_io_file_path (str)<span class="colon">:</span></dt>
<dd class="field-even"><p>Path to <code class="docutils literal notranslate"><span class="pre">customIO</span></code> file (formatted as a string). <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None.</span></code></p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="field-list simple">
<dt class="field-odd">str<span class="colon">:</span></dt>
<dd class="field-odd"><p>Path to compiled <code class="docutils literal notranslate"><span class="pre">qpc</span></code> package.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-QEfficient.generation.text_generation_inference">
<span id="execute"></span><h2><code class="docutils literal notranslate"><span class="pre">Execute</span></code><a class="headerlink" href="#module-QEfficient.generation.text_generation_inference" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="QEfficient.generation.text_generation_inference.CloudAI100ExecInfo">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">QEfficient.generation.text_generation_inference.</span></span><span class="sig-name descname"><span class="pre">CloudAI100ExecInfo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_texts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefill_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decode_perf</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_perf</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/QEfficient/generation/text_generation_inference.html#CloudAI100ExecInfo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#QEfficient.generation.text_generation_inference.CloudAI100ExecInfo" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Holds all the information about Cloud AI 100 execution</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">batch_size (int)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Batch size of the QPC compilation.</p>
</dd>
<dt class="field-even">generated_texts (Union[List[List[str]], List[str]])<span class="colon">:</span></dt>
<dd class="field-even"><p>Generated text(s).</p>
</dd>
<dt class="field-odd">generated_ids (Union[List[np.ndarray], np.ndarray])<span class="colon">:</span></dt>
<dd class="field-odd"><p>Generated IDs.</p>
</dd>
<dt class="field-even">prefill_time (float)<span class="colon">:</span></dt>
<dd class="field-even"><p>Time for prefilling.</p>
</dd>
<dt class="field-odd">decode_perf (float)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Decoding performance.</p>
</dd>
<dt class="field-even">total_perf (float)<span class="colon">:</span></dt>
<dd class="field-even"><p>Total performance.</p>
</dd>
<dt class="field-odd">total_time (float)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Total time.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="QEfficient.generation.text_generation_inference.cloud_ai_100_exec_kv">
<span class="sig-prename descclassname"><span class="pre">QEfficient.generation.text_generation_inference.</span></span><span class="sig-name descname"><span class="pre">cloud_ai_100_exec_kv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PreTrainedTokenizer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">PreTrainedTokenizerFast</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qpc_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompts_txt_file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generation_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_debug_logs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">write_io_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">automation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/QEfficient/generation/text_generation_inference.html#cloud_ai_100_exec_kv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#QEfficient.generation.text_generation_inference.cloud_ai_100_exec_kv" title="Permalink to this definition"></a></dt>
<dd><p>This method generates output until <code class="docutils literal notranslate"><span class="pre">eos</span></code> or <code class="docutils literal notranslate"><span class="pre">generation_len</span></code> by executing the compiled <code class="docutils literal notranslate"><span class="pre">qpc</span></code> on <code class="docutils literal notranslate"><span class="pre">Cloud</span> <span class="pre">AI</span> <span class="pre">100</span></code> Hardware cards.
This is a sequential execution based on the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> of the compiled model and the number of prompts passed.
If the number of prompts cannot be divided by the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>, the last unfulfilled batch will be dropped.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">Mandatory</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">tokenizer (Union[PreTrainedTokenizer, PreTrainedTokenizerFast])<span class="colon">:</span></dt>
<dd class="field-odd"><p>Model tokenizer.</p>
</dd>
<dt class="field-even">qpc_path (str)<span class="colon">:</span></dt>
<dd class="field-even"><p>Path to the saved generated binary file after compilation.</p>
</dd>
</dl>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">Optional</span></code> Args:</dt><dd><dl class="field-list simple">
<dt class="field-odd">prompt (str)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Sample prompt for the model text generation. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-even">prompts_txt_file_path (str)<span class="colon">:</span></dt>
<dd class="field-even"><p>Path of the prompt text file. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-odd">generation_len (int)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Maximum context length for the model during compilation. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-even">device_id (List[int])<span class="colon">:</span></dt>
<dd class="field-even"><p>Device IDs to be used for execution. If <code class="docutils literal notranslate"><span class="pre">len(device_id)</span> <span class="pre">&gt;</span> <span class="pre">1</span></code>, it enables multiple card setup. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, auto-device-picker will be used. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-odd">enable_debug_logs (bool)<span class="colon">:</span></dt>
<dd class="field-odd"><p>If True, it enables debugging logs. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">False</span></code>.</p>
</dd>
<dt class="field-even">stream (bool)<span class="colon">:</span></dt>
<dd class="field-even"><p>If True, enable streamer, which returns tokens one by one as the model generates them. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">True</span></code>.</p>
</dd>
<dt class="field-odd">Write_io_dir (str)<span class="colon">:</span></dt>
<dd class="field-odd"><p>Path to write the input and output files. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">None</span></code>.</p>
</dd>
<dt class="field-even">automation (bool)<span class="colon">:</span></dt>
<dd class="field-even"><p>If true, it prints input, output, and performance stats. <code class="docutils literal notranslate"><span class="pre">Defaults</span> <span class="pre">to</span> <span class="pre">False</span></code>.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="field-list simple">
<dt class="field-odd">CloudAI100ExecInfo<span class="colon">:</span></dt>
<dd class="field-odd"><p>Object holding execution output and performance details.</p>
</dd>
</dl>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">import</span> <span class="nn">QEfficient</span>
<span class="n">base_path</span><span class="p">,</span> <span class="n">onnx_model_path</span> <span class="o">=</span> <span class="n">QEfficient</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
<span class="n">qpc_path</span> <span class="o">=</span> <span class="n">QEfficient</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">onnx_path</span><span class="o">=</span><span class="n">onnx_model_path</span><span class="p">,</span> <span class="n">qpc_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_path</span><span class="p">,</span> <span class="s2">&quot;qpc&quot;</span><span class="p">),</span> <span class="n">num_cores</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">device_group</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
<span class="n">execinfo</span> <span class="o">=</span> <span class="n">QEfficient</span><span class="o">.</span><span class="n">cloud_ai_100_exec_kv</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">qpc_path</span><span class="o">=</span><span class="n">qpc_path</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="s2">&quot;Hi there!!&quot;</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cli_api.html" class="btn btn-neutral float-left" title="QEfficient.cloud.infer" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ll_api.html" class="btn btn-neutral float-right" title="Low Level API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Qualcomm.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
Search.setIndex({"docnames": ["README", "index", "source/blogs", "source/cli_api", "source/finetune", "source/hl_api", "source/installation", "source/introduction", "source/ll_api", "source/quick_start", "source/reference", "source/upgrade", "source/validate"], "filenames": ["README.md", "index.md", "source/blogs.md", "source/cli_api.md", "source/finetune.md", "source/hl_api.md", "source/installation.md", "source/introduction.md", "source/ll_api.md", "source/quick_start.md", "source/reference.md", "source/upgrade.md", "source/validate.md"], "titles": ["Docs", "Welcome to Efficient-Transformers Documentation!", "Train anywhere, Infer on Qualcomm Cloud AI 100", "<code class=\"docutils literal notranslate\"><span class=\"pre\">QEfficient.cloud.infer</span></code>", "Finetune Infra", "High Level API", "Pre-requisites", "Introduction Qualcomm <code class=\"docutils literal notranslate\"><span class=\"pre\">efficient-transformers</span></code> library", "Low Level API", "Transformed models and QPC storage", "Qualcomm Cloud AI home", "Using GitHub Repository", "Validated Models"], "terms": {"thi": [0, 3, 4, 5, 7, 8, 9, 11], "directori": [0, 4, 5, 6, 9], "contain": [0, 5, 9], "instruct": [0, 7, 12], "static": 0, "html": 0, "document": [0, 7], "base": [0, 1, 5, 7, 8, 12], "sphinx": 0, "instal": [0, 11], "packag": [0, 3, 5], "requir": [0, 5, 6, 9, 11], "pip": [0, 4, 11], "r": [0, 12], "txt": [0, 3, 9], "And": [0, 8], "chang": [0, 7, 9], "folder": [0, 9], "cd": 0, "To": [0, 4, 7, 9], "specif": [0, 1, 4, 5], "branch": 0, "m": [0, 3, 4, 5, 9, 11], "option": [0, 3, 5, 9], "all": [0, 5, 8, 12], "support": [0, 5, 6, 7, 9, 12], "multivers": 0, "python": [0, 3, 4, 5, 6, 11], "http": [0, 4, 9, 11], "server": 0, "you": [0, 4, 5, 6, 9], "can": [0, 4, 5, 6, 7, 9], "visit": [0, 4], "page": [0, 5], "your": [0, 5, 9], "web": 0, "browser": 0, "url": 0, "localhost": 0, "8080": 0, "introduct": 1, "qualcomm": 1, "librari": [1, 4, 6, 9], "valid": [1, 9, 11], "model": [1, 3, 4, 5, 6, 7, 8, 11], "come": [1, 5, 7], "soon": [1, 3, 5, 7], "pre": [1, 5, 7, 9], "requisit": 1, "1": [1, 3, 4, 5, 7, 8, 12], "download": [1, 3, 4, 5], "app": [1, 3], "sdk": [1, 3, 5, 9, 11], "2": [1, 4, 5, 7, 12], "saniti": 1, "check": [1, 3, 5, 8, 9], "github": [1, 4], "repositori": [1, 4], "qpc": [1, 3, 5, 8], "storag": 1, "qeffici": [1, 4, 5, 6, 8, 11], "cloud": [1, 4, 5, 6, 7, 8], "infer": [1, 5, 7], "execut": [1, 6, 7], "multi": [1, 6], "qranium": 1, "continu": [1, 3, 5, 7, 12], "batch": [1, 3, 5, 7, 12], "qnn": [1, 3, 5], "compil": [1, 7, 8], "optim": [1, 7], "ai": [1, 3, 5, 6, 7, 8], "100": [1, 3, 5, 6, 7, 8], "export": [1, 4, 7, 8], "one": [1, 5, 8], "3": [1, 4, 5, 7, 11, 12], "draft": 1, "specul": [1, 5, 7], "decod": [1, 5, 7, 8], "high": [1, 9], "level": [1, 3, 4, 9], "qeffautomodelforcausallm": [1, 3, 7, 8, 9], "qeffautomodel": 1, "qeffautopeftmodelforcausallm": 1, "qeffautoloramodelforcausallm": 1, "low": [1, 5], "convert_to_cloud_kvstyl": 1, "convert_to_cloud_bertstyl": [1, 5], "util": [1, 5, 6, 9], "infra": 1, "dataset": [1, 9], "detail": [1, 5, 9], "usag": [1, 5, 7], "visual": 1, "train": [1, 7], "anywher": [1, 7], "how": [1, 7], "quadrupl": 1, "llm": [1, 7, 9], "perform": [1, 5, 7], "spd": 1, "microsc": 1, "mx": 1, "format": [1, 3, 5], "power": [1, 9], "acceler": [1, 4], "larg": 1, "languag": [1, 5, 9], "2x": 1, "introduc": 1, "One": 1, "infinit": 1, "possibl": [1, 5], "home": 1, "user": [1, 7, 9], "guid": 1, "ocp": 1, "click": 2, "here": [2, 5, 7], "us": [3, 4, 5, 6, 7, 8, 9], "bash": [3, 9], "termin": [3, 9], "els": [3, 9], "zsh": [3, 9], "device_group": [3, 5, 8, 9], "should": [3, 5, 9], "singl": [3, 9], "quot": [3, 9], "e": [3, 9], "g": [3, 9], "0": [3, 4, 5, 9], "provid": [4, 5, 7, 9], "infrastructur": 4, "differ": [4, 5, 9], "hardwar": [4, 5, 9], "same": [4, 5, 9, 11], "cli": [3, 4, 9], "run": [3, 4, 5, 6, 9], "gpu": 4, "set": [3, 4, 5, 9], "devic": [3, 4, 5, 6, 7, 8, 9], "flag": [4, 5, 9], "torch": [4, 5, 8, 9], "cuda": 4, "along": [4, 9], "pytorch": [4, 5, 8, 9], "eager": [4, 9], "mode": [3, 4, 5], "For": [4, 7, 9], "com": [4, 11], "quic": [4, 11], "effici": [4, 8, 9, 11], "transform": [3, 4, 5, 8, 11], "torch_qaic": 4, "assum": 4, "i": [3, 4, 5, 6, 7, 9], "alreadi": [3, 4, 9], "opt": [4, 5, 6], "qti": [4, 5, 6], "aic": [4, 5, 6], "integr": [4, 5, 6], "py310": 4, "cp310": 4, "linux_x86_64": 4, "whl": 4, "env": [4, 11], "variabl": [4, 9], "enabl": [3, 4, 5, 6, 7, 8, 9], "privat": [3, 4], "hf_datasets_trust_remote_cod": 4, "true": [3, 4, 5, 9], "get": 4, "hw": [4, 7], "trace": 4, "debug": [4, 5], "log": [4, 5], "qaic_device_log_level": 4, "qaic_debug": 4, "understand": 4, "cpu": [4, 5], "fallback": 4, "op": 4, "alpaca": 4, "link": 4, "place": 4, "under": [4, 6, 9], "make": [4, 7, 8, 9], "sure": [4, 9], "updat": [4, 5, 7, 8], "configur": [3, 4, 5, 9], "accordingli": 4, "wget": 4, "c": [4, 6], "raw": 4, "githubusercont": 4, "tatsu": 4, "lab": 4, "stanford_alpaca": 4, "ref": 4, "head": 4, "main": 4, "alpaca_data": 4, "json": [4, 5, 9], "p": 4, "grammar": 4, "datasets_grammar": 4, "model_nam": [3, 4, 5, 8, 9], "meta": [4, 7, 9], "llama": [4, 5, 7, 9, 12], "1b": [4, 7, 9, 12], "also": [4, 5, 9], "variou": [4, 9], "paramet": [3, 4, 5, 9], "more": [4, 7, 8, 9], "checkout": [4, 9], "config": [3, 4, 5, 8, 9], "py": 4, "below": [4, 5, 9], "exampl": [3, 4, 7, 8, 9], "command": [4, 6, 12], "line": [4, 5, 6], "peft": [4, 5, 7, 9], "output_dir": [4, 9], "sam": [4, 9], "num_epoch": [4, 9], "context_length": [4, 9], "256": [4, 5, 9], "qaic_visible_devic": 4, "torchrun": 4, "nproc": 4, "per": 4, "node": [4, 5], "4": [3, 4, 7], "enable_ddp": 4, "dist_backend": 4, "qccl": 4, "number": [3, 4, 5, 9], "worker": 4, "local": [4, 5, 7, 9], "tensorboard": 4, "ar": [3, 4, 5, 6, 7, 9], "gener": [3, 4, 5, 8, 9], "insid": 4, "date": 4, "time": [4, 5, 8, 9], "stamp": 4, "visualis": 4, "data": 4, "logdir": 4, "file": [3, 4, 5, 8, 9], "bind_al": 4, "give": 5, "an": [5, 9], "overview": 5, "about": 5, "might": 5, "need": [5, 7, 9], "applic": [5, 7], "deprec": [3, 5], "sinc": 5, "version": [5, 6], "function": [3, 5, 7, 8, 12], "19": 5, "pleas": [5, 9], "instead": [5, 9], "import": [5, 6, 9], "base_path": 5, "onnx_model_path": 5, "gpt2": [3, 5, 8, 9, 12], "qpc_path": [3, 5, 8, 9], "onnx_path": [3, 5, 9], "o": [5, 6, 9], "path": [3, 5, 6, 7, 8, 9], "join": [5, 9], "num_cor": [3, 5, 9], "14": [5, 9], "system": 6, "linux": 6, "ubuntu": 6, "rhel": 6, "aw": 6, "platform": [3, 5, 6, 9], "shard": 6, "uninstal": 6, "exist": [3, 6, 9], "sudo": 6, "sh": 6, "script": 6, "root": 6, "permiss": 6, "qeff": [5, 6], "sourc": [5, 6, 7, 8, 11], "dev": 6, "bin": [6, 11], "activ": [5, 6, 11], "On": 6, "success": 6, "content": 6, "store": [3, 5, 6, 9], "exec": [5, 6], "follow": [6, 9], "tool": 6, "qaic": [3, 5, 6, 9], "appli": 6, "chmod": 6, "x": 6, "hexagon_tool": 6, "after": [3, 5, 6, 8], "abov": [6, 9], "method": [5, 6], "correctli": 6, "print": [5, 6, 9], "__version__": 6, "If": [3, 5, 6, 9], "successfulli": 6, "good": 6, "go": 6, "ahead": [6, 9], "start": [3, 5, 6], "deploi": 6, "card": [3, 5, 6, 7, 8, 9], "develop": [7, 9], "centric": 7, "toolchain": 7, "reimplement": 7, "block": 7, "which": [5, 7, 9], "highli": [5, 7], "we": [5, 7, 9], "wide": 7, "rang": 7, "architectur": [7, 8, 9], "easi": 7, "deploy": 7, "onli": [5, 7, 9], "from": [5, 7, 8, 9], "huggingfac": [3, 5, 7, 8, 9], "take": [5, 7, 9], "care": 7, "": [5, 7], "implement": 7, "other": [5, 7, 9], "comprehens": 7, "inspir": 7, "upon": [7, 9], "typic": 7, "retent": [7, 8], "intermedi": 7, "state": [7, 8], "read": 7, "graph": [5, 7, 9], "kei": 7, "oper": 7, "lower": 7, "precis": [3, 5, 7], "replac": [3, 5, 7], "some": 7, "mathemat": 7, "equival": 7, "backend": 7, "handl": [5, 7], "underflow": 7, "overflow": [7, 9], "patcher": 7, "modul": [5, 7, 8], "map": [5, 7], "weight": [3, 5, 7], "origin": [7, 8, 9], "onnx": [3, 5, 7, 8, 9], "sampl": [3, 5, 7, 9], "demo": [7, 9], "notebook": [7, 9], "unit": 7, "test": 7, "templat": 7, "latest": 7, "new": [5, 7, 9], "popular": 7, "11": 7, "2024": 7, "finit": [5, 7], "adapt": [5, 7, 12], "allow": [3, 5, 7], "mix": [5, 7], "tlm": [7, 9], "return": [3, 5, 7, 8], "than": 7, "logit": [5, 7, 8], "dure": [5, 7, 9], "ad": [5, 7, 9], "70b": [7, 9, 12], "3b": [7, 12], "09": 7, "awq": 7, "gptq": 7, "bit": 7, "quantiz": 7, "now": [5, 7, 9], "gemma": [7, 12], "famili": 7, "codegemma": [7, 12], "8b": [7, 12], "granit": [7, 12], "20b": [7, 12], "code": [5, 7, 9, 12], "8k": [7, 12], "starcoder1": [7, 12], "15b": [7, 12], "08": 7, "techniqu": [7, 9], "jai": [7, 12], "13b": [7, 12], "chat": [7, 9, 12], "7b": [5, 7, 12], "06": 7, "gpt": [7, 12], "j": [7, 12], "6b": [7, 12], "qwen2": [7, 12], "5b": [7, 12], "starcoder2": [7, 12], "phi3": [7, 12], "mini": [7, 12], "4k": [7, 12], "codestr": [7, 12], "22b": [7, 12], "v0": [5, 7, 12], "vicuna": [7, 12], "v1": [7, 9, 12], "5": [7, 12], "05": 7, "mixtral": [7, 12], "8x7b": [7, 12], "mistral": [5, 7, 12], "04": 7, "initi": [5, 7, 9], "releas": 7, "seamless": 7, "wa": 9, "design": [5, 9], "goal": 9, "onboard": 9, "straightforward": 9, "ani": [5, 9], "while": [5, 9], "leverag": 9, "complet": 9, "achiev": 9, "have": [5, 9, 11], "abstract": 9, "awai": 9, "complex": 9, "offer": 9, "simpler": 9, "thei": 9, "re": 9, "ideal": 9, "quick": 9, "prototyp": 9, "technologi": 9, "want": 9, "minim": 9, "effort": [3, 5, 9], "granular": 9, "control": [5, 9], "when": 9, "custom": [3, 5, 9], "necessari": 9, "By": 9, "default": [3, 5, 9], "program": 9, "readi": 9, "binari": [3, 5, 9], "cach": [3, 5, 8, 9], "qeff_cach": 9, "environ": 9, "qeff_hom": 9, "its": 9, "xdg_cache_hom": 9, "note": [9, 12], "rerout": 9, "entir": 9, "specifi": [5, 9], "includ": 9, "hf": [3, 9, 12], "neither": 9, "nor": 9, "e2": 9, "model_card": 9, "name": [3, 5, 8, 9, 12], "input": [3, 5, 8, 9], "argument": [5, 9], "doc": 9, "It": 9, "skip": 9, "stage": [5, 8, 9], "found": [5, 9], "second": 9, "automat": 9, "creation": 9, "directli": [5, 9], "jump": [3, 9], "out": 9, "help": 9, "batch_siz": [3, 5, 8, 9], "prompt_len": [3, 5, 8, 9], "32": [3, 5, 9], "ctx_len": [3, 5, 8, 9], "128": [3, 5, 9], "mxfp6": [3, 5, 9], "16": [5, 9], "prompt": [3, 5, 8, 9], "my": [5, 9], "mo": [3, 5, 9], "aic_enable_depth_first": [3, 5, 9], "size": [3, 5, 9], "pass": [3, 5, 8, 9], "string": [3, 5, 9], "separ": [8, 9], "pipe": 9, "symbol": 9, "The": [5, 8, 9], "flat": 9, "earth": 9, "theori": 9, "belief": 9, "sun": 9, "rise": 9, "lot": 9, "present": [3, 5, 9], "prompts_txt_file_path": [3, 5, 9], "first": 9, "onc": [5, 9], "precompil": 9, "refer": [5, 9], "qeff_model": [8, 9], "qpc_16cores_1bs_32pl_128cl_1devices_mxfp6": 9, "predefin": 9, "pipelin": 9, "subsect": 9, "mq": 9, "just": 9, "group": 9, "creat": [8, 9, 11], "t": [5, 9], "fly": 9, "soc": 9, "salesforc": 9, "codegen": 9, "2b": [9, 12], "mono": 9, "def": 9, "fibonacci": 9, "n": 9, "step": 9, "save": [3, 5, 8, 9], "model_card_nam": 9, "pick": 9, "qpc_16cores_1bs_32pl_128cl_2devices_mxfp6": 9, "binary_search": 9, "arrai": [5, 9], "np": [5, 9], "k": 9, "int": [3, 5, 8, 9], "disabl": 9, "like": 9, "again": 9, "reus": [5, 9], "featur": [5, 9], "full_batch_s": [3, 5, 8, 9], "full_batch_size_valu": 9, "regular": 9, "wai": 9, "tinyllama": 9, "tinyllama_v1": 9, "qnn_sdk_root": 9, "qnn_sdk_folder": 9, "enable_qnn": [3, 5, 9], "add": 9, "overrid": 9, "without": 9, "With": 9, "qnn_config": [3, 5, 9], "qpc_qnn_16cores_1bs_32pl_128cl_1devices_mxfp6": 9, "via": [5, 9], "modifi": 9, "framework": 9, "both": 9, "prefil": [5, 8, 9], "variat": 9, "automodelforcausallm": [5, 9], "co": 9, "xl": 9, "similar": [5, 9], "correspond": [5, 9], "lib": 9, "from_pretrain": [5, 9], "generated_qpc_path": 9, "qnn_config_file_path": 9, "advantag": 9, "fall": 9, "work": [9, 11], "fine": 9, "rais": 9, "issu": 9, "case": [5, 9], "troubl": 9, "uncom": 9, "appropri": 9, "don": [5, 9], "dir": [3, 5, 9], "transformers_cach": 9, "mnt": 9, "workspac": 9, "hf_cach": 9, "root_dir": 9, "dirnam": 9, "abspath": 9, "cache_dir": [3, 5, 9], "tmp": 9, "locat": 9, "param": [5, 9], "f": 9, "qualcomm_efficient_convert": [5, 9], "kv": [3, 5, 8, 9], "verifi": 9, "clip": 9, "constant": [3, 9], "fp16": [5, 9], "onnxruntim": [8, 9], "v": 9, "Then": 9, "customio": [3, 5, 9], "yaml": 9, "benchmark": 9, "token": [3, 5, 8, 9], "tok": 9, "sec": 9, "post": 9, "latenc": [5, 9], "stat": [5, 9], "comput": [5, 8, 9], "greedi": 9, "approach": [8, 9], "end": [5, 9], "avail": [8, 9], "them": [5, 9], "where": [3, 8, 9], "small": 9, "dlm": 9, "num_speculative_token": [5, 9], "autoregress": 9, "target": [5, 9], "object": [5, 8, 9], "predict": [8, 9], "what": 9, "would": 9, "been": [5, 9, 11], "benefici": 9, "phase": 9, "memori": [3, 5, 9], "bound": 9, "thu": 9, "extra": [5, 9], "resourc": 9, "our": 9, "is_tlm": [5, 8, 9], "tlm_name": 9, "dlm_name": 9, "fed": [5, 9], "instanti": 9, "becaus": 9, "slight": 9, "defin": 9, "actual": 9, "As": 9, "warn": 11, "compat": 11, "upgrad": 11, "mai": 11, "result": 11, "certain": 11, "becom": 11, "incompat": 11, "virtual": 11, "10": 11, "python3": 11, "venv": 11, "qeff_env": 11, "u": 11, "clone": 11, "repo": [3, 11], "git": 11, "codellama": 12, "34b": 12, "deepseek": 12, "r1": 12, "distil": 12, "qwen": 12, "32b": 12, "falcon": 12, "40b": 12, "9b": 12, "27b": 12, "mpt": 12, "baichuan2": 12, "cohereforai": 12, "c4ai": 12, "v01": 12, "chatglm2": 12, "databrick": 12, "dbrx": 12, "405b": 12, "11b": 12, "vision": 12, "90b": 12, "given": [3, 5, 8], "doe": [3, 5], "mandatori": [3, 5, 8], "arg": [3, 5, 8], "str": [3, 5, 8], "hug": [3, 8], "face": [3, 8], "core": [3, 5], "list": [3, 5, 8], "id": [3, 5, 8], "len": [3, 5, 8], "multipl": [3, 5, 8], "setup": [3, 5, 8], "none": [3, 5, 8], "text": [3, 5], "bool": [3, 5], "df": [3, 5], "fals": [3, 5, 8], "reduc": [3, 5], "chip": [3, 5], "full": [3, 5], "length": [3, 5, 8], "maximum": [3, 5], "context": [3, 5], "generation_len": [3, 5], "mxint8": [3, 5], "compress": [3, 5], "past": [3, 5], "local_model_dir": [3, 5], "hf_token": [3, 5], "login": 3, "access": [3, 5], "allow_mxint8_mdp_io": [3, 5], "mdp": [3, 5], "io": [3, 5], "traffic": [3, 5], "helper": 3, "tensor": [3, 5, 8], "slice": [3, 5], "find": [3, 5], "custom_io_file_path": [3, 5], "class": 5, "modeling_auto": 5, "continuous_batch": 5, "kwarg": 5, "manipul": 5, "causal": 5, "hub": 5, "although": 5, "recommend": 5, "nn": [5, 8], "weather": 5, "futur": 5, "later": 5, "whether": 5, "num_logits_to_keep": 5, "autotoken": 5, "num_hidden_lay": 5, "prefill_seq_len": 5, "num_devic": 5, "hi": 5, "classmethod": 5, "pretrained_model_name_or_path": 5, "serv": 5, "easiest": 5, "entri": 5, "point": 5, "interfac": 5, "except": 5, "vlm": 5, "load": 5, "internchatvl": 5, "automodel": 5, "pretrained_name_or_path": 5, "addit": 5, "consid": 5, "standard": 5, "sku": 5, "export_dir": 5, "compile_dir": 5, "kv_cache_batch_s": 5, "mxfp6_matmul": 5, "mxint8_kv_cach": 5, "compiler_opt": 5, "ha": 5, "yet": 5, "process": [5, 8], "less": 5, "ctx": 5, "rememb": 5, "mean": 5, "pretrainedtokenizerfast": [5, 8], "pretrainedtoken": [5, 8], "device_id": 5, "runtime_ai100": 5, "output": [5, 8], "until": [5, 8], "eo": [5, 8], "sequenti": 5, "cannot": 5, "divid": 5, "last": 5, "unfulfil": 5, "drop": 5, "union": [5, 8], "normal": 5, "ai_100": 5, "runtim": 5, "prepar": 5, "return_tensor": 5, "pt": 5, "seq_len": [5, 8], "ndarrai": [5, 8], "dict": [5, 8], "cloud_ai_100_feature_gener": 5, "A": 5, "session": [5, 8], "dictionari": 5, "pytorch_feature_gener": 5, "each": 5, "auto": [5, 8], "lora": 5, "current": [5, 8], "anoth": 5, "predibas": 5, "magicod": 5, "1024": 5, "math": 5, "load_adapt": 5, "gsm8k": 5, "set_adapt": 5, "model_id": 5, "adapter_nam": 5, "properti": 5, "active_adapt": 5, "finite_adapt": 5, "identifi": 5, "autopeftmodelforcausallm": 5, "suffix": 5, "hash": 5, "ai100": 5, "avoid": 5, "matmul": 5, "faster": 5, "convert": [5, 8], "aic_num_cor": 5, "num": 5, "convert_to_fp16": 5, "alloc": 5, "sequenc": [5, 8], "chunk": 5, "accord": 5, "space": 5, "generation_config": 5, "generationconfig": 5, "stopping_criteria": 5, "stoppingcriteria": 5, "streamer": 5, "basestream": 5, "input_id": [5, 8], "merg": 5, "stop": 5, "put": 5, "prompt_to_adapter_map": 5, "mistralai": 5, "gsm8k_id": 5, "download_adapt": 5, "adapter_model_id": 5, "adapter_weight": 5, "adapter_config": 5, "peftconfig": 5, "unload_adapt": 5, "deactiv": 5, "adpat": 5, "remov": 5, "unload": 5, "non": 5, "legaci": 5, "match": 5, "picker": 5, "onnxrt": [5, 8], "export_hf_to_cloud_ai_100": [5, 8], "model_kv": 5, "qeffbasemodel": 5, "onnx_dir_path": [5, 8], "seq_length": 5, "form_factor": 5, "tupl": 5, "alia": 5, "In": 5, "gate": 5, "bert": 5, "style": [5, 8], "form": 5, "factor": 5, "accept": 5, "compile_help": 5, "text_generation_infer": 5, "cloudai100execinfo": 5, "generated_text": 5, "generated_id": 5, "perf_metr": 5, "perfmetr": 5, "hold": 5, "inform": [5, 8], "metric": 5, "cloudai100execinfonew": 5, "numpi": [5, 8], "prefill_tim": 5, "float": 5, "decode_perf": 5, "total_perf": 5, "total_tim": 5, "total": 5, "calculate_lat": 5, "total_decoded_token": 5, "loop_start": 5, "decode_pause_tim": 5, "calcul": 5, "loop": 5, "count": 5, "paus": 5, "cloud_ai_100_exec_kv": 5, "enable_debug_log": 5, "stream": 5, "write_io_dir": 5, "autom": 5, "prompt_to_lora_id_map": 5, "write": 5, "associ": 5, "respect": 5, "exec_info": 5, "fix_prompt": 5, "adjust": 5, "get_compilation_dim": 5, "fetch": 5, "dimens": 5, "special": 5, "compris": 5, "particularli": 8, "suitabl": 8, "regress": 8, "task": 8, "involv": 8, "contextu": 8, "earlier": 8, "crucial": 8, "next": 8, "inclus": 8, "enhanc": 8, "computation": 8, "bertstyl": 8, "No": 8, "logic": 8, "everi": 8, "max_length": 8, "device_util": 8, "get_available_device_id": 8, "generate_input": 8, "inputhandl": 8, "prepare_ort_input": 8, "position_id": 8, "past_key_valu": 8, "prepare_pytorch_input": 8, "update_ort_input": 8, "ort_output": 8, "previou": 8, "iter": 8, "update_ort_output": 8, "updated_output": 8, "update_pytorch_input": 8, "pt_output": 8, "run_util": 8, "run_hf_model_on_pytorch": 8, "model_hf": 8, "run_hf_model_on_pytorch_cb": 8, "run_kv_model_on_cloud_ai_100": 8, "run_kv_model_on_ort": 8, "model_path": 8, "run_kv_model_on_pytorch": 8, "run_ort_sess": 8, "retain": 8, "capi": 8, "onnxruntime_inference_collect": 8, "inferencesess": 8}, "objects": {"QEfficient.cloud.execute": [[3, 0, 0, "-", "main"]], "QEfficient.cloud.export": [[3, 0, 0, "-", "main"]], "QEfficient.cloud.finetune": [[3, 0, 0, "-", "main"]], "QEfficient.cloud.infer": [[3, 0, 0, "-", "main"]], "QEfficient.compile": [[5, 0, 0, "-", "compile_helper"]], "QEfficient.compile.compile_helper": [[3, 0, 0, "-", "compile"]], "QEfficient.exporter": [[8, 0, 0, "-", "export_hf_to_cloud_ai_100"]], "QEfficient.exporter.export_hf_to_cloud_ai_100": [[8, 1, 1, "", "convert_to_cloud_bertstyle"], [8, 1, 1, "", "convert_to_cloud_kvstyle"], [5, 1, 1, "", "qualcomm_efficient_converter"]], "QEfficient.generation": [[5, 0, 0, "-", "text_generation_inference"]], "QEfficient.generation.text_generation_inference": [[5, 2, 1, "", "CloudAI100ExecInfo"], [5, 2, 1, "", "CloudAI100ExecInfoNew"], [5, 2, 1, "", "PerfMetrics"], [5, 1, 1, "", "calculate_latency"], [5, 1, 1, "", "cloud_ai_100_exec_kv"], [5, 1, 1, "", "fix_prompts"], [5, 1, 1, "", "get_compilation_dims"]], "QEfficient.peft.auto": [[5, 2, 1, "", "QEffAutoPeftModelForCausalLM"]], "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM": [[5, 3, 1, "", "active_adapter"], [5, 4, 1, "", "compile"], [5, 4, 1, "", "export"], [5, 4, 1, "", "from_pretrained"], [5, 4, 1, "", "generate"], [5, 4, 1, "", "load_adapter"], [5, 4, 1, "", "set_adapter"]], "QEfficient.peft.lora.auto": [[5, 2, 1, "", "QEffAutoLoraModelForCausalLM"]], "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM": [[5, 4, 1, "", "download_adapter"], [5, 4, 1, "", "export"], [5, 4, 1, "", "generate"], [5, 4, 1, "", "load_adapter"], [5, 4, 1, "", "unload_adapter"]], "QEfficient.transformers.models.modeling_auto": [[5, 2, 1, "", "QEFFAutoModel"], [5, 2, 1, "", "QEFFAutoModelForCausalLM"]], "QEfficient.transformers.models.modeling_auto.QEFFAutoModel": [[5, 4, 1, "", "cloud_ai_100_feature_generate"], [5, 4, 1, "", "compile"], [5, 4, 1, "", "export"], [5, 4, 1, "", "generate"], [5, 4, 1, "", "pytorch_feature_generate"]], "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM": [[5, 4, 1, "", "compile"], [5, 4, 1, "", "export"], [5, 4, 1, "", "from_pretrained"], [5, 4, 1, "", "generate"]], "QEfficient.utils": [[8, 0, 0, "-", "device_utils"], [8, 0, 0, "-", "generate_inputs"], [8, 0, 0, "-", "run_utils"]], "QEfficient.utils.device_utils": [[8, 1, 1, "", "get_available_device_id"]], "QEfficient.utils.generate_inputs": [[8, 2, 1, "", "InputHandler"]], "QEfficient.utils.generate_inputs.InputHandler": [[8, 4, 1, "", "prepare_ort_inputs"], [8, 4, 1, "", "prepare_pytorch_inputs"], [8, 4, 1, "", "update_ort_inputs"], [8, 4, 1, "", "update_ort_outputs"], [8, 4, 1, "", "update_pytorch_inputs"]], "QEfficient.utils.run_utils": [[8, 2, 1, "", "ApiRunner"]], "QEfficient.utils.run_utils.ApiRunner": [[8, 4, 1, "", "run_hf_model_on_pytorch"], [8, 4, 1, "", "run_hf_model_on_pytorch_CB"], [8, 4, 1, "", "run_kv_model_on_cloud_ai_100"], [8, 4, 1, "", "run_kv_model_on_ort"], [8, 4, 1, "", "run_kv_model_on_pytorch"], [8, 4, 1, "", "run_ort_session"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class", "3": "py:property", "4": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"], "3": ["py", "property", "Python property"], "4": ["py", "method", "Python method"]}, "titleterms": {"doc": 0, "build": 0, "preview": 0, "local": 0, "welcom": 1, "effici": [1, 2, 6, 7], "transform": [1, 2, 6, 7, 9], "document": 1, "get": 1, "start": 1, "instal": [1, 4, 6], "upgrad": 1, "quick": 1, "command": [1, 9], "line": [1, 9], "interfac": [1, 9], "us": [1, 2, 11], "cli": 1, "python": [1, 9], "api": [1, 2, 5, 8, 9, 10], "qaic": [1, 4], "finetun": [1, 3, 4, 9], "blog": 1, "refer": [1, 10], "train": [2, 4], "anywher": 2, "infer": [2, 3, 9], "qualcomm": [2, 7, 10], "cloud": [2, 3, 9, 10], "ai": [2, 9, 10], "100": [2, 9], "how": 2, "quadrupl": 2, "llm": 2, "decod": [2, 9], "perform": 2, "specul": [2, 9], "spd": 2, "microsc": [2, 10], "mx": [2, 10], "format": [2, 10], "power": 2, "acceler": 2, "larg": 2, "languag": 2, "model": [2, 9, 12], "sdk": [2, 6, 10], "2x": 2, "introduc": 2, "One": 2, "infinit": 2, "possibl": 2, "qeffici": [3, 9], "execut": [3, 5, 9], "compil": [3, 5, 9], "export": [3, 5, 9], "infra": 4, "dataset": 4, "detail": 4, "usag": 4, "singl": 4, "soc": 4, "distribut": 4, "ddp": 4, "visual": 4, "high": 5, "level": [5, 8], "qeffautomodelforcausallm": 5, "qeffautomodel": 5, "qeffautopeftmodelforcausallm": 5, "qeffautoloramodelforcausallm": 5, "pre": 6, "requisit": 6, "small": 6, "1": [6, 9], "download": [6, 9, 10], "app": 6, "2": [6, 9], "saniti": 6, "check": 6, "introduct": 7, "librari": 7, "low": 8, "convert_to_cloud_kvstyl": 8, "convert_to_cloud_bertstyl": 8, "util": 8, "qpc": 9, "storag": 9, "multi": 9, "qranium": 9, "continu": 9, "batch": 9, "qnn": 9, "optim": 9, "one": 9, "3": 9, "draft": 9, "base": 9, "home": 10, "user": 10, "guid": 10, "ocp": 10, "specif": 10, "github": 11, "repositori": 11, "valid": 12, "come": 12, "soon": 12, "apirunn": 8, "class": 8, "i": 8, "respons": 8, "run": 8}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 58}, "alltitles": {"Docs": [[0, "docs"]], "Build the docs": [[0, "build-the-docs"]], "Preview the docs locally": [[0, "preview-the-docs-locally"]], "Welcome to Efficient-Transformers Documentation!": [[1, "welcome-to-efficient-transformers-documentation"]], "Getting Started": [[1, null]], "Installation": [[1, null], [4, "installation"], [6, "installation"]], "Upgrade Efficient-Transformers": [[1, null]], "Quick start": [[1, null]], "Command Line Interface Use (CLI)": [[1, null]], "Python API": [[1, null], [9, "python-api"]], "QAIC Finetune": [[1, null]], "Blogs": [[1, null]], "Reference": [[1, null]], "Train anywhere, Infer on Qualcomm Cloud AI 100": [[2, "train-anywhere-infer-on-qualcomm-cloud-ai-100"]], "How to Quadruple LLM Decoding Performance with Speculative Decoding (SpD) and Microscaling (MX) Formats on Qualcomm\u00ae Cloud AI 100": [[2, "how-to-quadruple-llm-decoding-performance-with-speculative-decoding-spd-and-microscaling-mx-formats-on-qualcomm-cloud-ai-100"]], "Power-efficient acceleration for large language models \u2013 Qualcomm Cloud AI SDK": [[2, "power-efficient-acceleration-for-large-language-models-qualcomm-cloud-ai-sdk"]], "Qualcomm Cloud AI 100 Accelerates Large Language Model Inference by ~2x Using Microscaling (Mx) Formats": [[2, "qualcomm-cloud-ai-100-accelerates-large-language-model-inference-by-2x-using-microscaling-mx-formats"]], "Qualcomm Cloud AI Introduces Efficient Transformers: One API, Infinite Possibilities": [[2, "qualcomm-cloud-ai-introduces-efficient-transformers-one-api-infinite-possibilities"]], "Finetune Infra": [[4, "finetune-infra"]], "Finetuning": [[4, "finetuning"]], "Dataset Details": [[4, "dataset-details"]], "Usage": [[4, "usage"]], "Single SOC finetuning on QAIC": [[4, "single-soc-finetuning-on-qaic"]], "Distributed training(DDP) on QAIC": [[4, "distributed-training-ddp-on-qaic"]], "Visualization": [[4, "visualization"]], "Pre-requisites": [[6, "pre-requisites"]], "<small> 1. Download Apps SDK</small>": [[6, "download-apps-sdk"]], "<small> 2. Install Efficient-Transformers</small>": [[6, "install-efficient-transformers"]], "Sanity Check": [[6, "sanity-check"]], "Introduction Qualcomm efficient-transformers library": [[7, "introduction-qualcomm-efficient-transformers-library"]], "Transformed models and QPC storage": [[9, "transformed-models-and-qpc-storage"]], "Command Line Interface": [[9, "command-line-interface"]], "QEfficient.cloud.infer": [[9, "qefficient-cloud-infer"], [3, "module-QEfficient.cloud.infer.main"]], "QEfficient.cloud.execute": [[9, "qefficient-cloud-execute"], [3, "module-QEfficient.cloud.execute.main"]], "QEfficient.cloud.finetune": [[9, "qefficient-cloud-finetune"], [3, "qefficient-cloud-finetune"]], "Multi-Qranium Inference": [[9, "multi-qranium-inference"]], "Continuous Batching": [[9, "continuous-batching"]], "QNN Compilation": [[9, "qnn-compilation"]], "1.  Model download and Optimize for Cloud AI 100": [[9, "model-download-and-optimize-for-cloud-ai-100"]], "2. Export and Compile with one API": [[9, "export-and-compile-with-one-api"]], "3. Execute": [[9, "execute"]], "Draft-Based Speculative Decoding": [[9, "draft-based-speculative-decoding"]], "Qualcomm Cloud AI home": [[10, "qualcomm-cloud-ai-home"]], "Qualcomm Cloud AI SDK download": [[10, "qualcomm-cloud-ai-sdk-download"]], "Qualcomm Cloud AI API reference": [[10, "qualcomm-cloud-ai-api-reference"]], "User Guide": [[10, "user-guide"]], "OCP Microscaling Formats (MX) Specification": [[10, "ocp-microscaling-formats-mx-specification"]], "Using GitHub Repository": [[11, "using-github-repository"]], "Validated Models": [[12, "validated-models"]], "Models Coming Soon": [[12, "models-coming-soon"]], "High Level API": [[5, "high-level-api"]], "QEFFAutoModelForCausalLM": [[5, "qeffautomodelforcausallm"]], "QEFFAutoModel": [[5, "qeffautomodel"]], "QEffAutoPeftModelForCausalLM": [[5, "qeffautopeftmodelforcausallm"]], "QEffAutoLoraModelForCausalLM": [[5, "qeffautoloramodelforcausallm"]], "export": [[5, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "compile": [[5, "module-QEfficient.compile.compile_helper"]], "Execute": [[5, "module-QEfficient.generation.text_generation_inference"]], "Low Level API": [[8, "low-level-api"]], "convert_to_cloud_kvstyle": [[8, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "convert_to_cloud_bertstyle": [[8, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "utils": [[8, "module-QEfficient.utils.device_utils"]], "ApiRunner class is responsible for running:": [[8, "apirunner-class-is-responsible-for-running"]], "QEfficient.cloud.compile": [[3, "qefficient-cloud-compile"]], "QEfficient.cloud.export": [[3, "qefficient-cloud-export"]]}, "indexentries": {"qefficient.cloud.execute.main": [[3, "module-QEfficient.cloud.execute.main"]], "qefficient.cloud.export.main": [[3, "module-QEfficient.cloud.export.main"]], "qefficient.cloud.finetune.main": [[3, "module-QEfficient.cloud.finetune.main"]], "qefficient.cloud.infer.main": [[3, "module-QEfficient.cloud.infer.main"]], "qefficient.compile.compile_helper.compile": [[3, "module-QEfficient.compile.compile_helper.compile"]], "module": [[3, "module-QEfficient.cloud.execute.main"], [3, "module-QEfficient.cloud.export.main"], [3, "module-QEfficient.cloud.finetune.main"], [3, "module-QEfficient.cloud.infer.main"], [3, "module-QEfficient.compile.compile_helper.compile"]]}})
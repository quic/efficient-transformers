Search.setIndex({"docnames": ["README", "index", "source/blogs", "source/cli_api", "source/finetune", "source/hl_api", "source/installation", "source/introduction", "source/ll_api", "source/quick_start", "source/reference", "source/upgrade", "source/validate"], "filenames": ["README.md", "index.md", "source/blogs.md", "source/cli_api.md", "source/finetune.md", "source/hl_api.md", "source/installation.md", "source/introduction.md", "source/ll_api.md", "source/quick_start.md", "source/reference.md", "source/upgrade.md", "source/validate.md"], "titles": ["Docs", "Welcome to Efficient-Transformers Documentation!", "Train anywhere, Infer on Qualcomm Cloud AI 100", "<code class=\"docutils literal notranslate\"><span class=\"pre\">QEfficient.cloud.infer</span></code>", "Finetune Infra", "High Level API", "Pre-requisites", "Introduction Qualcomm <code class=\"docutils literal notranslate\"><span class=\"pre\">efficient-transformers</span></code> library", "Low Level API", "Transformed models and QPC storage", "Qualcomm Cloud AI home", "Using GitHub Repository", "Validated Models"], "terms": {"thi": [0, 3, 4, 5, 7, 8, 9, 11], "directori": [0, 4, 5, 6, 9], "contain": [0, 5, 9], "instruct": [0, 7, 12], "static": 0, "html": 0, "document": [0, 7], "base": [0, 1, 5, 7, 8, 12], "sphinx": 0, "instal": [0, 11], "packag": [0, 3, 5], "requir": [0, 5, 6, 9, 11], "pip": [0, 4, 11], "r": [0, 12], "txt": [0, 3, 9], "And": [0, 8], "chang": [0, 7, 9], "folder": [0, 9], "cd": 0, "To": [0, 4, 7, 9], "specif": [0, 1, 5], "branch": 0, "m": [0, 3, 4, 5, 9, 11], "option": [0, 3, 5, 9], "all": [0, 5, 8, 12], "support": [0, 5, 6, 7, 9, 12], "multivers": 0, "python": [0, 3, 4, 5, 6, 11], "http": [0, 4, 9, 11], "server": 0, "you": [0, 4, 5, 6, 9], "can": [0, 4, 5, 6, 7, 9], "visit": [0, 4], "page": [0, 5], "your": [0, 5, 9], "web": 0, "browser": 0, "url": [0, 4], "localhost": 0, "8080": 0, "introduct": 1, "qualcomm": 1, "librari": [1, 6, 9], "valid": [1, 9, 11], "model": [1, 3, 4, 5, 6, 7, 8, 11], "come": [1, 5, 7], "soon": [1, 3, 5, 7], "pre": [1, 5, 7, 9], "requisit": 1, "1": [1, 3, 4, 5, 7, 8, 12], "download": [1, 3, 4, 5], "app": [1, 3], "sdk": [1, 3, 5, 9, 11], "2": [1, 4, 5, 7, 12], "saniti": 1, "check": [1, 3, 5, 8, 9], "github": 1, "repositori": [1, 4], "qpc": [1, 3, 5, 8], "storag": 1, "qeffici": [1, 4, 5, 6, 8, 11], "cloud": [1, 4, 5, 6, 7, 8], "infer": [1, 5, 7], "execut": [1, 6, 7], "multi": [1, 6], "qranium": 1, "continu": [1, 3, 5, 7, 12], "batch": [1, 3, 5, 7, 12], "optim": [1, 7], "ai": [1, 3, 5, 6, 7, 8], "100": [1, 3, 5, 6, 7, 8], "export": [1, 4, 7, 8], "compil": [1, 7, 8], "one": [1, 5, 8], "3": [1, 4, 5, 7, 11, 12], "draft": 1, "specul": [1, 5, 7], "decod": [1, 5, 7, 8], "high": [1, 9], "level": [1, 3, 4, 9], "qeffautomodelforcausallm": [1, 3, 7, 8, 9], "qeffautomodel": 1, "qeffautopeftmodelforcausallm": 1, "qeffautoloramodelforcausallm": 1, "low": [1, 5], "convert_to_cloud_kvstyl": 1, "convert_to_cloud_bertstyl": [1, 5], "util": [1, 5, 6, 9], "infra": 1, "dataset": [1, 9], "detail": [1, 5, 9], "usag": [1, 5, 7], "train": [1, 7], "anywher": [1, 7], "how": [1, 7], "quadrupl": 1, "llm": [1, 7, 9], "perform": [1, 5, 7], "spd": 1, "microsc": 1, "mx": 1, "format": [1, 3, 5], "power": [1, 9], "acceler": [1, 4], "larg": 1, "languag": [1, 5, 9], "2x": 1, "introduc": 1, "One": 1, "infinit": 1, "possibl": [1, 5], "home": 1, "user": [1, 7, 9], "guid": 1, "ocp": 1, "click": 2, "here": [2, 5, 7], "us": [3, 4, 5, 6, 7, 8, 9], "bash": [3, 9], "termin": [3, 9], "els": [3, 9], "zsh": [3, 9], "device_group": [3, 5, 8, 9], "should": [3, 5, 9], "singl": [3, 9], "quot": [3, 9], "e": [3, 4, 9], "g": [3, 9], "0": [3, 4, 5, 9], "given": [3, 5, 8], "config": [3, 4, 5, 8, 9], "alreadi": [3, 9], "exist": [3, 6, 9], "doe": [3, 5], "jump": [3, 9], "onnx": [3, 5, 7, 8, 9], "file": [3, 5, 8, 9], "true": [3, 4, 5, 9], "hf": [3, 9, 12], "cach": [3, 5, 8, 9], "start": [3, 5, 6], "transform": [3, 5, 8, 11], "4": [3, 4, 7], "mandatori": [3, 5, 8], "arg": [3, 5, 8], "model_nam": [3, 4, 5, 8, 9], "str": [3, 5, 8], "hug": [3, 8], "face": [3, 8], "card": [3, 5, 6, 7, 8, 9], "name": [3, 5, 8, 9, 12], "exampl": [3, 4, 7, 8, 9], "gpt2": [3, 5, 8, 9, 12], "num_cor": [3, 5, 9], "int": [3, 5, 8, 9], "number": [3, 4, 5, 9], "core": [3, 5], "list": [3, 5, 8], "devic": [3, 4, 5, 6, 7, 8, 9], "id": [3, 5, 8], "If": [3, 5, 6, 9], "len": [3, 5, 8], "multipl": [3, 5, 8], "setup": [3, 5, 8], "i": [3, 4, 5, 6, 7, 9], "enabl": [3, 4, 5, 6, 7, 8, 9], "default": [3, 5, 9], "none": [3, 5, 8, 9], "prompt": [3, 5, 8, 9], "sampl": [3, 5, 7, 9], "text": [3, 5], "gener": [3, 5, 8, 9], "prompts_txt_file_path": [3, 5, 9], "path": [3, 5, 6, 7, 8, 9], "input": [3, 5, 8, 9], "aic_enable_depth_first": [3, 5, 9], "bool": [3, 5], "df": [3, 5], "memori": [3, 5, 9], "size": [3, 5, 9], "fals": [3, 5, 8, 9], "mo": [3, 5, 9], "effort": [3, 5, 9], "reduc": [3, 5], "chip": [3, 5], "batch_siz": [3, 5, 8, 9], "full_batch_s": [3, 5, 8, 9], "set": [3, 4, 5, 9], "full": [3, 5], "mode": [3, 4, 5], "prompt_len": [3, 5, 8, 9], "length": [3, 5, 8], "32": [3, 5, 9], "ctx_len": [3, 5, 8, 9], "maximum": [3, 5], "context": [3, 5], "128": [3, 5, 9], "generation_len": [3, 5], "token": [3, 5, 8, 9], "mxfp6": [3, 5, 9], "precis": [3, 5, 7], "mxint8": [3, 5], "compress": [3, 5], "present": [3, 5, 9], "past": [3, 5], "kv": [3, 5, 8, 9], "customio": [3, 5, 9], "local_model_dir": [3, 5], "custom": [3, 5, 9], "weight": [3, 5, 7], "cache_dir": [3, 5, 9], "dir": [3, 5, 9], "where": [3, 8, 9], "huggingfac": [3, 5, 7, 8, 9], "ar": [3, 5, 6, 7, 9], "store": [3, 5, 6, 9], "hf_token": [3, 5], "login": 3, "access": [3, 5], "privat": [3, 4], "repo": [3, 11], "allow_mxint8_mdp_io": [3, 5], "allow": [3, 5, 7], "mdp": [3, 5], "io": [3, 5], "traffic": [3, 5], "enable_qnn": [3, 5, 9], "qnn": [3, 5, 9], "qnn_config": [3, 5, 9], "paramet": [3, 4, 5, 9], "helper": 3, "function": [3, 5, 7, 8, 12], "cli": [3, 4, 9], "run": [3, 4, 5, 6, 9], "platform": [3, 5, 6, 9], "qpc_path": [3, 5, 8, 9], "binari": [3, 5, 9], "after": [3, 5, 6, 8], "constant": [3, 5, 9], "save": [3, 5, 8, 9], "tensor": [3, 5, 8], "slice": [3, 5], "configur": [3, 4, 5, 9], "pass": [3, 5, 8, 9], "deprec": [3, 5], "replac": [3, 5, 7], "onnx_path": [3, 5], "find": [3, 5], "custom_io_file_path": [3, 5], "string": [3, 5, 9], "return": [3, 5, 7, 8], "provid": [4, 5, 7, 9], "infrastructur": 4, "differ": [4, 5, 9], "hardwar": [4, 5, 9], "same": [4, 5, 9, 11], "gpu": 4, "flag": [4, 5, 9], "along": [4, 9], "eager": [4, 9], "env": [4, 11], "variabl": [4, 9], "hf_datasets_trust_remote_cod": 4, "get": 4, "hw": [4, 7], "trace": 4, "debug": [4, 5], "log": [4, 5], "qaic_delay_sem_wait_at_copi": 4, "For": [4, 7, 9], "profil": 4, "qaic_device_log_level": 4, "qaic_debug": 4, "understand": 4, "cpu": [4, 5], "fallback": 4, "op": 4, "alpaca": 4, "link": 4, "place": 4, "under": [4, 6, 9], "make": [4, 7, 8, 9], "sure": [4, 9], "updat": [4, 5, 7, 8], "accordingli": 4, "wget": 4, "c": [4, 6], "raw": 4, "githubusercont": 4, "com": [4, 11], "tatsu": 4, "lab": 4, "stanford_alpaca": 4, "ref": 4, "head": 4, "main": 4, "alpaca_data": 4, "json": [4, 5, 9], "p": 4, "grammar": 4, "datasets_grammar": 4, "insid": 4, "releas": [4, 7], "docker": 4, "ld_library_path": 4, "opt": [4, 5, 6], "qti": [4, 5, 6], "aic": [4, 5, 6], "dev": [4, 6], "lib": [4, 9], "x86_64": 4, "extra": [4, 5, 9], "index": 4, "pytorch": [4, 5, 8, 9], "org": 4, "whl": 4, "meta": [4, 7, 9], "llama": [4, 5, 7, 9, 12], "1b": [4, 7, 9, 12], "also": [4, 9], "variou": [4, 9], "more": [4, 7, 8, 9], "checkout": [4, 9], "py": 4, "below": [4, 5, 9], "command": [4, 6, 12], "line": [4, 5, 6], "peft": [4, 5, 7, 9], "output_dir": [4, 9], "sam": [4, 9], "num_epoch": [4, 9], "context_length": [4, 9], "256": [4, 9], "qaic_visible_devic": 4, "torchrun": 4, "nproc": 4, "per": 4, "node": [4, 5], "enable_ddp": 4, "dist_backend": 4, "qccl": 4, "worker": 4, "local": [4, 5, 7, 9], "give": 5, "an": [5, 9], "overview": 5, "about": 5, "might": 5, "need": [5, 7, 9], "integr": [5, 6], "applic": [5, 7], "class": 5, "modeling_auto": 5, "modul": [5, 7, 8], "continuous_batch": 5, "is_tlm": [5, 8, 9], "kwarg": 5, "sourc": [5, 6, 7, 8, 11], "The": [5, 8, 9], "qeff": [5, 6], "design": [5, 9], "manipul": 5, "ani": [5, 9], "causal": 5, "from": [5, 7, 8, 9], "hub": 5, "although": 5, "initi": [5, 7, 9], "directli": [5, 9], "we": [5, 7, 9], "highli": [5, 7], "recommend": 5, "from_pretrain": [5, 9], "method": [5, 6], "nn": [5, 8], "weather": 5, "futur": 5, "later": 5, "whether": 5, "target": [5, 9], "num_logits_to_keep": 5, "arrai": [5, 9], "have": [5, 9, 11], "fed": [5, 9], "control": [5, 9], "logit": [5, 7, 8], "dure": [5, 7, 9], "prefil": [5, 8, 9], "import": [5, 6, 9], "num_hidden_lay": 5, "prefill_seq_len": 5, "1024": 5, "hi": 5, "classmethod": 5, "pretrained_model_name_or_path": 5, "serv": 5, "easiest": 5, "entri": 5, "point": 5, "interfac": 5, "similar": [5, 9], "automodelforcausallm": [5, 9], "onc": [5, 9], "other": [5, 7, 9], "object": [5, 8, 9], "pretrained_name_or_path": 5, "addit": 5, "argument": [5, 9], "now": [5, 7, 9], "6": 5, "consid": 5, "standard": 5, "sku": 5, "export_dir": 5, "torch": [5, 8, 9], "graph": [5, 7, 9], "compile_dir": 5, "num_devic": 5, "16": [5, 9], "mxfp6_matmul": 5, "mxint8_kv_cach": 5, "num_speculative_token": [5, 9], "compiler_opt": 5, "found": [5, 9], "exec": [5, 6], "qaic": [5, 6, 9], "ha": 5, "been": [5, 9, 11], "yet": 5, "handl": [5, 7], "process": [5, 8], "take": [5, 7, 9], "less": 5, "ctx": 5, "rememb": 5, "mean": 5, "pretrainedtokenizerfast": [5, 8], "pretrainedtoken": [5, 8], "device_id": 5, "runtime_ai100": 5, "output": [5, 8], "until": [5, 8], "eo": [5, 8], "sequenti": 5, "cannot": 5, "divid": 5, "last": 5, "unfulfil": 5, "drop": 5, "case": [5, 9], "normal": 5, "ai_100": 5, "runtim": 5, "autotoken": 5, "automodel": 5, "prepar": 5, "my": [5, 9], "return_tensor": 5, "pt": 5, "seq_len": [5, 8], "ndarrai": [5, 8], "union": [5, 8], "np": [5, 9], "eq_len": 5, "sequenc": [5, 8], "dict": [5, 8], "cloud_ai_100_feature_gener": 5, "featur": [5, 9], "A": 5, "session": [5, 8], "dictionari": 5, "pytorch_feature_gener": 5, "each": 5, "auto": [5, 8], "load": 5, "adapt": [5, 7, 12], "onli": [5, 7, 9], "lora": 5, "current": [5, 8], "anoth": 5, "predibas": 5, "magicod": 5, "code": [5, 7, 9], "math": 5, "load_adapt": 5, "gsm8k": 5, "set_adapt": 5, "model_id": 5, "adapter_nam": 5, "new": [5, 7, 9], "properti": 5, "active_adapt": 5, "activ": [5, 6, 11], "finite_adapt": 5, "finit": [5, 7], "pleas": [5, 9], "refer": [5, 9], "identifi": 5, "autopeftmodelforcausallm": 5, "specifi": [5, 9], "suffix": 5, "hash": 5, "correspond": [5, 9], "ai100": 5, "ad": [5, 7, 9], "avoid": 5, "reus": [5, 9], "matmul": 5, "faster": 5, "param": [5, 9], "convert": [5, 8], "aic_num_cor": 5, "num": 5, "convert_to_fp16": 5, "fp16": [5, 9], "alloc": 5, "chunk": 5, "accord": 5, "space": 5, "generation_config": 5, "generationconfig": 5, "stopping_criteria": 5, "stoppingcriteria": 5, "streamer": 5, "basestream": 5, "input_id": [5, 8], "merg": 5, "stop": 5, "put": 5, "while": [5, 9], "mistral": [5, 7, 12], "mix": [5, 7], "prompt_to_adapter_map": 5, "mistralai": 5, "7b": [5, 7, 12], "v0": [5, 7, 12], "gsm8k_id": 5, "download_adapt": 5, "adapter_model_id": 5, "adapter_weight": 5, "adapter_config": 5, "peftconfig": 5, "unload_adapt": 5, "deactiv": 5, "adpat": 5, "remov": 5, "unload": 5, "don": [5, 9], "t": [5, 9], "non": 5, "legaci": 5, "match": 5, "onnxrt": [5, 8], "export_hf_to_cloud_ai_100": [5, 8], "qualcomm_efficient_convert": [5, 9], "model_kv": 5, "qeffbasemodel": 5, "onnx_dir_path": [5, 8], "seq_length": 5, "form_factor": 5, "tupl": 5, "alia": 5, "In": 5, "gate": 5, "bert": 5, "style": [5, 8], "form": 5, "factor": 5, "accept": 5, "base_path": 5, "onnx_model_path": 5, "sinc": 5, "version": [5, 6], "19": 5, "instead": [5, 9], "compile_help": 5, "o": [5, 6, 9], "join": [5, 9], "14": [5, 9], "text_generation_infer": 5, "cloudai100execinfo": 5, "generated_text": 5, "generated_id": 5, "perf_metr": 5, "perfmetr": 5, "hold": 5, "inform": [5, 8], "": [5, 7], "metric": 5, "prefill_tim": 5, "float": 5, "decode_perf": 5, "total_perf": 5, "total_tim": 5, "time": [5, 8, 9], "total": 5, "calculate_lat": 5, "total_decoded_token": 5, "loop_start": 5, "end": [5, 9], "decode_pause_tim": 5, "calcul": 5, "latenc": [5, 9], "loop": 5, "count": 5, "stage": [5, 8, 9], "paus": 5, "cloud_ai_100_exec_kv": 5, "enable_debug_log": 5, "stream": 5, "write_io_dir": 5, "autom": 5, "prompt_to_lora_id_map": 5, "picker": 5, "which": [5, 7, 9], "them": [5, 9], "write": 5, "print": [5, 6, 9], "stat": [5, 9], "map": [5, 7], "associ": 5, "respect": 5, "exec_info": 5, "fix_prompt": 5, "adjust": 5, "get_compilation_dim": 5, "fetch": 5, "dimens": 5, "special": 5, "comput": [5, 8, 9], "compris": 5, "system": 6, "linux": 6, "ubuntu": 6, "rhel": 6, "aw": 6, "shard": 6, "uninstal": 6, "sudo": 6, "sh": 6, "script": 6, "root": 6, "permiss": 6, "bin": [6, 11], "On": 6, "success": 6, "content": 6, "follow": [6, 9], "tool": 6, "appli": 6, "chmod": 6, "x": 6, "hexagon_tool": 6, "abov": [6, 9], "correctli": 6, "__version__": 6, "successfulli": 6, "good": 6, "go": 6, "ahead": [6, 9], "deploi": 6, "develop": [7, 9], "centric": 7, "toolchain": 7, "reimplement": 7, "block": 7, "wide": 7, "rang": 7, "architectur": [7, 8, 9], "easi": 7, "deploy": 7, "care": 7, "implement": 7, "comprehens": 7, "inspir": 7, "upon": [7, 9], "typic": 7, "retent": [7, 8], "intermedi": 7, "state": [7, 8], "read": 7, "kei": 7, "oper": 7, "lower": 7, "some": 7, "mathemat": 7, "equival": 7, "backend": 7, "underflow": 7, "overflow": [7, 9], "patcher": 7, "origin": [7, 8, 9], "demo": [7, 9], "notebook": [7, 9], "unit": 7, "test": 7, "templat": 7, "latest": 7, "popular": 7, "11": 7, "2024": 7, "tlm": [7, 9], "than": 7, "70b": [7, 9, 12], "3b": [7, 12], "09": 7, "awq": 7, "gptq": 7, "bit": 7, "quantiz": 7, "gemma": [7, 12], "famili": 7, "codegemma": [7, 12], "8b": [7, 12], "granit": 7, "20b": 7, "8k": 7, "starcoder1": [7, 12], "15b": [7, 12], "08": 7, "techniqu": [7, 9], "jai": [7, 12], "13b": [7, 12], "chat": [7, 9, 12], "06": 7, "gpt": [7, 12], "j": [7, 12], "6b": [7, 12], "qwen2": [7, 12], "5b": [7, 12], "starcoder2": [7, 12], "phi3": [7, 12], "mini": [7, 12], "4k": [7, 12], "codestr": [7, 12], "22b": [7, 12], "vicuna": [7, 12], "v1": [7, 9, 12], "5": [7, 12], "05": 7, "mixtral": [7, 12], "8x7b": [7, 12], "04": 7, "seamless": 7, "qeff_model": [8, 9], "approach": [8, 9], "particularli": 8, "suitabl": 8, "regress": 8, "task": 8, "involv": 8, "contextu": 8, "earlier": 8, "crucial": 8, "predict": [8, 9], "next": 8, "inclus": 8, "enhanc": 8, "effici": [8, 9, 11], "computation": 8, "bertstyl": 8, "No": 8, "separ": [8, 9], "logic": 8, "everi": 8, "max_length": 8, "device_util": 8, "get_available_device_id": 8, "avail": [8, 9], "generate_input": 8, "inputhandl": 8, "prepare_ort_input": 8, "creat": [8, 9, 11], "numpi": 8, "position_id": 8, "past_key_valu": 8, "prepare_pytorch_input": 8, "update_ort_input": 8, "ort_output": 8, "previou": 8, "iter": 8, "update_ort_output": 8, "updated_output": 8, "update_pytorch_input": 8, "pt_output": 8, "run_util": 8, "run_hf_model_on_pytorch": 8, "model_hf": 8, "run_hf_model_on_pytorch_cb": 8, "run_kv_model_on_cloud_ai_100": 8, "run_kv_model_on_ort": 8, "model_path": 8, "onnxruntim": [8, 9], "run_kv_model_on_pytorch": 8, "run_ort_sess": 8, "retain": 8, "capi": 8, "onnxruntime_inference_collect": 8, "inferencesess": 8, "wa": 9, "goal": 9, "onboard": 9, "straightforward": 9, "leverag": 9, "complet": 9, "achiev": 9, "abstract": 9, "awai": 9, "complex": 9, "offer": 9, "simpler": 9, "thei": 9, "re": 9, "ideal": 9, "quick": 9, "prototyp": 9, "technologi": 9, "want": 9, "minim": 9, "granular": 9, "when": 9, "necessari": 9, "By": 9, "program": 9, "readi": 9, "qeff_cach": 9, "environ": 9, "qeff_hom": 9, "its": 9, "xdg_cache_hom": 9, "note": [9, 12], "rerout": 9, "entir": 9, "includ": 9, "neither": 9, "nor": 9, "e2": 9, "model_card": 9, "doc": 9, "It": 9, "skip": 9, "second": 9, "automat": 9, "creation": 9, "out": 9, "help": 9, "pipe": 9, "symbol": 9, "flat": 9, "earth": 9, "theori": 9, "belief": 9, "sun": 9, "rise": 9, "lot": 9, "qnn_sdk_root": 9, "qnn_sdk_folder": 9, "add": 9, "wish": 9, "overrid": 9, "without": 9, "With": 9, "first": 9, "precompil": 9, "qpc_16cores_1bs_32pl_128cl_1devices_mxfp6": 9, "predefin": 9, "pipelin": 9, "subsect": 9, "mq": 9, "just": 9, "group": 9, "fly": 9, "soc": 9, "salesforc": 9, "codegen": 9, "2b": [9, 12], "mono": 9, "def": 9, "fibonacci": 9, "n": 9, "step": 9, "model_card_nam": 9, "pick": 9, "qpc_16cores_1bs_32pl_128cl_2devices_mxfp6": 9, "binary_search": 9, "k": 9, "disabl": 9, "like": 9, "again": 9, "full_batch_size_valu": 9, "regular": 9, "wai": 9, "tinyllama": 9, "tinyllama_v1": 9, "fall": 9, "work": [9, 11], "fine": 9, "rais": 9, "issu": 9, "troubl": 9, "uncom": 9, "appropri": 9, "transformers_cach": 9, "mnt": 9, "workspac": 9, "hf_cach": 9, "root_dir": 9, "dirnam": 9, "abspath": 9, "tmp": 9, "locat": 9, "co": 9, "xl": 9, "f": 9, "verifi": 9, "modifi": 9, "framework": 9, "both": 9, "variat": 9, "clip": 9, "v": 9, "Then": 9, "yaml": 9, "generated_qpc_path": 9, "qnn_config_file_path": 9, "benchmark": 9, "tok": 9, "sec": 9, "post": 9, "greedi": 9, "small": 9, "dlm": 9, "autoregress": 9, "what": 9, "would": 9, "benefici": 9, "phase": 9, "bound": 9, "thu": 9, "resourc": 9, "our": 9, "tlm_name": 9, "dlm_name": 9, "instanti": 9, "becaus": 9, "slight": 9, "defin": 9, "actual": 9, "As": 9, "warn": 11, "compat": 11, "upgrad": 11, "mai": 11, "result": 11, "certain": 11, "becom": 11, "incompat": 11, "virtual": 11, "10": 11, "python3": 11, "venv": 11, "qeff_env": 11, "u": 11, "clone": 11, "git": 11, "quic": 11, "codellama": 12, "34b": 12, "falcon": 12, "40b": 12, "9b": 12, "27b": 12, "mpt": 12, "baichuan2": 12, "cohereforai": 12, "c4ai": 12, "v01": 12, "chatglm2": 12, "databrick": 12, "dbrx": 12, "405b": 12, "11b": 12, "vision": 12, "90b": 12}, "objects": {"QEfficient.cloud.execute": [[3, 0, 0, "-", "main"]], "QEfficient.cloud.export": [[3, 0, 0, "-", "main"]], "QEfficient.cloud.infer": [[3, 0, 0, "-", "main"]], "QEfficient.compile": [[5, 0, 0, "-", "compile_helper"]], "QEfficient.compile.compile_helper": [[5, 1, 1, "", "compile"], [3, 0, 0, "-", "compile"]], "QEfficient.exporter": [[8, 0, 0, "-", "export_hf_to_cloud_ai_100"]], "QEfficient.exporter.export_hf_to_cloud_ai_100": [[8, 1, 1, "", "convert_to_cloud_bertstyle"], [8, 1, 1, "", "convert_to_cloud_kvstyle"], [5, 1, 1, "", "qualcomm_efficient_converter"]], "QEfficient.generation": [[5, 0, 0, "-", "text_generation_inference"]], "QEfficient.generation.text_generation_inference": [[5, 2, 1, "", "CloudAI100ExecInfo"], [5, 2, 1, "", "PerfMetrics"], [5, 1, 1, "", "calculate_latency"], [5, 1, 1, "", "cloud_ai_100_exec_kv"], [5, 1, 1, "", "fix_prompts"], [5, 1, 1, "", "get_compilation_dims"]], "QEfficient.peft.auto": [[5, 2, 1, "", "QEffAutoPeftModelForCausalLM"]], "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM": [[5, 3, 1, "", "active_adapter"], [5, 4, 1, "", "compile"], [5, 4, 1, "", "export"], [5, 4, 1, "", "from_pretrained"], [5, 4, 1, "", "generate"], [5, 4, 1, "", "load_adapter"], [5, 4, 1, "", "set_adapter"]], "QEfficient.peft.lora.auto": [[5, 2, 1, "", "QEffAutoLoraModelForCausalLM"]], "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM": [[5, 4, 1, "", "download_adapter"], [5, 4, 1, "", "export"], [5, 4, 1, "", "generate"], [5, 4, 1, "", "load_adapter"], [5, 4, 1, "", "unload_adapter"]], "QEfficient.transformers.models.modeling_auto": [[5, 2, 1, "", "QEFFAutoModel"], [5, 2, 1, "", "QEFFAutoModelForCausalLM"]], "QEfficient.transformers.models.modeling_auto.QEFFAutoModel": [[5, 4, 1, "", "cloud_ai_100_feature_generate"], [5, 4, 1, "", "compile"], [5, 4, 1, "", "export"], [5, 4, 1, "", "generate"], [5, 4, 1, "", "pytorch_feature_generate"]], "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM": [[5, 4, 1, "", "compile"], [5, 4, 1, "", "export"], [5, 4, 1, "", "from_pretrained"], [5, 4, 1, "", "generate"]], "QEfficient.utils": [[8, 0, 0, "-", "device_utils"], [8, 0, 0, "-", "generate_inputs"], [8, 0, 0, "-", "run_utils"]], "QEfficient.utils.device_utils": [[8, 1, 1, "", "get_available_device_id"]], "QEfficient.utils.generate_inputs": [[8, 2, 1, "", "InputHandler"]], "QEfficient.utils.generate_inputs.InputHandler": [[8, 4, 1, "", "prepare_ort_inputs"], [8, 4, 1, "", "prepare_pytorch_inputs"], [8, 4, 1, "", "update_ort_inputs"], [8, 4, 1, "", "update_ort_outputs"], [8, 4, 1, "", "update_pytorch_inputs"]], "QEfficient.utils.run_utils": [[8, 2, 1, "", "ApiRunner"]], "QEfficient.utils.run_utils.ApiRunner": [[8, 4, 1, "", "run_hf_model_on_pytorch"], [8, 4, 1, "", "run_hf_model_on_pytorch_CB"], [8, 4, 1, "", "run_kv_model_on_cloud_ai_100"], [8, 4, 1, "", "run_kv_model_on_ort"], [8, 4, 1, "", "run_kv_model_on_pytorch"], [8, 4, 1, "", "run_ort_session"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class", "3": "py:property", "4": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"], "3": ["py", "property", "Python property"], "4": ["py", "method", "Python method"]}, "titleterms": {"doc": 0, "build": 0, "preview": 0, "local": 0, "welcom": 1, "effici": [1, 2, 6, 7], "transform": [1, 2, 6, 7, 9], "document": 1, "get": 1, "start": 1, "instal": [1, 4, 6], "upgrad": 1, "quick": 1, "command": [1, 9], "line": [1, 9], "interfac": [1, 9], "us": [1, 2, 11], "cli": 1, "python": [1, 9], "api": [1, 2, 5, 8, 9, 10], "qaic": [1, 4], "finetun": [1, 4, 9], "blog": 1, "refer": [1, 10], "train": [2, 4], "anywher": 2, "infer": [2, 3, 9], "qualcomm": [2, 7, 10], "cloud": [2, 3, 9, 10], "ai": [2, 9, 10], "100": [2, 9], "how": 2, "quadrupl": 2, "llm": 2, "decod": [2, 9], "perform": 2, "specul": [2, 9], "spd": 2, "microsc": [2, 10], "mx": [2, 10], "format": [2, 10], "power": 2, "acceler": 2, "larg": 2, "languag": 2, "model": [2, 9, 12], "sdk": [2, 6, 10], "2x": 2, "introduc": 2, "One": 2, "infinit": 2, "possibl": 2, "qeffici": [3, 9], "execut": [3, 5, 9], "compil": [3, 5, 9], "export": [3, 5, 9], "infra": 4, "dataset": 4, "detail": 4, "usag": 4, "singl": 4, "soc": 4, "distribut": 4, "ddp": 4, "high": 5, "level": [5, 8], "qeffautomodelforcausallm": 5, "qeffautomodel": 5, "qeffautopeftmodelforcausallm": 5, "qeffautoloramodelforcausallm": 5, "pre": 6, "requisit": 6, "small": 6, "1": [6, 9], "download": [6, 9, 10], "app": 6, "2": [6, 9], "saniti": 6, "check": 6, "introduct": 7, "librari": 7, "low": 8, "convert_to_cloud_kvstyl": 8, "convert_to_cloud_bertstyl": 8, "util": 8, "apirunn": 8, "class": 8, "i": 8, "respons": 8, "run": 8, "qpc": 9, "storag": 9, "multi": 9, "qranium": 9, "continu": 9, "batch": 9, "optim": 9, "one": 9, "3": 9, "draft": 9, "base": 9, "home": 10, "user": 10, "guid": 10, "ocp": 10, "specif": 10, "github": 11, "repositori": 11, "valid": 12, "come": 12, "soon": 12}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 58}, "alltitles": {"Docs": [[0, "docs"]], "Build the docs": [[0, "build-the-docs"]], "Preview the docs locally": [[0, "preview-the-docs-locally"]], "Welcome to Efficient-Transformers Documentation!": [[1, "welcome-to-efficient-transformers-documentation"]], "Getting Started": [[1, null]], "Installation": [[1, null], [4, "installation"], [6, "installation"]], "Upgrade Efficient-Transformers": [[1, null]], "Quick start": [[1, null]], "Command Line Interface Use (CLI)": [[1, null]], "Python API": [[1, null], [9, "python-api"]], "QAIC Finetune": [[1, null]], "Blogs": [[1, null]], "Reference": [[1, null]], "Train anywhere, Infer on Qualcomm Cloud AI 100": [[2, "train-anywhere-infer-on-qualcomm-cloud-ai-100"]], "How to Quadruple LLM Decoding Performance with Speculative Decoding (SpD) and Microscaling (MX) Formats on Qualcomm\u00ae Cloud AI 100": [[2, "how-to-quadruple-llm-decoding-performance-with-speculative-decoding-spd-and-microscaling-mx-formats-on-qualcomm-cloud-ai-100"]], "Power-efficient acceleration for large language models \u2013 Qualcomm Cloud AI SDK": [[2, "power-efficient-acceleration-for-large-language-models-qualcomm-cloud-ai-sdk"]], "Qualcomm Cloud AI 100 Accelerates Large Language Model Inference by ~2x Using Microscaling (Mx) Formats": [[2, "qualcomm-cloud-ai-100-accelerates-large-language-model-inference-by-2x-using-microscaling-mx-formats"]], "Qualcomm Cloud AI Introduces Efficient Transformers: One API, Infinite Possibilities": [[2, "qualcomm-cloud-ai-introduces-efficient-transformers-one-api-infinite-possibilities"]], "QEfficient.cloud.infer": [[3, "module-QEfficient.cloud.infer.main"], [9, "qefficient-cloud-infer"]], "QEfficient.cloud.execute": [[3, "module-QEfficient.cloud.execute.main"], [9, "qefficient-cloud-execute"]], "QEfficient.cloud.compile": [[3, "qefficient-cloud-compile"]], "QEfficient.cloud.export": [[3, "qefficient-cloud-export"]], "Finetune Infra": [[4, "finetune-infra"]], "Finetuning": [[4, "finetuning"]], "Dataset Details": [[4, "dataset-details"]], "Usage": [[4, "usage"]], "Single SOC finetuning on QAIC": [[4, "single-soc-finetuning-on-qaic"]], "Distributed training(DDP) on QAIC": [[4, "distributed-training-ddp-on-qaic"]], "High Level API": [[5, "high-level-api"]], "QEFFAutoModelForCausalLM": [[5, "qeffautomodelforcausallm"]], "QEFFAutoModel": [[5, "qeffautomodel"]], "QEffAutoPeftModelForCausalLM": [[5, "qeffautopeftmodelforcausallm"]], "QEffAutoLoraModelForCausalLM": [[5, "qeffautoloramodelforcausallm"]], "export": [[5, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "compile": [[5, "module-QEfficient.compile.compile_helper"]], "Execute": [[5, "module-QEfficient.generation.text_generation_inference"]], "Pre-requisites": [[6, "pre-requisites"]], "<small> 1. Download Apps SDK</small>": [[6, "download-apps-sdk"]], "<small> 2. Install Efficient-Transformers</small>": [[6, "install-efficient-transformers"]], "Sanity Check": [[6, "sanity-check"]], "Introduction Qualcomm efficient-transformers library": [[7, "introduction-qualcomm-efficient-transformers-library"]], "Low Level API": [[8, "low-level-api"]], "convert_to_cloud_kvstyle": [[8, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "convert_to_cloud_bertstyle": [[8, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "utils": [[8, "module-QEfficient.utils.device_utils"]], "ApiRunner class is responsible for running:": [[8, "apirunner-class-is-responsible-for-running"]], "Transformed models and QPC storage": [[9, "transformed-models-and-qpc-storage"]], "Command Line Interface": [[9, "command-line-interface"]], "QEfficient.cloud.finetune": [[9, "qefficient-cloud-finetune"]], "Multi-Qranium Inference": [[9, "multi-qranium-inference"]], "Continuous Batching": [[9, "continuous-batching"]], "1.  Model download and Optimize for Cloud AI 100": [[9, "model-download-and-optimize-for-cloud-ai-100"]], "2. Export and Compile with one API": [[9, "export-and-compile-with-one-api"]], "3. Execute": [[9, "execute"]], "Draft-Based Speculative Decoding": [[9, "draft-based-speculative-decoding"]], "Qualcomm Cloud AI home": [[10, "qualcomm-cloud-ai-home"]], "Qualcomm Cloud AI SDK download": [[10, "qualcomm-cloud-ai-sdk-download"]], "Qualcomm Cloud AI API reference": [[10, "qualcomm-cloud-ai-api-reference"]], "User Guide": [[10, "user-guide"]], "OCP Microscaling Formats (MX) Specification": [[10, "ocp-microscaling-formats-mx-specification"]], "Using GitHub Repository": [[11, "using-github-repository"]], "Validated Models": [[12, "validated-models"]], "Models Coming Soon": [[12, "models-coming-soon"]]}, "indexentries": {"qefficient.cloud.execute.main": [[3, "module-QEfficient.cloud.execute.main"]], "qefficient.cloud.export.main": [[3, "module-QEfficient.cloud.export.main"]], "qefficient.cloud.infer.main": [[3, "module-QEfficient.cloud.infer.main"]], "qefficient.compile.compile_helper.compile": [[3, "module-QEfficient.compile.compile_helper.compile"]], "module": [[3, "module-QEfficient.cloud.execute.main"], [3, "module-QEfficient.cloud.export.main"], [3, "module-QEfficient.cloud.infer.main"], [3, "module-QEfficient.compile.compile_helper.compile"], [5, "module-QEfficient.compile.compile_helper"], [5, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"], [5, "module-QEfficient.generation.text_generation_inference"], [8, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"], [8, "module-QEfficient.utils.device_utils"], [8, "module-QEfficient.utils.generate_inputs"], [8, "module-QEfficient.utils.run_utils"]], "cloudai100execinfo (class in qefficient.generation.text_generation_inference)": [[5, "QEfficient.generation.text_generation_inference.CloudAI100ExecInfo"]], "perfmetrics (class in qefficient.generation.text_generation_inference)": [[5, "QEfficient.generation.text_generation_inference.PerfMetrics"]], "qeffautomodel (class in qefficient.transformers.models.modeling_auto)": [[5, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel"]], "qeffautomodelforcausallm (class in qefficient.transformers.models.modeling_auto)": [[5, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM"]], "qeffautoloramodelforcausallm (class in qefficient.peft.lora.auto)": [[5, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM"]], "qeffautopeftmodelforcausallm (class in qefficient.peft.auto)": [[5, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM"]], "qefficient.compile.compile_helper": [[5, "module-QEfficient.compile.compile_helper"]], "qefficient.exporter.export_hf_to_cloud_ai_100": [[5, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"], [8, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "qefficient.generation.text_generation_inference": [[5, "module-QEfficient.generation.text_generation_inference"]], "active_adapter (qefficient.peft.auto.qeffautopeftmodelforcausallm property)": [[5, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.active_adapter"]], "calculate_latency() (in module qefficient.generation.text_generation_inference)": [[5, "QEfficient.generation.text_generation_inference.calculate_latency"]], "cloud_ai_100_exec_kv() (in module qefficient.generation.text_generation_inference)": [[5, "QEfficient.generation.text_generation_inference.cloud_ai_100_exec_kv"]], "cloud_ai_100_feature_generate() (qefficient.transformers.models.modeling_auto.qeffautomodel method)": [[5, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel.cloud_ai_100_feature_generate"]], "compile() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[5, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.compile"]], "compile() (qefficient.transformers.models.modeling_auto.qeffautomodel method)": [[5, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel.compile"]], "compile() (qefficient.transformers.models.modeling_auto.qeffautomodelforcausallm method)": [[5, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.compile"]], "compile() (in module qefficient.compile.compile_helper)": [[5, "QEfficient.compile.compile_helper.compile"]], "download_adapter() (qefficient.peft.lora.auto.qeffautoloramodelforcausallm method)": [[5, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM.download_adapter"]], "export() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[5, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.export"]], "export() (qefficient.peft.lora.auto.qeffautoloramodelforcausallm method)": [[5, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM.export"]], "export() (qefficient.transformers.models.modeling_auto.qeffautomodel method)": [[5, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel.export"]], "export() (qefficient.transformers.models.modeling_auto.qeffautomodelforcausallm method)": [[5, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.export"]], "fix_prompts() (in module qefficient.generation.text_generation_inference)": [[5, "QEfficient.generation.text_generation_inference.fix_prompts"]], "from_pretrained() (qefficient.peft.auto.qeffautopeftmodelforcausallm class method)": [[5, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.from_pretrained"]], "from_pretrained() (qefficient.transformers.models.modeling_auto.qeffautomodelforcausallm class method)": [[5, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.from_pretrained"]], "generate() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[5, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.generate"]], "generate() (qefficient.peft.lora.auto.qeffautoloramodelforcausallm method)": [[5, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM.generate"]], "generate() (qefficient.transformers.models.modeling_auto.qeffautomodel method)": [[5, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel.generate"]], "generate() (qefficient.transformers.models.modeling_auto.qeffautomodelforcausallm method)": [[5, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.generate"]], "get_compilation_dims() (in module qefficient.generation.text_generation_inference)": [[5, "QEfficient.generation.text_generation_inference.get_compilation_dims"]], "load_adapter() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[5, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.load_adapter"]], "load_adapter() (qefficient.peft.lora.auto.qeffautoloramodelforcausallm method)": [[5, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM.load_adapter"]], "pytorch_feature_generate() (qefficient.transformers.models.modeling_auto.qeffautomodel method)": [[5, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel.pytorch_feature_generate"]], "qualcomm_efficient_converter() (in module qefficient.exporter.export_hf_to_cloud_ai_100)": [[5, "QEfficient.exporter.export_hf_to_cloud_ai_100.qualcomm_efficient_converter"]], "set_adapter() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[5, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.set_adapter"]], "unload_adapter() (qefficient.peft.lora.auto.qeffautoloramodelforcausallm method)": [[5, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM.unload_adapter"]], "apirunner (class in qefficient.utils.run_utils)": [[8, "QEfficient.utils.run_utils.ApiRunner"]], "inputhandler (class in qefficient.utils.generate_inputs)": [[8, "QEfficient.utils.generate_inputs.InputHandler"]], "qefficient.utils.device_utils": [[8, "module-QEfficient.utils.device_utils"]], "qefficient.utils.generate_inputs": [[8, "module-QEfficient.utils.generate_inputs"]], "qefficient.utils.run_utils": [[8, "module-QEfficient.utils.run_utils"]], "convert_to_cloud_bertstyle() (in module qefficient.exporter.export_hf_to_cloud_ai_100)": [[8, "QEfficient.exporter.export_hf_to_cloud_ai_100.convert_to_cloud_bertstyle"]], "convert_to_cloud_kvstyle() (in module qefficient.exporter.export_hf_to_cloud_ai_100)": [[8, "QEfficient.exporter.export_hf_to_cloud_ai_100.convert_to_cloud_kvstyle"]], "get_available_device_id() (in module qefficient.utils.device_utils)": [[8, "QEfficient.utils.device_utils.get_available_device_id"]], "prepare_ort_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[8, "QEfficient.utils.generate_inputs.InputHandler.prepare_ort_inputs"]], "prepare_pytorch_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[8, "QEfficient.utils.generate_inputs.InputHandler.prepare_pytorch_inputs"]], "run_hf_model_on_pytorch() (qefficient.utils.run_utils.apirunner method)": [[8, "QEfficient.utils.run_utils.ApiRunner.run_hf_model_on_pytorch"]], "run_hf_model_on_pytorch_cb() (qefficient.utils.run_utils.apirunner method)": [[8, "QEfficient.utils.run_utils.ApiRunner.run_hf_model_on_pytorch_CB"]], "run_kv_model_on_cloud_ai_100() (qefficient.utils.run_utils.apirunner method)": [[8, "QEfficient.utils.run_utils.ApiRunner.run_kv_model_on_cloud_ai_100"]], "run_kv_model_on_ort() (qefficient.utils.run_utils.apirunner method)": [[8, "QEfficient.utils.run_utils.ApiRunner.run_kv_model_on_ort"]], "run_kv_model_on_pytorch() (qefficient.utils.run_utils.apirunner method)": [[8, "QEfficient.utils.run_utils.ApiRunner.run_kv_model_on_pytorch"]], "run_ort_session() (qefficient.utils.run_utils.apirunner method)": [[8, "QEfficient.utils.run_utils.ApiRunner.run_ort_session"]], "update_ort_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[8, "QEfficient.utils.generate_inputs.InputHandler.update_ort_inputs"]], "update_ort_outputs() (qefficient.utils.generate_inputs.inputhandler method)": [[8, "QEfficient.utils.generate_inputs.InputHandler.update_ort_outputs"]], "update_pytorch_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[8, "QEfficient.utils.generate_inputs.InputHandler.update_pytorch_inputs"]]}})
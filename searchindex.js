Search.setIndex({"docnames": ["README", "index", "source/blogs", "source/cli_api", "source/finetune", "source/installation", "source/introduction", "source/python_api", "source/quick_start", "source/reference", "source/upgrade", "source/validate"], "filenames": ["README.md", "index.md", "source/blogs.md", "source/cli_api.md", "source/finetune.md", "source/installation.md", "source/introduction.md", "source/python_api.md", "source/quick_start.md", "source/reference.md", "source/upgrade.md", "source/validate.md"], "titles": ["Docs", "Welcome to Efficient-Transformers Documentation!", "Train anywhere, Infer on Qualcomm Cloud AI 100", "Command Line Interface Use (CLI)", "Finetune Infra", "Pre-requisites", "Introduction Qualcomm <code class=\"docutils literal notranslate\"><span class=\"pre\">efficient-transformers</span></code> library", "Python API", "Quick Start", "Qualcomm Cloud AI home", "Using GitHub Repository", "Validated Models"], "terms": {"thi": [0, 3, 4, 6, 7, 8, 10], "directori": [0, 4, 5, 7, 8], "contain": [0, 7, 8], "instruct": [0, 6, 8, 11], "static": 0, "html": 0, "document": [0, 6], "base": [0, 1, 6, 7, 11], "sphinx": 0, "instal": [0, 10], "packag": [0, 3, 7], "requir": [0, 5, 7, 8, 10], "pip": [0, 4, 10], "r": [0, 11], "txt": [0, 3, 8], "And": [0, 7], "chang": [0, 6, 8], "folder": [0, 8], "cd": 0, "To": [0, 4, 6, 8], "specif": [0, 1, 4, 7], "branch": 0, "m": [0, 3, 4, 7, 8, 10], "option": [0, 3, 7, 8], "all": [0, 7], "support": [0, 1, 5, 6, 7, 11], "multivers": 0, "python": [0, 1, 3, 4, 5, 10], "http": [0, 4, 6, 8, 10], "server": 0, "you": [0, 4, 5, 7, 8], "can": [0, 4, 5, 6, 7, 8], "visit": [0, 4], "page": [0, 7], "your": [0, 7, 8], "web": 0, "browser": 0, "url": 0, "localhost": 0, "8080": 0, "introduct": 1, "qualcomm": 1, "librari": [1, 4, 5, 8], "valid": [1, 8, 10], "model": [1, 3, 4, 5, 6, 7, 10], "text": [1, 3, 7, 8], "onli": [1, 6, 7, 8], "languag": [1, 7, 8], "gener": [1, 3, 4, 7, 8], "task": [1, 7, 8], "embed": [1, 8], "multimod": 1, "vision": [1, 8], "imag": 1, "audio": [1, 7], "come": [1, 6, 7], "soon": [1, 3, 6, 7], "pre": [1, 6, 7, 8], "requisit": 1, "1": [1, 3, 4, 6, 7, 11], "download": [1, 3, 4, 7], "app": [1, 3], "sdk": [1, 3, 7, 8, 10], "2": [1, 4, 6, 7, 11], "saniti": 1, "check": [1, 3, 7, 8], "us": [1, 4, 5, 6, 7, 8], "github": [1, 4], "repositori": [1, 4], "quick": 1, "featur": [1, 7], "qpc": [1, 3, 7], "storag": 1, "command": [1, 4, 5, 11], "line": [1, 4, 5, 7], "interfac": 1, "qeffici": [1, 4, 5, 7, 10], "execut": [1, 5, 6], "multi": [1, 5, 11], "qranium": 1, "continu": [1, 3, 6, 7], "batch": [1, 3, 6, 7], "qnn": [1, 3, 7], "compil": [1, 6], "api": 1, "optim": [1, 6], "export": [1, 4, 6], "one": [1, 7], "3": [1, 4, 6, 7, 10, 11], "draft": 1, "specul": [1, 6, 7], "decod": [1, 6, 7], "cli": [1, 4, 8], "high": [1, 8], "level": [1, 3, 4, 8], "qeffautomodelforcausallm": [1, 3, 6, 8, 11], "qeffautomodel": [1, 11], "qeffautopeftmodelforcausallm": 1, "qeffautoloramodelforcausallm": 1, "qeffautomodelforimagetexttotext": 1, "qeffautomodelforspeechseq2seq": [1, 8, 11], "qualcomm_efficient_convert": [1, 7, 8], "cloudai100execinfo": [1, 7], "cloudai100execinfonew": [1, 7], "perfmetr": [1, 7], "calculate_lat": [1, 7], "cloud_ai_100_exec_kv": [1, 7], "fix_prompt_to_lora_id_map": [1, 7], "fix_prompt": [1, 7], "get_compilation_dim": [1, 7], "low": [1, 8], "convert_to_cloud_kvstyl": 1, "convert_to_cloud_bertstyl": 1, "util": [1, 5, 8], "get_available_device_id": [1, 7], "inputhandl": [1, 7], "apirunn": 1, "infra": 1, "dataset": [1, 8], "detail": [1, 7, 8], "usag": [1, 6, 7, 8], "visual": 1, "train": [1, 6], "anywher": [1, 6], "how": [1, 6], "quadrupl": 1, "llm": [1, 6, 8], "perform": [1, 6, 7, 8], "spd": 1, "microsc": 1, "mx": 1, "format": [1, 3, 7, 8], "power": [1, 8], "acceler": [1, 4, 8], "larg": [1, 8, 11], "2x": 1, "introduc": 1, "One": 1, "infinit": 1, "possibl": [1, 7], "home": 1, "user": [1, 6, 8], "guid": 1, "ocp": 1, "click": 2, "here": [2, 6, 7], "bash": [3, 8], "termin": [3, 8], "els": [3, 8], "zsh": [3, 8], "device_group": [3, 7, 8], "should": [3, 7, 8], "singl": [3, 7, 8], "quot": [3, 8], "e": [3, 8], "g": [3, 8], "0": [3, 4, 7, 8], "given": [3, 7], "config": [3, 4, 7, 8], "alreadi": [3, 4, 8], "exist": [3, 5, 8], "doe": [3, 7], "jump": [3, 8], "onnx": [3, 6, 7, 8], "file": [3, 4, 7, 8], "true": [3, 4, 7, 8], "hf": [3, 8, 11], "cach": [3, 7, 8], "start": [3, 5, 7], "transform": [3, 4, 7, 10, 11], "4": [3, 4, 6], "mandatori": [3, 7], "arg": [3, 7], "model_nam": [3, 4, 7, 8], "str": [3, 7], "hug": [3, 7], "face": [3, 7], "card": [3, 5, 6, 7, 8], "name": [3, 7, 8], "exampl": [3, 4, 6, 7, 8], "gpt2": [3, 7, 8, 11], "num_cor": [3, 7, 8], "int": [3, 7, 8], "number": [3, 4, 7, 8], "core": [3, 7], "list": [3, 7], "devic": [3, 4, 5, 6, 7, 8], "id": [3, 7], "If": [3, 5, 7, 8], "len": [3, 7], "multipl": [3, 7, 8], "setup": [3, 7], "i": [3, 4, 5, 6, 8], "enabl": [3, 4, 5, 6, 7, 8], "default": [3, 7, 8], "none": [3, 7], "prompt": [3, 7, 8], "sampl": [3, 6, 7, 8], "prompts_txt_file_path": [3, 7, 8], "path": [3, 5, 6, 7, 8], "input": [3, 7, 8], "aic_enable_depth_first": [3, 7, 8], "bool": [3, 7], "df": [3, 7], "memori": [3, 7, 8], "size": [3, 7, 8], "fals": [3, 7], "mo": [3, 7, 8], "effort": [3, 7, 8], "reduc": [3, 7, 8], "chip": [3, 7], "batch_siz": [3, 7, 8], "full_batch_s": [3, 7, 8], "set": [3, 4, 7, 8], "full": [3, 7], "mode": [3, 4, 7], "prompt_len": [3, 7, 8], "length": [3, 7, 8], "32": [3, 7, 8], "ctx_len": [3, 7, 8], "maximum": [3, 7, 8], "context": [3, 7, 8], "128": [3, 7, 8], "generation_len": [3, 7], "token": [3, 7, 8], "mxfp6": [3, 7, 8], "precis": [3, 6, 7, 8], "mxint8": [3, 7], "compress": [3, 7], "present": [3, 7, 8], "past": [3, 7], "kv": [3, 7, 8], "customio": [3, 7, 8], "local_model_dir": [3, 7], "custom": [3, 7, 8], "weight": [3, 6, 7], "cache_dir": [3, 7, 8], "dir": [3, 7, 8], "where": [3, 7, 8], "huggingfac": [3, 6, 7, 8], "ar": [3, 4, 5, 6, 7, 8], "store": [3, 5, 7, 8], "hf_token": [3, 7], "login": 3, "access": [3, 7, 8], "privat": [3, 4], "repo": [3, 10], "allow_mxint8_mdp_io": [3, 7], "allow": [3, 6, 7, 8], "mdp": [3, 7], "io": [3, 7], "traffic": [3, 7], "enable_qnn": [3, 7, 8], "qnn_config": [3, 7, 8], "paramet": [3, 4, 7, 8], "helper": 3, "function": [3, 6, 7], "run": [3, 4, 5, 8], "ai": [3, 5, 6, 7, 11], "100": [3, 5, 6, 7], "platform": [3, 5, 7, 8], "qpc_path": [3, 7, 8], "binari": [3, 7, 8], "after": [3, 5, 7], "constant": [3, 8], "save": [3, 7, 8], "tensor": [3, 7], "slice": [3, 7], "configur": [3, 4, 7, 8], "pass": [3, 7, 8], "deprec": [3, 7], "replac": [3, 6, 7], "onnx_path": [3, 7, 8], "find": [3, 7], "custom_io_file_path": [3, 7], "string": [3, 7, 8], "return": [3, 6, 7], "qaic": [3, 5, 7, 8], "provid": [4, 6, 7, 8], "infrastructur": 4, "differ": [4, 7, 8], "hardwar": [4, 7, 8], "same": [4, 7, 8, 10], "gpu": 4, "flag": [4, 7, 8], "torch": [4, 7, 8], "cuda": 4, "along": [4, 8], "pytorch": [4, 7, 8], "eager": [4, 8], "For": [4, 6, 8], "com": [4, 10], "quic": [4, 10], "effici": [4, 7, 8, 10], "torch_qaic": 4, "assum": 4, "opt": [4, 5, 7], "qti": [4, 5, 7], "aic": [4, 5, 7], "integr": [4, 5, 7, 8], "py310": 4, "cp310": 4, "linux_x86_64": 4, "whl": 4, "env": [4, 10], "variabl": [4, 8], "hf_datasets_trust_remote_cod": 4, "get": 4, "hw": [4, 6], "trace": 4, "debug": [4, 7], "log": [4, 7], "qaic_device_log_level": 4, "qaic_debug": 4, "understand": 4, "cpu": [4, 7], "fallback": 4, "op": 4, "alpaca": 4, "link": 4, "place": 4, "under": [4, 5, 8], "make": [4, 6, 7, 8], "sure": [4, 8], "updat": [4, 6, 7], "accordingli": 4, "wget": 4, "c": [4, 5], "raw": 4, "githubusercont": 4, "tatsu": 4, "lab": 4, "stanford_alpaca": 4, "ref": 4, "head": [4, 7, 8], "main": 4, "alpaca_data": 4, "json": [4, 7, 8], "p": 4, "grammar": 4, "datasets_grammar": 4, "cloud": [4, 5, 6, 7], "meta": [4, 6, 8, 11], "llama": [4, 6, 7, 8, 11], "1b": [4, 6, 8, 11], "also": [4, 8], "variou": [4, 8], "more": [4, 6, 7, 8], "checkout": [4, 8], "py": 4, "below": [4, 7, 8], "peft": [4, 6, 7, 8], "output_dir": [4, 8], "sam": [4, 8], "num_epoch": [4, 8], "context_length": [4, 8], "256": [4, 7, 8], "qaic_visible_devic": 4, "torchrun": 4, "nproc": 4, "per": 4, "node": [4, 7], "enable_ddp": 4, "dist_backend": 4, "qccl": 4, "worker": 4, "local": [4, 6, 7, 8], "tensorboard": 4, "insid": 4, "date": 4, "time": [4, 7, 8], "stamp": 4, "visualis": 4, "data": [4, 7], "logdir": 4, "bind_al": 4, "system": 5, "linux": 5, "o": [5, 7, 8], "ubuntu": 5, "rhel": 5, "aw": 5, "shard": 5, "uninstal": 5, "sudo": 5, "sh": 5, "script": [5, 8], "root": 5, "permiss": 5, "qeff": [5, 7, 8, 11], "sourc": [5, 6, 7, 10], "dev": 5, "bin": [5, 10], "activ": [5, 7, 8, 10], "On": 5, "success": [5, 8], "content": 5, "exec": [5, 7], "version": [5, 7], "follow": [5, 8], "tool": 5, "appli": 5, "chmod": 5, "x": 5, "hexagon_tool": 5, "abov": [5, 8], "method": [5, 7], "correctli": 5, "import": [5, 7, 8], "print": [5, 7, 8], "__version__": 5, "successfulli": 5, "good": 5, "go": 5, "ahead": [5, 8], "deploi": 5, "infer": [6, 7], "develop": [6, 8], "centric": 6, "toolchain": 6, "reimplement": 6, "block": [6, 8], "which": [6, 7, 8], "highli": [6, 7], "we": [6, 7, 8], "wide": 6, "rang": 6, "architectur": [6, 7, 8, 11], "easi": 6, "deploy": 6, "need": [6, 7, 8], "from": [6, 7, 8], "take": [6, 7, 8], "care": 6, "": [6, 7], "implement": 6, "other": [6, 7, 8], "comprehens": 6, "inspir": 6, "upon": [6, 8], "typic": 6, "retent": [6, 7], "intermedi": 6, "state": [6, 7, 8], "read": 6, "graph": [6, 7, 8], "kei": [6, 8], "oper": 6, "lower": 6, "some": [6, 7], "mathemat": 6, "equival": 6, "backend": [6, 8], "handl": [6, 7, 8], "underflow": 6, "overflow": [6, 8], "patcher": 6, "modul": [6, 7], "map": [6, 7], "origin": [6, 7, 8], "applic": [6, 7, 8], "demo": [6, 8], "notebook": [6, 8], "unit": 6, "test": 6, "templat": 6, "latest": 6, "new": [6, 7, 8], "popular": 6, "01": 6, "2025": 6, "fp8": [6, 8], "ad": [6, 7, 8], "ibm": [6, 11], "granit": [6, 11], "co": [6, 8, 11], "8b": [6, 8, 11], "11": 6, "2024": 6, "finit": [6, 7, 8], "adapt": [6, 7, 8, 11], "mix": [6, 7, 8], "tlm": [6, 8], "than": 6, "logit": [6, 7], "dure": [6, 7, 8], "70b": [6, 8, 11], "3b": [6, 11], "09": 6, "awq": [6, 8], "gptq": [6, 8], "bit": 6, "quantiz": [6, 8], "now": [6, 7, 8], "guardian": [6, 11], "gemma": [6, 11], "famili": [6, 11], "codegemma": [6, 11], "20b": [6, 11], "code": [6, 7, 8, 11], "8k": [6, 11], "starcoder1": [6, 11], "15b": [6, 11], "08": 6, "techniqu": [6, 8], "jai": [6, 11], "13b": [6, 11], "chat": [6, 8, 11], "7b": [6, 7, 11], "06": 6, "gpt": [6, 11], "j": [6, 11], "6b": [6, 11], "qwen2": [6, 11], "5b": [6, 11], "starcoder2": [6, 11], "phi3": 6, "mini": [6, 11], "4k": [6, 11], "codestr": [6, 11], "22b": [6, 11], "v0": [6, 7, 11], "vicuna": [6, 11], "v1": [6, 8, 11], "5": [6, 11], "05": 6, "mixtral": [6, 11], "8x7b": [6, 11], "mistral": [6, 7, 11], "04": 6, "initi": [6, 7, 8], "releas": 6, "seamless": [6, 8], "give": 7, "an": [7, 8], "overview": 7, "about": 7, "might": 7, "modeling_auto": 7, "continuous_batch": 7, "is_tlm": [7, 8], "kwarg": 7, "The": [7, 8], "design": [7, 8], "manipul": 7, "ani": [7, 8], "causal": 7, "hub": 7, "although": 7, "directli": [7, 8], "recommend": 7, "from_pretrain": [7, 8], "nn": 7, "weather": 7, "futur": [7, 8], "later": 7, "whether": 7, "target": [7, 8], "num_logits_to_keep": 7, "arrai": [7, 8], "have": [7, 8, 10], "fed": [7, 8], "control": [7, 8], "prefil": [7, 8], "autotoken": 7, "num_hidden_lay": 7, "prefill_seq_len": 7, "16": [7, 8], "num_devic": 7, "hi": 7, "export_dir": 7, "compile_dir": 7, "kv_cache_batch_s": 7, "mxfp6_matmul": 7, "mxint8_kv_cach": 7, "num_speculative_token": [7, 8], "compiler_opt": 7, "found": [7, 8], "ha": 7, "been": [7, 8, 10], "yet": 7, "process": [7, 8], "argument": [7, 8], "extra": [7, 8], "less": 7, "ctx": 7, "rememb": 7, "mean": 7, "pretrainedtokenizerfast": 7, "pretrainedtoken": 7, "device_id": 7, "runtime_ai100": 7, "output": 7, "until": 7, "eo": 7, "sequenti": 7, "cannot": 7, "divid": [7, 8], "last": 7, "unfulfil": 7, "drop": 7, "union": 7, "case": [7, 8], "normal": 7, "ai_100": 7, "runtim": [7, 8], "similar": [7, 8], "automodel": 7, "consid": 7, "sku": 7, "prepar": 7, "my": [7, 8], "return_tensor": 7, "pt": 7, "seq_len": 7, "ndarrai": 7, "np": [7, 8], "dict": 7, "cloud_ai_100_feature_gener": 7, "A": [7, 8], "session": [7, 8], "dictionari": 7, "pytorch_feature_gener": 7, "each": 7, "auto": [7, 11], "load": 7, "lora": [7, 8], "current": 7, "onc": [7, 8], "anoth": 7, "predibas": 7, "magicod": 7, "1024": 7, "math": 7, "load_adapt": 7, "gsm8k": 7, "set_adapt": 7, "model_id": 7, "adapter_nam": 7, "properti": 7, "active_adapt": 7, "classmethod": 7, "pretrained_name_or_path": 7, "finite_adapt": 7, "pleas": [7, 8], "refer": [7, 8], "identifi": 7, "addit": 7, "autopeftmodelforcausallm": 7, "specifi": [7, 8], "suffix": 7, "hash": 7, "correspond": [7, 8], "ai100": 7, "avoid": 7, "reus": [7, 8], "matmul": 7, "faster": [7, 8], "param": [7, 8], "convert": 7, "aic_num_cor": 7, "num": 7, "convert_to_fp16": 7, "fp16": [7, 8], "alloc": 7, "sequenc": [7, 8], "chunk": 7, "accord": 7, "space": 7, "generation_config": 7, "generationconfig": 7, "stopping_criteria": 7, "stoppingcriteria": 7, "streamer": 7, "basestream": 7, "input_id": 7, "merg": 7, "stop": 7, "point": 7, "put": 7, "while": [7, 8], "prompt_to_adapter_map": 7, "mistralai": [7, 11], "gsm8k_id": 7, "download_adapt": 7, "adapter_model_id": 7, "adapter_weight": 7, "adapter_config": 7, "peftconfig": 7, "unload_adapt": 7, "deactiv": 7, "adpat": 7, "remov": 7, "unload": 7, "don": [7, 8], "t": [7, 8], "non": 7, "legaci": 7, "match": 7, "picker": 7, "onnxrt": 7, "kv_offload": 7, "factori": 7, "creat": [7, 8, 10], "instanc": 7, "dual": 7, "approach": [7, 8], "attribut": 7, "_hf_auto_class": 7, "imagetexttotext": 7, "speech": [7, 8, 11], "includ": [7, 8], "whisper": [7, 11], "encod": 7, "processor": 7, "autoprocessor": 7, "automodelforspeechseq2seq": 7, "input_audio": 7, "sample_r": 7, "via": [7, 8], "extern": 7, "librosa": 7, "soundfil": 7, "input_featur": 7, "sampling_r": 7, "numpi": 7, "astyp": 7, "float32": 7, "decoder_input_id": 7, "ones": 7, "dtype": 7, "int64": 7, "decoder_start_token_id": 7, "decoder_position_id": 7, "arang": 7, "view": 7, "repeat": 7, "150": 7, "encoder_ctx_len": 7, "1500": 7, "decoder_ctx_len": 7, "feature_len": 7, "3000": 7, "textstream": 7, "enable_debug_log": 7, "endoftranscript": 7, "upto": 7, "rate": 7, "export_hf_to_cloud_ai_100": 7, "model_kv": 7, "qeffbasemodel": 7, "onnx_dir_path": 7, "seq_length": 7, "form_factor": 7, "tupl": 7, "alia": 7, "object": [7, 8], "In": 7, "gate": 7, "bert": [7, 11], "style": 7, "form": 7, "factor": 7, "accept": 7, "base_path": 7, "onnx_model_path": 7, "sinc": 7, "19": 7, "instead": [7, 8], "compile_help": 7, "join": [7, 8], "14": [7, 8], "text_generation_infer": 7, "generated_text": 7, "generated_id": 7, "perf_metr": 7, "hold": 7, "inform": 7, "metric": 7, "prefill_tim": 7, "float": 7, "decode_perf": 7, "total_perf": 7, "total_tim": 7, "total": 7, "total_decoded_token": 7, "loop_start": 7, "end": [7, 8], "decode_pause_tim": 7, "calcul": [7, 8], "latenc": [7, 8], "loop": 7, "count": 7, "stage": [7, 8], "paus": 7, "stream": 7, "write_io_dir": 7, "autom": 7, "prompt_to_lora_id_map": 7, "them": [7, 8], "write": 7, "stat": [7, 8], "associ": 7, "respect": 7, "exec_info": 7, "adjust": 7, "fetch": 7, "dimens": 7, "special": [7, 8], "comput": [7, 8], "compris": 7, "qeff_model": [7, 8], "particularli": [7, 8], "suitabl": 7, "regress": 7, "involv": 7, "contextu": 7, "earlier": 7, "crucial": 7, "predict": [7, 8], "next": 7, "inclus": 7, "enhanc": [7, 8], "computation": 7, "bertstyl": 7, "No": 7, "separ": [7, 8], "logic": 7, "everi": 7, "max_length": 7, "device_util": 7, "avail": [7, 8], "generate_input": 7, "prepare_ort_input": 7, "position_id": 7, "past_key_valu": 7, "prepare_pytorch_input": 7, "update_ort_input": 7, "ort_output": 7, "previou": 7, "iter": 7, "update_ort_output": 7, "updated_output": 7, "update_pytorch_input": 7, "pt_output": 7, "run_util": 7, "run_hf_model_on_pytorch": 7, "model_hf": 7, "run_hf_model_on_pytorch_cb": 7, "run_kv_model_on_cloud_ai_100": 7, "run_kv_model_on_ort": 7, "model_path": 7, "onnxruntim": [7, 8], "run_kv_model_on_pytorch": 7, "run_ort_sess": 7, "retain": 7, "capi": 7, "onnxruntime_inference_collect": 7, "inferencesess": 7, "wa": 8, "goal": 8, "onboard": 8, "straightforward": 8, "leverag": 8, "complet": 8, "achiev": 8, "abstract": 8, "awai": 8, "complex": 8, "offer": 8, "simpler": 8, "thei": 8, "re": 8, "ideal": 8, "prototyp": 8, "technologi": 8, "want": 8, "minim": 8, "granular": 8, "when": 8, "necessari": 8, "impact": 8, "upcom": 8, "increas": 8, "better": 8, "long": 8, "swift": 8, "overhead": 8, "valu": 8, "pair": 8, "lead": 8, "improv": 8, "throughput": 8, "attent": 8, "progress": 8, "cost": 8, "rag": 8, "automodelforimagetexttotext": 8, "class": [8, 11], "advanc": 8, "facilit": 8, "significantli": 8, "speed": 8, "share": 8, "prefix": 8, "redund": 8, "lookup": 8, "up": 8, "overlap": 8, "part": 8, "without": 8, "lose": 8, "qualiti": 8, "fine": 8, "tune": 8, "rank": 8, "vector": 8, "retriev": 8, "preliminari": 8, "verifi": 8, "lorax": 8, "At": 8, "within": 8, "cpp": 8, "inferenc": 8, "flexibl": 8, "dynam": 8, "request": 8, "ensur": 8, "resourc": 8, "serv": 8, "yield": 8, "perplex": 8, "evalu": 8, "comparison": 8, "across": 8, "replic": 8, "modifi": 8, "By": 8, "program": 8, "readi": 8, "qeff_cach": 8, "environ": 8, "qeff_hom": 8, "its": 8, "xdg_cache_hom": 8, "note": 8, "rerout": 8, "entir": 8, "neither": 8, "nor": 8, "e2": 8, "model_card": 8, "doc": 8, "It": 8, "skip": 8, "second": 8, "automat": [8, 11], "creation": 8, "out": 8, "help": 8, "pipe": 8, "symbol": 8, "flat": 8, "earth": 8, "theori": 8, "belief": 8, "sun": 8, "rise": 8, "lot": 8, "first": 8, "precompil": 8, "qpc_16cores_1bs_32pl_128cl_1devices_mxfp6": 8, "predefin": 8, "pipelin": 8, "subsect": 8, "mq": 8, "just": 8, "group": 8, "fly": 8, "soc": 8, "salesforc": 8, "codegen": 8, "2b": [8, 11], "mono": 8, "def": 8, "fibonacci": 8, "n": 8, "step": 8, "model_card_nam": 8, "pick": 8, "qpc_16cores_1bs_32pl_128cl_2devices_mxfp6": 8, "binary_search": 8, "k": 8, "disabl": 8, "like": 8, "again": 8, "full_batch_size_valu": 8, "regular": 8, "wai": 8, "tinyllama": 8, "tinyllama_v1": 8, "qnn_sdk_root": 8, "qnn_sdk_folder": 8, "add": 8, "overrid": 8, "With": 8, "qpc_qnn_16cores_1bs_32pl_128cl_1devices_mxfp6": 8, "framework": 8, "both": 8, "variat": 8, "automodelforcausallm": 8, "xl": 8, "lib": 8, "generated_qpc_path": 8, "qnn_config_file_path": 8, "advantag": 8, "fall": 8, "work": [8, 10], "rais": 8, "issu": 8, "troubl": 8, "uncom": 8, "appropri": 8, "transformers_cach": 8, "mnt": 8, "workspac": 8, "hf_cach": 8, "root_dir": 8, "dirnam": 8, "abspath": 8, "tmp": 8, "locat": 8, "f": 8, "clip": 8, "v": 8, "Then": 8, "yaml": 8, "benchmark": 8, "tok": 8, "sec": 8, "post": 8, "greedi": 8, "small": [8, 11], "dlm": 8, "autoregress": 8, "what": 8, "would": 8, "benefici": 8, "phase": 8, "bound": 8, "thu": 8, "our": 8, "tlm_name": 8, "dlm_name": 8, "instanti": 8, "becaus": 8, "slight": 8, "defin": 8, "actual": 8, "As": 8, "warn": 10, "compat": 10, "upgrad": 10, "mai": 10, "result": 10, "certain": 10, "becom": 10, "incompat": 10, "virtual": 10, "10": 10, "python3": 10, "venv": 10, "qeff_env": 10, "u": 10, "clone": 10, "git": 10, "repres": 11, "cb": 11, "falconforcausallm": 11, "falcon": 11, "tiiuae": 11, "40b": 11, "gemmaforcausallm": 11, "googl": 11, "9b": 11, "27b": 11, "gptbigcodeforcausallm": 11, "bigcod": 11, "starcod": 11, "gptjforcausallm": 11, "eleutherai": 11, "gpt2lmheadmodel": 11, "openai": 11, "commun": 11, "graniteforcausallm": 11, "internvlchatmodel": 11, "intern": 11, "vl": 11, "opengvlab": 11, "internvl2_5": 11, "llamaforcausallm": 11, "codellama": 11, "34b": 11, "deepseek": 11, "r1": 11, "distil": 11, "inceptionai": 11, "lmsy": 11, "delta": 11, "mistralforcausallm": 11, "mixtralforcausallm": 11, "mptforcausallm": 11, "mpt": 11, "mosaicml": 11, "phi3forcausallm": 11, "phi": 11, "microsoft": 11, "qwenforcausallm": 11, "qwen": 11, "32b": 11, "bertmodel": 11, "baai": 11, "bge": 11, "en": 11, "e5": 11, "v2": 11, "llamamodel": 11, "intfloat": 11, "qwen2forcausallm": 11, "stella_en_1": 11, "5b_v5": 11, "xlmrobertaforsequenceclassif": 11, "xlm": 11, "roberta": 11, "rerank": 11, "m3bge": 11, "m3": 11, "mpnetformaskedlm": 11, "mpnet": 11, "sentenc": 11, "qa": 11, "nomicbertmodel": 11, "nomicbert": 11, "nomic": 11, "emb": 11, "mistralmodel": 11, "qeffautomodelimagetexttotext": 11, "llavaforconditionalgener": 11, "llava": 11, "mllamaforconditionalgener": 11, "11b": 11, "90b": 11, "recognit": 11, "transcript": 11, "tini": 11, "medium": 11, "v3": 11, "turbo": 11, "baichuanforcausallm": 11, "baichuan2": 11, "baichuan": 11, "inc": 11, "cohereforcausallm": 11, "cohereforai": 11, "c4ai": 11, "v01": 11, "dbrxforcausallm": 11, "dbrx": 11, "databrick": 11}, "objects": {"QEfficient.cloud.execute": [[3, 0, 0, "-", "main"]], "QEfficient.cloud.export": [[3, 0, 0, "-", "main"]], "QEfficient.cloud.finetune": [[3, 0, 0, "-", "main"]], "QEfficient.cloud.infer": [[3, 0, 0, "-", "main"]], "QEfficient.compile": [[7, 0, 0, "-", "compile_helper"]], "QEfficient.compile.compile_helper": [[7, 1, 1, "", "compile"], [3, 0, 0, "-", "compile"]], "QEfficient.exporter": [[7, 0, 0, "-", "export_hf_to_cloud_ai_100"]], "QEfficient.exporter.export_hf_to_cloud_ai_100": [[7, 1, 1, "", "convert_to_cloud_bertstyle"], [7, 1, 1, "", "convert_to_cloud_kvstyle"], [7, 1, 1, "", "qualcomm_efficient_converter"]], "QEfficient.generation": [[7, 0, 0, "-", "text_generation_inference"]], "QEfficient.generation.text_generation_inference": [[7, 2, 1, "", "CloudAI100ExecInfo"], [7, 2, 1, "", "CloudAI100ExecInfoNew"], [7, 2, 1, "", "PerfMetrics"], [7, 1, 1, "", "calculate_latency"], [7, 1, 1, "", "cloud_ai_100_exec_kv"], [7, 1, 1, "", "fix_prompt_to_lora_id_mapping"], [7, 1, 1, "", "fix_prompts"], [7, 1, 1, "", "get_compilation_dims"]], "QEfficient.peft.auto": [[7, 2, 1, "", "QEffAutoPeftModelForCausalLM"]], "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM": [[7, 3, 1, "", "active_adapter"], [7, 4, 1, "", "compile"], [7, 4, 1, "", "export"], [7, 4, 1, "", "from_pretrained"], [7, 4, 1, "", "generate"], [7, 4, 1, "", "load_adapter"], [7, 4, 1, "", "set_adapter"]], "QEfficient.peft.lora.auto": [[7, 2, 1, "", "QEffAutoLoraModelForCausalLM"]], "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM": [[7, 4, 1, "", "download_adapter"], [7, 4, 1, "", "export"], [7, 4, 1, "", "generate"], [7, 4, 1, "", "load_adapter"], [7, 4, 1, "", "unload_adapter"]], "QEfficient.transformers.models.modeling_auto": [[7, 2, 1, "", "QEFFAutoModel"], [7, 2, 1, "", "QEFFAutoModelForCausalLM"], [7, 2, 1, "", "QEFFAutoModelForImageTextToText"], [7, 2, 1, "", "QEFFAutoModelForSpeechSeq2Seq"]], "QEfficient.transformers.models.modeling_auto.QEFFAutoModel": [[7, 4, 1, "", "cloud_ai_100_feature_generate"], [7, 4, 1, "", "compile"], [7, 4, 1, "", "export"], [7, 4, 1, "", "generate"], [7, 4, 1, "", "pytorch_feature_generate"]], "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM": [[7, 4, 1, "", "compile"], [7, 4, 1, "", "export"], [7, 4, 1, "", "generate"]], "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForSpeechSeq2Seq": [[7, 4, 1, "", "compile"], [7, 4, 1, "", "export"], [7, 4, 1, "", "generate"]], "QEfficient.utils": [[7, 0, 0, "-", "device_utils"], [7, 0, 0, "-", "generate_inputs"], [7, 0, 0, "-", "run_utils"]], "QEfficient.utils.device_utils": [[7, 1, 1, "", "get_available_device_id"]], "QEfficient.utils.generate_inputs": [[7, 2, 1, "", "InputHandler"]], "QEfficient.utils.generate_inputs.InputHandler": [[7, 4, 1, "", "prepare_ort_inputs"], [7, 4, 1, "", "prepare_pytorch_inputs"], [7, 4, 1, "", "update_ort_inputs"], [7, 4, 1, "", "update_ort_outputs"], [7, 4, 1, "", "update_pytorch_inputs"]], "QEfficient.utils.run_utils": [[7, 2, 1, "", "ApiRunner"]], "QEfficient.utils.run_utils.ApiRunner": [[7, 4, 1, "", "run_hf_model_on_pytorch"], [7, 4, 1, "", "run_hf_model_on_pytorch_CB"], [7, 4, 1, "", "run_kv_model_on_cloud_ai_100"], [7, 4, 1, "", "run_kv_model_on_ort"], [7, 4, 1, "", "run_kv_model_on_pytorch"], [7, 4, 1, "", "run_ort_session"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class", "3": "py:property", "4": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"], "3": ["py", "property", "Python property"], "4": ["py", "method", "Python method"]}, "titleterms": {"doc": 0, "build": 0, "preview": 0, "local": 0, "welcom": 1, "effici": [1, 2, 5, 6], "transform": [1, 2, 5, 6, 8], "document": 1, "get": 1, "start": [1, 8], "instal": [1, 4, 5], "upgrad": 1, "infer": [1, 2, 3, 8], "cloud": [1, 2, 3, 8, 9], "ai": [1, 2, 8, 9], "100": [1, 2, 8], "qaic": [1, 4], "finetun": [1, 3, 4, 8], "blog": 1, "refer": [1, 9], "train": [2, 4], "anywher": 2, "qualcomm": [2, 6, 9], "how": 2, "quadrupl": 2, "llm": 2, "decod": [2, 8], "perform": 2, "specul": [2, 8], "spd": 2, "microsc": [2, 9], "mx": [2, 9], "format": [2, 9], "power": 2, "acceler": 2, "larg": 2, "languag": [2, 11], "model": [2, 8, 11], "sdk": [2, 5, 9], "2x": 2, "us": [2, 3, 10], "introduc": 2, "One": 2, "api": [2, 7, 8, 9], "infinit": 2, "possibl": 2, "command": [3, 8], "line": [3, 8], "interfac": [3, 8], "cli": 3, "qeffici": [3, 8], "execut": [3, 7, 8], "compil": [3, 7, 8], "export": [3, 7, 8], "infra": 4, "dataset": 4, "detail": 4, "usag": 4, "singl": 4, "soc": 4, "distribut": 4, "ddp": 4, "visual": 4, "pre": 5, "requisit": 5, "small": 5, "1": [5, 8], "download": [5, 8, 9], "app": 5, "2": [5, 8], "saniti": 5, "check": 5, "introduct": 6, "librari": 6, "python": [7, 8], "high": 7, "level": 7, "qeffautomodelforcausallm": 7, "qeffautomodel": 7, "qeffautopeftmodelforcausallm": 7, "qeffautoloramodelforcausallm": 7, "qeffautomodelforimagetexttotext": 7, "qeffautomodelforspeechseq2seq": 7, "low": 7, "convert_to_cloud_kvstyl": 7, "convert_to_cloud_bertstyl": 7, "util": 7, "apirunn": 7, "class": 7, "i": 7, "respons": 7, "run": 7, "quick": 8, "support": 8, "featur": 8, "qpc": 8, "storag": 8, "multi": 8, "qranium": 8, "continu": 8, "batch": 8, "qnn": 8, "optim": 8, "one": 8, "3": 8, "draft": 8, "base": 8, "home": 9, "user": 9, "guid": 9, "ocp": 9, "specif": 9, "github": 10, "repositori": 10, "valid": 11, "text": 11, "onli": 11, "gener": 11, "task": 11, "embed": 11, "multimod": 11, "vision": 11, "imag": 11, "audio": 11, "come": 11, "soon": 11}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 58}, "alltitles": {"Docs": [[0, "docs"]], "Build the docs": [[0, "build-the-docs"]], "Preview the docs locally": [[0, "preview-the-docs-locally"]], "Welcome to Efficient-Transformers Documentation!": [[1, "welcome-to-efficient-transformers-documentation"]], "Getting Started": [[1, null]], "Installation": [[1, null], [4, "installation"], [5, "installation"]], "Upgrade Efficient-Transformers": [[1, null]], "Inference on Cloud AI 100": [[1, null]], "QAIC Finetune": [[1, null]], "Blogs": [[1, null]], "Reference": [[1, null]], "Train anywhere, Infer on Qualcomm Cloud AI 100": [[2, "train-anywhere-infer-on-qualcomm-cloud-ai-100"]], "How to Quadruple LLM Decoding Performance with Speculative Decoding (SpD) and Microscaling (MX) Formats on Qualcomm\u00ae Cloud AI 100": [[2, "how-to-quadruple-llm-decoding-performance-with-speculative-decoding-spd-and-microscaling-mx-formats-on-qualcomm-cloud-ai-100"]], "Power-efficient acceleration for large language models \u2013 Qualcomm Cloud AI SDK": [[2, "power-efficient-acceleration-for-large-language-models-qualcomm-cloud-ai-sdk"]], "Qualcomm Cloud AI 100 Accelerates Large Language Model Inference by ~2x Using Microscaling (Mx) Formats": [[2, "qualcomm-cloud-ai-100-accelerates-large-language-model-inference-by-2x-using-microscaling-mx-formats"]], "Qualcomm Cloud AI Introduces Efficient Transformers: One API, Infinite Possibilities": [[2, "qualcomm-cloud-ai-introduces-efficient-transformers-one-api-infinite-possibilities"]], "Command Line Interface Use (CLI)": [[3, "command-line-interface-use-cli"]], "QEfficient.cloud.infer": [[3, "module-QEfficient.cloud.infer.main"], [8, "qefficient-cloud-infer"]], "QEfficient.cloud.execute": [[3, "module-QEfficient.cloud.execute.main"], [8, "qefficient-cloud-execute"]], "QEfficient.cloud.compile": [[3, "qefficient-cloud-compile"]], "QEfficient.cloud.export": [[3, "qefficient-cloud-export"]], "QEfficient.cloud.finetune": [[3, "qefficient-cloud-finetune"], [8, "qefficient-cloud-finetune"]], "Finetune Infra": [[4, "finetune-infra"]], "Finetuning": [[4, "finetuning"]], "Dataset Details": [[4, "dataset-details"]], "Usage": [[4, "usage"]], "Single SOC finetuning on QAIC": [[4, "single-soc-finetuning-on-qaic"]], "Distributed training(DDP) on QAIC": [[4, "distributed-training-ddp-on-qaic"]], "Visualization": [[4, "visualization"]], "Pre-requisites": [[5, "pre-requisites"]], "<small> 1. Download Apps SDK</small>": [[5, "download-apps-sdk"]], "<small> 2. Install Efficient-Transformers</small>": [[5, "install-efficient-transformers"]], "Sanity Check": [[5, "sanity-check"]], "Introduction Qualcomm efficient-transformers library": [[6, "introduction-qualcomm-efficient-transformers-library"]], "Qualcomm Cloud AI home": [[9, "qualcomm-cloud-ai-home"]], "Qualcomm Cloud AI SDK download": [[9, "qualcomm-cloud-ai-sdk-download"]], "Qualcomm Cloud AI API reference": [[9, "qualcomm-cloud-ai-api-reference"]], "User Guide": [[9, "user-guide"]], "OCP Microscaling Formats (MX) Specification": [[9, "ocp-microscaling-formats-mx-specification"]], "Using GitHub Repository": [[10, "using-github-repository"]], "Validated Models": [[11, "validated-models"]], "Text-only Language Models": [[11, "text-only-language-models"]], "Text Generation Task": [[11, "text-generation-task"]], "Embedding Models": [[11, "embedding-models"]], "Text Embedding Task": [[11, "text-embedding-task"]], "Multimodal Language Models": [[11, "multimodal-language-models"]], "Vision-Language Models (Text + Image Generation)": [[11, "vision-language-models-text-image-generation"]], "Audio Models": [[11, "audio-models"]], "Models Coming Soon": [[11, "models-coming-soon"]], "Python API": [[7, "python-api"], [8, "python-api"]], "High Level API": [[7, "high-level-api"]], "QEFFAutoModelForCausalLM": [[7, "qeffautomodelforcausallm"]], "QEFFAutoModel": [[7, "qeffautomodel"]], "QEffAutoPeftModelForCausalLM": [[7, "qeffautopeftmodelforcausallm"]], "QEffAutoLoraModelForCausalLM": [[7, "qeffautoloramodelforcausallm"]], "QEFFAutoModelForImageTextToText": [[7, "qeffautomodelforimagetexttotext"]], "QEFFAutoModelForSpeechSeq2Seq": [[7, "qeffautomodelforspeechseq2seq"]], "export": [[7, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "compile": [[7, "module-QEfficient.compile.compile_helper"]], "Execute": [[7, "module-QEfficient.generation.text_generation_inference"]], "Low Level API": [[7, "low-level-api"]], "convert_to_cloud_kvstyle": [[7, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "convert_to_cloud_bertstyle": [[7, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "utils": [[7, "module-QEfficient.utils.device_utils"]], "ApiRunner class is responsible for running:": [[7, "apirunner-class-is-responsible-for-running"]], "Quick Start": [[8, "quick-start"]], "Supported Features": [[8, "supported-features"]], "Transformed models and QPC storage": [[8, "transformed-models-and-qpc-storage"]], "Command Line Interface": [[8, "command-line-interface"]], "Multi-Qranium Inference": [[8, "multi-qranium-inference"]], "Continuous Batching": [[8, "continuous-batching"]], "QNN Compilation": [[8, "qnn-compilation"]], "1.  Model download and Optimize for Cloud AI 100": [[8, "model-download-and-optimize-for-cloud-ai-100"]], "2. Export and Compile with one API": [[8, "export-and-compile-with-one-api"]], "3. Execute": [[8, "execute"]], "Draft-Based Speculative Decoding": [[8, "draft-based-speculative-decoding"]]}, "indexentries": {"apirunner (class in qefficient.utils.run_utils)": [[7, "QEfficient.utils.run_utils.ApiRunner"]], "cloudai100execinfo (class in qefficient.generation.text_generation_inference)": [[7, "QEfficient.generation.text_generation_inference.CloudAI100ExecInfo"]], "cloudai100execinfonew (class in qefficient.generation.text_generation_inference)": [[7, "QEfficient.generation.text_generation_inference.CloudAI100ExecInfoNew"]], "inputhandler (class in qefficient.utils.generate_inputs)": [[7, "QEfficient.utils.generate_inputs.InputHandler"]], "perfmetrics (class in qefficient.generation.text_generation_inference)": [[7, "QEfficient.generation.text_generation_inference.PerfMetrics"]], "qeffautomodel (class in qefficient.transformers.models.modeling_auto)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel"]], "qeffautomodelforcausallm (class in qefficient.transformers.models.modeling_auto)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM"]], "qeffautomodelforimagetexttotext (class in qefficient.transformers.models.modeling_auto)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForImageTextToText"]], "qeffautomodelforspeechseq2seq (class in qefficient.transformers.models.modeling_auto)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForSpeechSeq2Seq"]], "qeffautoloramodelforcausallm (class in qefficient.peft.lora.auto)": [[7, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM"]], "qeffautopeftmodelforcausallm (class in qefficient.peft.auto)": [[7, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM"]], "qefficient.compile.compile_helper": [[7, "module-QEfficient.compile.compile_helper"]], "qefficient.exporter.export_hf_to_cloud_ai_100": [[7, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "qefficient.generation.text_generation_inference": [[7, "module-QEfficient.generation.text_generation_inference"]], "qefficient.utils.device_utils": [[7, "module-QEfficient.utils.device_utils"]], "qefficient.utils.generate_inputs": [[7, "module-QEfficient.utils.generate_inputs"]], "qefficient.utils.run_utils": [[7, "module-QEfficient.utils.run_utils"]], "active_adapter (qefficient.peft.auto.qeffautopeftmodelforcausallm property)": [[7, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.active_adapter"]], "calculate_latency() (in module qefficient.generation.text_generation_inference)": [[7, "QEfficient.generation.text_generation_inference.calculate_latency"]], "cloud_ai_100_exec_kv() (in module qefficient.generation.text_generation_inference)": [[7, "QEfficient.generation.text_generation_inference.cloud_ai_100_exec_kv"]], "cloud_ai_100_feature_generate() (qefficient.transformers.models.modeling_auto.qeffautomodel method)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel.cloud_ai_100_feature_generate"]], "compile() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[7, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.compile"]], "compile() (qefficient.transformers.models.modeling_auto.qeffautomodel method)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel.compile"]], "compile() (qefficient.transformers.models.modeling_auto.qeffautomodelforcausallm method)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.compile"]], "compile() (qefficient.transformers.models.modeling_auto.qeffautomodelforspeechseq2seq method)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForSpeechSeq2Seq.compile"]], "compile() (in module qefficient.compile.compile_helper)": [[7, "QEfficient.compile.compile_helper.compile"]], "convert_to_cloud_bertstyle() (in module qefficient.exporter.export_hf_to_cloud_ai_100)": [[7, "QEfficient.exporter.export_hf_to_cloud_ai_100.convert_to_cloud_bertstyle"]], "convert_to_cloud_kvstyle() (in module qefficient.exporter.export_hf_to_cloud_ai_100)": [[7, "QEfficient.exporter.export_hf_to_cloud_ai_100.convert_to_cloud_kvstyle"]], "download_adapter() (qefficient.peft.lora.auto.qeffautoloramodelforcausallm method)": [[7, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM.download_adapter"]], "export() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[7, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.export"]], "export() (qefficient.peft.lora.auto.qeffautoloramodelforcausallm method)": [[7, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM.export"]], "export() (qefficient.transformers.models.modeling_auto.qeffautomodel method)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel.export"]], "export() (qefficient.transformers.models.modeling_auto.qeffautomodelforcausallm method)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.export"]], "export() (qefficient.transformers.models.modeling_auto.qeffautomodelforspeechseq2seq method)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForSpeechSeq2Seq.export"]], "fix_prompt_to_lora_id_mapping() (in module qefficient.generation.text_generation_inference)": [[7, "QEfficient.generation.text_generation_inference.fix_prompt_to_lora_id_mapping"]], "fix_prompts() (in module qefficient.generation.text_generation_inference)": [[7, "QEfficient.generation.text_generation_inference.fix_prompts"]], "from_pretrained() (qefficient.peft.auto.qeffautopeftmodelforcausallm class method)": [[7, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.from_pretrained"]], "generate() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[7, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.generate"]], "generate() (qefficient.peft.lora.auto.qeffautoloramodelforcausallm method)": [[7, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM.generate"]], "generate() (qefficient.transformers.models.modeling_auto.qeffautomodel method)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel.generate"]], "generate() (qefficient.transformers.models.modeling_auto.qeffautomodelforcausallm method)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.generate"]], "generate() (qefficient.transformers.models.modeling_auto.qeffautomodelforspeechseq2seq method)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForSpeechSeq2Seq.generate"]], "get_available_device_id() (in module qefficient.utils.device_utils)": [[7, "QEfficient.utils.device_utils.get_available_device_id"]], "get_compilation_dims() (in module qefficient.generation.text_generation_inference)": [[7, "QEfficient.generation.text_generation_inference.get_compilation_dims"]], "load_adapter() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[7, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.load_adapter"]], "load_adapter() (qefficient.peft.lora.auto.qeffautoloramodelforcausallm method)": [[7, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM.load_adapter"]], "module": [[7, "module-QEfficient.compile.compile_helper"], [7, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"], [7, "module-QEfficient.generation.text_generation_inference"], [7, "module-QEfficient.utils.device_utils"], [7, "module-QEfficient.utils.generate_inputs"], [7, "module-QEfficient.utils.run_utils"]], "prepare_ort_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[7, "QEfficient.utils.generate_inputs.InputHandler.prepare_ort_inputs"]], "prepare_pytorch_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[7, "QEfficient.utils.generate_inputs.InputHandler.prepare_pytorch_inputs"]], "pytorch_feature_generate() (qefficient.transformers.models.modeling_auto.qeffautomodel method)": [[7, "QEfficient.transformers.models.modeling_auto.QEFFAutoModel.pytorch_feature_generate"]], "qualcomm_efficient_converter() (in module qefficient.exporter.export_hf_to_cloud_ai_100)": [[7, "QEfficient.exporter.export_hf_to_cloud_ai_100.qualcomm_efficient_converter"]], "run_hf_model_on_pytorch() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_hf_model_on_pytorch"]], "run_hf_model_on_pytorch_cb() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_hf_model_on_pytorch_CB"]], "run_kv_model_on_cloud_ai_100() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_kv_model_on_cloud_ai_100"]], "run_kv_model_on_ort() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_kv_model_on_ort"]], "run_kv_model_on_pytorch() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_kv_model_on_pytorch"]], "run_ort_session() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_ort_session"]], "set_adapter() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[7, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.set_adapter"]], "unload_adapter() (qefficient.peft.lora.auto.qeffautoloramodelforcausallm method)": [[7, "QEfficient.peft.lora.auto.QEffAutoLoraModelForCausalLM.unload_adapter"]], "update_ort_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[7, "QEfficient.utils.generate_inputs.InputHandler.update_ort_inputs"]], "update_ort_outputs() (qefficient.utils.generate_inputs.inputhandler method)": [[7, "QEfficient.utils.generate_inputs.InputHandler.update_ort_outputs"]], "update_pytorch_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[7, "QEfficient.utils.generate_inputs.InputHandler.update_pytorch_inputs"]]}})
Search.setIndex({"docnames": ["README", "index", "source/blogs", "source/cli_api", "source/hl_api", "source/installation", "source/introduction", "source/ll_api", "source/quick_start", "source/reference", "source/upgrade", "source/validate"], "filenames": ["README.md", "index.md", "source/blogs.md", "source/cli_api.md", "source/hl_api.md", "source/installation.md", "source/introduction.md", "source/ll_api.md", "source/quick_start.md", "source/reference.md", "source/upgrade.md", "source/validate.md"], "titles": ["Docs", "Welcome to Efficient-Transformers Documentation!", "Train anywhere, Infer on Qualcomm Cloud AI 100", "<code class=\"docutils literal notranslate\"><span class=\"pre\">QEfficient.cloud.infer</span></code>", "High Level API", "Pre-requisites", "Introduction Qualcomm <code class=\"docutils literal notranslate\"><span class=\"pre\">efficient-transformers</span></code> library", "Low Level API", "Transformed models and QPC storage", "Qualcomm Cloud AI home", "Using GitHub Repository", "Validated Models"], "terms": {"thi": [0, 3, 4, 6, 7, 8, 10], "directori": [0, 4, 5, 8], "contain": [0, 8], "instruct": [0, 6, 11], "static": 0, "html": 0, "document": [0, 6], "base": [0, 4, 6, 7, 8, 11], "sphinx": 0, "instal": [0, 10], "packag": [0, 3, 4], "requir": [0, 4, 5, 8, 10], "pip": [0, 10], "r": [0, 11], "txt": [0, 3, 8], "And": [0, 7], "chang": [0, 6, 8], "folder": [0, 8], "cd": 0, "To": [0, 6, 8], "specif": [0, 1, 4], "branch": 0, "m": [0, 3, 4, 8, 10], "option": [0, 3, 4, 8], "all": [0, 4, 7, 11], "support": [0, 4, 5, 6, 8, 11], "multivers": 0, "python": [0, 3, 4, 5, 10], "http": [0, 8, 10], "server": 0, "you": [0, 4, 5, 8], "can": [0, 4, 5, 8], "visit": 0, "page": [0, 4], "your": [0, 4, 8], "web": 0, "browser": 0, "url": 0, "localhost": 0, "8080": 0, "introduct": 1, "qualcomm": 1, "librari": [1, 5, 8], "valid": [1, 10], "model": [1, 3, 4, 5, 6, 7, 10], "come": [1, 4, 6], "soon": [1, 3, 4, 6], "pre": [1, 4, 6, 8], "requisit": 1, "1": [1, 3, 4, 6, 7, 11], "download": [1, 3, 4], "app": [1, 3], "sdk": [1, 3, 4, 8, 10], "2": [1, 4, 11], "saniti": 1, "check": [1, 3, 4, 7, 8], "github": 1, "repositori": 1, "qpc": [1, 3, 4, 7], "storag": 1, "qeffici": [1, 4, 5, 7, 10], "cloud": [1, 4, 5, 6, 7], "infer": [1, 4, 6], "execut": [1, 5, 6], "multi": [1, 5], "qranium": 1, "continu": [1, 3, 4, 6, 11], "batch": [1, 3, 4, 6, 11], "optim": [1, 6], "ai": [1, 3, 4, 5, 6, 7], "100": [1, 3, 4, 5, 6, 7], "export": [1, 6, 7], "compil": [1, 7], "one": [1, 4, 7], "3": [1, 4, 6, 10, 11], "high": [1, 8], "level": [1, 3, 8], "qeffautomodelforcausallm": [1, 3, 7, 8], "qeffautopeftmodelforcausallm": 1, "low": [1, 4], "convert_to_cloud_kvstyl": 1, "convert_to_cloud_bertstyl": [1, 4], "util": [1, 4, 5, 8], "train": [1, 6], "anywher": [1, 6], "how": [1, 6], "quadrupl": 1, "llm": [1, 6], "decod": [1, 4, 6, 7, 8], "perform": [1, 4, 6], "specul": [1, 6], "spd": 1, "microsc": 1, "mx": 1, "format": [1, 3, 4], "power": [1, 8], "acceler": 1, "larg": 1, "languag": [1, 4], "2x": 1, "introduc": 1, "One": 1, "infinit": 1, "possibl": [1, 4], "home": 1, "user": [1, 6, 8], "guid": 1, "ocp": 1, "click": 2, "here": [2, 4, 6], "us": [3, 4, 5, 6, 7, 8], "bash": [3, 8], "termin": [3, 8], "els": [3, 8], "zsh": [3, 8], "device_group": [3, 4, 7, 8], "should": [3, 4, 8], "singl": [3, 8], "quot": [3, 8], "e": [3, 8], "g": [3, 8], "0": [3, 4, 8], "given": [3, 4, 7], "config": [3, 4, 7, 8], "alreadi": [3, 8], "exist": [3, 5], "doe": [3, 4], "jump": [3, 8], "onnx": [3, 4, 6, 7, 8], "file": [3, 4, 7, 8], "true": [3, 4, 8], "hf": [3, 8, 11], "cach": [3, 4, 7, 8], "start": [3, 5], "transform": [3, 4, 7, 10], "4": [3, 6, 8], "mandatori": [3, 4, 7], "arg": [3, 4, 7], "model_nam": [3, 4, 7, 8], "str": [3, 4, 7], "hug": [3, 7], "face": [3, 7], "card": [3, 4, 5, 6, 7, 8], "name": [3, 4, 7, 8, 11], "exampl": [3, 6, 7, 8], "gpt2": [3, 4, 7, 8, 11], "num_cor": [3, 4, 8], "int": [3, 4, 7, 8], "number": [3, 4, 8], "core": [3, 4], "list": [3, 4, 7], "devic": [3, 4, 5, 6, 7, 8], "id": [3, 4, 7], "If": [3, 4, 5, 8], "len": [3, 4, 7], "multipl": [3, 4, 7], "setup": [3, 4, 7], "i": [3, 4, 5, 6, 8], "enabl": [3, 4, 5, 6, 7, 8], "default": [3, 4, 8], "none": [3, 4, 7], "prompt": [3, 4, 7, 8], "sampl": [3, 4, 6, 8], "text": [3, 4], "gener": [3, 4, 7, 8], "prompts_txt_file_path": [3, 4, 8], "path": [3, 4, 5, 6, 7, 8], "input": [3, 4, 7, 8], "aic_enable_depth_first": [3, 4, 8], "bool": [3, 4], "df": [3, 4], "memori": [3, 4], "size": [3, 4, 8], "fals": [3, 4], "mo": [3, 4, 8], "effort": [3, 4, 8], "reduc": [3, 4], "chip": [3, 4], "batch_siz": [3, 4, 7, 8], "full_batch_s": [3, 4, 7, 8], "set": [3, 4, 8], "full": [3, 4], "mode": [3, 4], "prompt_len": [3, 4, 7, 8], "length": [3, 4, 7], "32": [3, 4, 8], "ctx_len": [3, 4, 7, 8], "maximum": [3, 4], "context": [3, 4], "128": [3, 4, 8], "generation_len": [3, 4], "token": [3, 4, 7, 8], "mxfp6": [3, 4, 8], "precis": [3, 4, 6], "mxint8": [3, 4], "compress": [3, 4], "present": [3, 4, 8], "past": [3, 4], "kv": [3, 4, 7, 8], "customio": [3, 4, 8], "local_model_dir": [3, 4], "custom": [3, 4, 8], "weight": [3, 4, 6], "cache_dir": [3, 4, 8], "dir": [3, 4, 8], "where": [3, 7], "huggingfac": [3, 4, 6, 7, 8], "ar": [3, 4, 5, 6, 8], "store": [3, 4, 5, 8], "hf_token": [3, 4], "login": 3, "access": [3, 4], "privat": 3, "repo": [3, 10], "helper": 3, "function": [3, 4, 6, 7, 11], "cli": [3, 8], "run": [3, 4, 5, 8], "platform": [3, 4, 5, 8], "qpc_path": [3, 4, 7, 8], "binari": [3, 4, 8], "after": [3, 4, 5, 7], "constant": [3, 8], "save": [3, 4, 7, 8], "tensor": [3, 4, 7], "slice": [3, 4], "configur": [3, 4], "pass": [3, 4, 7, 8], "deprec": [3, 4], "replac": [3, 4, 6], "onnx_path": [3, 4], "find": [3, 4], "custom_io_file_path": [3, 4], "string": [3, 4, 8], "return": [3, 4, 7], "give": 4, "an": [4, 8], "overview": 4, "about": 4, "might": 4, "need": [4, 6, 8], "integr": [4, 5], "applic": [4, 6], "class": 4, "modeling_auto": 4, "modul": [4, 6, 7], "continuous_batch": 4, "kwarg": 4, "sourc": [4, 5, 6, 7, 10], "The": [4, 7, 8], "qeff": [4, 5], "design": [4, 8], "manipul": 4, "ani": [4, 8], "causal": 4, "from": [4, 6, 7, 8], "hub": 4, "although": 4, "initi": [4, 6, 8], "directli": [4, 8], "we": [4, 6, 8], "highli": [4, 6], "recommend": 4, "from_pretrain": [4, 8], "method": [4, 5], "nn": [4, 7], "pytorch": [4, 7, 8], "weather": 4, "futur": 4, "later": 4, "import": [4, 5, 8], "num_hidden_lay": 4, "prefill_seq_len": 4, "1024": 4, "hi": 4, "classmethod": 4, "pretrained_model_name_or_path": 4, "serv": 4, "easiest": 4, "entri": 4, "point": 4, "interfac": 4, "similar": [4, 8], "automodelforcausallm": [4, 8], "onc": [4, 8], "other": [4, 6, 8], "same": [4, 8, 10], "object": [4, 7], "pretrained_name_or_path": 4, "local": [4, 6, 8], "addit": 4, "argument": [4, 8], "now": [4, 6, 8], "14": [4, 8], "consid": 4, "have": [4, 8, 10], "standard": 4, "sku": 4, "export_dir": 4, "torch": [4, 7, 8], "current": [4, 7], "don": [4, 8], "t": [4, 8], "non": 4, "pleas": [4, 8], "refer": [4, 8], "legaci": 4, "graph": [4, 6], "compile_dir": 4, "num_devic": 4, "16": [4, 8], "mxfp6_matmul": 4, "mxint8_kv_cach": 4, "compiler_opt": 4, "found": [4, 8], "opt": [4, 5], "qti": [4, 5], "aic": [4, 5], "exec": [4, 5], "qaic": [4, 5, 8], "ha": 4, "been": [4, 10], "yet": 4, "handl": [4, 6], "process": [4, 7], "take": [4, 6, 8], "extra": 4, "invok": 4, "automat": [4, 8], "choos": 4, "suitabl": [4, 7], "prefil": [4, 7, 8], "less": 4, "ctx": 4, "rememb": 4, "whether": 4, "mean": 4, "pretrainedtokenizerfast": [4, 7], "pretrainedtoken": [4, 7], "device_id": 4, "runtim": 4, "ai_100": 4, "output": [4, 7], "until": [4, 7], "eo": [4, 7], "hardwar": 4, "sequenti": 4, "cannot": 4, "divid": 4, "last": 4, "unfulfil": 4, "drop": 4, "case": [4, 8], "normal": 4, "onli": [4, 6, 8], "onnxrt": [4, 7], "peft": [4, 6], "auto": [4, 7], "load": 4, "adapt": [4, 6, 11], "lora": 4, "anoth": 4, "predibas": 4, "magicod": 4, "A": 4, "code": [4, 6, 8, 11], "math": 4, "load_adapt": 4, "gsm8k": 4, "set_adapt": 4, "model_id": 4, "adapter_nam": 4, "new": [4, 6, 8], "properti": 4, "active_adapt": 4, "activ": [4, 5, 10], "autopeftmodelforcausallm": 4, "specifi": [4, 8], "suffix": 4, "hash": 4, "correspond": [4, 8], "ai100": 4, "ad": [4, 6, 8], "avoid": 4, "reus": [4, 8], "differ": [4, 8], "paramet": 4, "each": 4, "matmul": 4, "node": 4, "faster": 4, "updat": [4, 6, 7], "flag": 4, "param": [4, 8], "convert": [4, 7], "below": [4, 8], "aic_num_cor": 4, "num": 4, "convert_to_fp16": 4, "fp16": [4, 8], "alloc": 4, "line": [4, 5], "sequenc": [4, 7], "chunk": 4, "accord": 4, "space": 4, "ndarrai": [4, 7], "generation_config": 4, "generationconfig": 4, "stopping_criteria": 4, "stoppingcriteria": 4, "streamer": 4, "basestream": 4, "input_id": [4, 7], "merg": 4, "stop": 4, "put": 4, "while": [4, 8], "export_hf_to_cloud_ai_100": [4, 7], "qualcomm_efficient_convert": [4, 8], "model_kv": 4, "qeffbasemodel": 4, "onnx_dir_path": [4, 7], "seq_length": 4, "form_factor": 4, "tupl": 4, "alia": 4, "usag": 4, "In": 4, "union": [4, 7], "gate": 4, "seq_len": [4, 7], "bert": 4, "style": [4, 7], "form": 4, "factor": 4, "accept": 4, "base_path": 4, "onnx_model_path": 4, "sinc": 4, "version": [4, 5], "19": 4, "instead": [4, 8], "compile_help": 4, "o": [4, 5, 8], "join": [4, 8], "text_generation_infer": 4, "cloudai100execinfo": 4, "generated_text": 4, "generated_id": 4, "prefill_tim": 4, "float": 4, "decode_perf": 4, "total_perf": 4, "total_tim": 4, "hold": 4, "inform": [4, 7], "": [4, 6], "np": [4, 8], "time": [4, 7, 8], "total": 4, "cloud_ai_100_exec_kv": 4, "enable_debug_log": 4, "stream": 4, "write_io_dir": 4, "autom": 4, "dure": [4, 8], "picker": 4, "debug": 4, "log": 4, "which": [4, 6, 8], "them": [4, 8], "write": 4, "print": [4, 5, 8], "stat": [4, 8], "detail": [4, 8], "autotoken": 4, "execinfo": 4, "fix_prompt": 4, "adjust": 4, "match": 4, "system": 5, "linux": 5, "ubuntu": 5, "rhel": 5, "aw": 5, "shard": 5, "uninstal": 5, "sudo": 5, "sh": 5, "script": 5, "root": 5, "permiss": 5, "dev": 5, "bin": [5, 10], "On": 5, "success": 5, "content": 5, "under": [5, 8], "follow": [5, 8], "command": [5, 11], "tool": 5, "appli": 5, "chmod": 5, "x": 5, "hexagon_tool": 5, "abov": [5, 8], "correctli": 5, "c": 5, "__version__": 5, "successfulli": 5, "good": 5, "go": 5, "ahead": 5, "deploi": 5, "develop": [6, 8], "centric": 6, "toolchain": 6, "provid": [6, 8], "reimplement": 6, "block": 6, "make": [6, 7, 8], "wide": 6, "rang": 6, "architectur": [6, 7, 8], "easi": 6, "deploy": 6, "care": 6, "implement": 6, "For": 6, "comprehens": 6, "inspir": 6, "upon": [6, 8], "typic": 6, "retent": [6, 7], "intermedi": 6, "state": [6, 7], "read": 6, "more": [6, 7, 8], "kei": 6, "oper": 6, "lower": 6, "some": 6, "mathemat": 6, "equival": 6, "hw": 6, "backend": 6, "underflow": 6, "overflow": [6, 8], "patcher": 6, "map": 6, "origin": [6, 7, 8], "demo": [6, 8], "notebook": [6, 8], "unit": 6, "test": 6, "templat": 6, "latest": 6, "popular": 6, "techniqu": 6, "09": 6, "2024": 6, "awq": 6, "gptq": 6, "bit": 6, "quantiz": 6, "meta": 6, "llama": [6, 11], "8b": [6, 11], "70b": [6, 11], "granit": [6, 11], "20b": [6, 11], "8k": [6, 11], "starcoder1": [6, 11], "15b": [6, 11], "08": 6, "jai": [6, 11], "13b": [6, 11], "chat": [6, 11], "7b": [6, 11], "06": 6, "gpt": [6, 11], "j": [6, 11], "6b": [6, 11], "qwen2": [6, 11], "5b": [6, 11], "starcoder2": [6, 11], "phi3": [6, 11], "mini": [6, 11], "4k": [6, 11], "codestr": [6, 11], "22b": [6, 11], "v0": [6, 11], "vicuna": [6, 11], "v1": [6, 11], "5": [6, 11], "05": 6, "mixtral": [6, 11], "8x7b": [6, 11], "mistral": [6, 11], "04": 6, "releas": 6, "seamless": 6, "qeff_model": [7, 8], "approach": [7, 8], "particularli": 7, "regress": 7, "task": 7, "involv": 7, "contextu": 7, "earlier": 7, "crucial": 7, "predict": 7, "next": 7, "inclus": 7, "enhanc": 7, "effici": [7, 8, 10], "computation": 7, "bertstyl": 7, "No": 7, "separ": [7, 8], "logic": 7, "everi": 7, "comput": [7, 8], "max_length": 7, "device_util": 7, "get_available_device_id": 7, "avail": [7, 8], "generate_input": 7, "inputhandl": 7, "prepare_ort_input": 7, "creat": [7, 8, 10], "stage": [7, 8], "numpi": 7, "dict": 7, "position_id": 7, "past_key_valu": 7, "prepare_pytorch_input": 7, "update_ort_input": 7, "ort_output": 7, "previou": 7, "iter": 7, "update_ort_output": 7, "session": 7, "updated_output": 7, "logit": 7, "update_pytorch_input": 7, "pt_output": 7, "run_util": 7, "run_hf_model_on_pytorch": 7, "model_hf": 7, "run_hf_model_on_pytorch_cb": 7, "run_kv_model_on_cloud_ai_100": 7, "run_kv_model_on_ort": 7, "model_path": 7, "onnxruntim": [7, 8], "run_kv_model_on_pytorch": 7, "run_ort_sess": 7, "retain": 7, "capi": 7, "onnxruntime_inference_collect": 7, "inferencesess": 7, "wa": 8, "goal": 8, "onboard": 8, "straightforward": 8, "leverag": 8, "complet": 8, "achiev": 8, "abstract": 8, "awai": 8, "complex": 8, "offer": 8, "simpler": 8, "thei": 8, "re": 8, "ideal": 8, "quick": 8, "prototyp": 8, "technologi": 8, "want": 8, "minim": 8, "granular": 8, "control": 8, "when": 8, "necessari": 8, "By": 8, "program": 8, "readi": 8, "qeff_cach": 8, "environ": 8, "variabl": 8, "qeff_hom": 8, "its": 8, "xdg_cache_hom": 8, "note": [8, 11], "rerout": 8, "entir": 8, "includ": 8, "neither": 8, "nor": 8, "e2": 8, "model_card": 8, "along": 8, "doc": 8, "It": 8, "skip": 8, "second": 8, "creation": 8, "out": 8, "help": 8, "my": 8, "pipe": 8, "symbol": 8, "flat": 8, "earth": 8, "theori": 8, "belief": 8, "sun": 8, "rise": 8, "also": 8, "lot": 8, "first": 8, "precompil": 8, "sure": 8, "qpc_16cores_1bs_32pl_128cl_1devices_mxfp6": 8, "mq": 8, "just": 8, "group": 8, "fly": 8, "soc": 8, "salesforc": [8, 11], "codegen": 8, "2b": [8, 11], "mono": 8, "def": 8, "fibonacci": 8, "n": 8, "step": 8, "model_card_nam": 8, "pick": 8, "qpc_16cores_1bs_32pl_128cl_2devices_mxfp6": 8, "binary_search": 8, "arrai": 8, "k": 8, "disabl": 8, "like": 8, "again": 8, "featur": 8, "full_batch_size_valu": 8, "regular": 8, "wai": 8, "tinyllama": 8, "tinyllama_v1": 8, "fall": 8, "work": [8, 10], "fine": 8, "rais": 8, "issu": 8, "troubl": 8, "uncom": 8, "appropri": 8, "transformers_cach": 8, "mnt": 8, "workspac": 8, "hf_cach": 8, "root_dir": 8, "dirnam": 8, "abspath": 8, "tmp": 8, "locat": 8, "co": 8, "xl": 8, "lib": 8, "f": 8, "verifi": 8, "modifi": 8, "framework": 8, "both": 8, "variat": 8, "clip": 8, "v": 8, "Then": 8, "yaml": 8, "generated_qpc_path": 8, "benchmark": 8, "tok": 8, "sec": 8, "post": 8, "latenc": 8, "greedi": 8, "end": 8, "variou": 8, "warn": 10, "compat": 10, "upgrad": 10, "mai": 10, "result": 10, "certain": 10, "becom": 10, "incompat": 10, "virtual": 10, "env": 10, "10": 10, "python3": 10, "venv": 10, "qeff_env": 10, "u": 10, "clone": 10, "git": 10, "com": 10, "quic": 10, "codellama": 11, "34b": 11, "gemma": 11, "codegemma": 11, "27b": 11, "codegen25": 11, "mono_p": 11, "xgen": 11, "mpt": 11, "falcon": 11, "40b": 11, "cohereforai": 11, "c4ai": 11, "v01": 11, "databrick": 11, "dbrx": 11, "chatglm2": 11, "baichuan2": 11}, "objects": {"QEfficient.cloud.execute": [[3, 0, 0, "-", "main"]], "QEfficient.cloud.export": [[3, 0, 0, "-", "main"]], "QEfficient.cloud.infer": [[3, 0, 0, "-", "main"]], "QEfficient.compile": [[4, 0, 0, "-", "compile_helper"]], "QEfficient.compile.compile_helper": [[4, 1, 1, "", "compile"], [3, 0, 0, "-", "compile"]], "QEfficient.exporter": [[7, 0, 0, "-", "export_hf_to_cloud_ai_100"]], "QEfficient.exporter.export_hf_to_cloud_ai_100": [[7, 1, 1, "", "convert_to_cloud_bertstyle"], [7, 1, 1, "", "convert_to_cloud_kvstyle"], [4, 1, 1, "", "qualcomm_efficient_converter"]], "QEfficient.generation": [[4, 0, 0, "-", "text_generation_inference"]], "QEfficient.generation.text_generation_inference": [[4, 2, 1, "", "CloudAI100ExecInfo"], [4, 1, 1, "", "cloud_ai_100_exec_kv"], [4, 1, 1, "", "fix_prompts"]], "QEfficient.peft.auto": [[4, 2, 1, "", "QEffAutoPeftModelForCausalLM"]], "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM": [[4, 3, 1, "", "active_adapter"], [4, 4, 1, "", "compile"], [4, 4, 1, "", "export"], [4, 4, 1, "", "from_pretrained"], [4, 4, 1, "", "generate"], [4, 4, 1, "", "load_adapter"], [4, 4, 1, "", "set_adapter"]], "QEfficient.transformers.models.modeling_auto": [[4, 2, 1, "", "QEFFAutoModelForCausalLM"]], "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM": [[4, 4, 1, "", "compile"], [4, 4, 1, "", "export"], [4, 4, 1, "", "from_pretrained"], [4, 4, 1, "", "generate"]], "QEfficient.utils": [[7, 0, 0, "-", "device_utils"], [7, 0, 0, "-", "generate_inputs"], [7, 0, 0, "-", "run_utils"]], "QEfficient.utils.device_utils": [[7, 1, 1, "", "get_available_device_id"]], "QEfficient.utils.generate_inputs": [[7, 2, 1, "", "InputHandler"]], "QEfficient.utils.generate_inputs.InputHandler": [[7, 4, 1, "", "prepare_ort_inputs"], [7, 4, 1, "", "prepare_pytorch_inputs"], [7, 4, 1, "", "update_ort_inputs"], [7, 4, 1, "", "update_ort_outputs"], [7, 4, 1, "", "update_pytorch_inputs"]], "QEfficient.utils.run_utils": [[7, 2, 1, "", "ApiRunner"]], "QEfficient.utils.run_utils.ApiRunner": [[7, 4, 1, "", "run_hf_model_on_pytorch"], [7, 4, 1, "", "run_hf_model_on_pytorch_CB"], [7, 4, 1, "", "run_kv_model_on_cloud_ai_100"], [7, 4, 1, "", "run_kv_model_on_ort"], [7, 4, 1, "", "run_kv_model_on_pytorch"], [7, 4, 1, "", "run_ort_session"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class", "3": "py:property", "4": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"], "3": ["py", "property", "Python property"], "4": ["py", "method", "Python method"]}, "titleterms": {"doc": 0, "build": 0, "preview": 0, "local": 0, "welcom": 1, "effici": [1, 2, 5, 6], "transform": [1, 2, 5, 6, 8], "document": 1, "get": 1, "start": 1, "instal": [1, 5], "upgrad": 1, "quick": 1, "command": [1, 8], "line": [1, 8], "interfac": [1, 8], "us": [1, 2, 10], "cli": 1, "python": [1, 8], "api": [1, 2, 4, 7, 8, 9], "blog": 1, "refer": [1, 9], "train": 2, "anywher": 2, "infer": [2, 3, 8], "qualcomm": [2, 6, 9], "cloud": [2, 3, 8, 9], "ai": [2, 8, 9], "100": [2, 8], "how": 2, "quadrupl": 2, "llm": 2, "decod": 2, "perform": 2, "specul": 2, "spd": 2, "microsc": [2, 9], "mx": [2, 9], "format": [2, 9], "power": 2, "acceler": 2, "larg": 2, "languag": 2, "model": [2, 8, 11], "sdk": [2, 5, 9], "2x": 2, "introduc": 2, "One": 2, "infinit": 2, "possibl": 2, "qeffici": [3, 8], "execut": [3, 4, 8], "compil": [3, 4, 8], "export": [3, 4, 8], "high": 4, "level": [4, 7], "qeffautomodelforcausallm": 4, "qeffautopeftmodelforcausallm": 4, "pre": 5, "requisit": 5, "small": 5, "1": [5, 8], "download": [5, 8, 9], "app": 5, "2": [5, 8], "saniti": 5, "check": 5, "introduct": 6, "librari": 6, "low": 7, "convert_to_cloud_kvstyl": 7, "convert_to_cloud_bertstyl": 7, "util": 7, "apirunn": 7, "class": 7, "i": 7, "respons": 7, "run": 7, "qpc": 8, "storag": 8, "multi": 8, "qranium": 8, "continu": 8, "batch": 8, "optim": 8, "one": 8, "3": 8, "home": 9, "user": 9, "guid": 9, "ocp": 9, "specif": 9, "github": 10, "repositori": 10, "valid": 11, "come": 11, "soon": 11}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 58}, "alltitles": {"Docs": [[0, "docs"]], "Build the docs": [[0, "build-the-docs"]], "Preview the docs locally": [[0, "preview-the-docs-locally"]], "Welcome to Efficient-Transformers Documentation!": [[1, "welcome-to-efficient-transformers-documentation"]], "Getting Started": [[1, null]], "Installation": [[1, null], [5, "installation"]], "Upgrade Efficient-Transformers": [[1, null]], "Quick start": [[1, null]], "Command Line Interface Use (CLI)": [[1, null]], "Python API": [[1, null], [8, "python-api"]], "Blogs": [[1, null]], "Reference": [[1, null]], "Train anywhere, Infer on Qualcomm Cloud AI 100": [[2, "train-anywhere-infer-on-qualcomm-cloud-ai-100"]], "How to Quadruple LLM Decoding Performance with Speculative Decoding (SpD) and Microscaling (MX) Formats on Qualcomm\u00ae Cloud AI 100": [[2, "how-to-quadruple-llm-decoding-performance-with-speculative-decoding-spd-and-microscaling-mx-formats-on-qualcomm-cloud-ai-100"]], "Power-efficient acceleration for large language models \u2013 Qualcomm Cloud AI SDK": [[2, "power-efficient-acceleration-for-large-language-models-qualcomm-cloud-ai-sdk"]], "Qualcomm Cloud AI 100 Accelerates Large Language Model Inference by ~2x Using Microscaling (Mx) Formats": [[2, "qualcomm-cloud-ai-100-accelerates-large-language-model-inference-by-2x-using-microscaling-mx-formats"]], "Qualcomm Cloud AI Introduces Efficient Transformers: One API, Infinite Possibilities": [[2, "qualcomm-cloud-ai-introduces-efficient-transformers-one-api-infinite-possibilities"]], "QEfficient.cloud.infer": [[3, "module-QEfficient.cloud.infer.main"], [8, "qefficient-cloud-infer"]], "QEfficient.cloud.execute": [[3, "module-QEfficient.cloud.execute.main"], [8, "qefficient-cloud-execute"]], "QEfficient.cloud.compile": [[3, "qefficient-cloud-compile"]], "QEfficient.cloud.export": [[3, "qefficient-cloud-export"]], "High Level API": [[4, "high-level-api"]], "QEFFAutoModelForCausalLM": [[4, "qeffautomodelforcausallm"]], "QEffAutoPeftModelForCausalLM": [[4, "qeffautopeftmodelforcausallm"]], "export": [[4, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "compile": [[4, "module-QEfficient.compile.compile_helper"]], "Execute": [[4, "module-QEfficient.generation.text_generation_inference"]], "Pre-requisites": [[5, "pre-requisites"]], "<small> 1. Download Apps SDK</small>": [[5, "download-apps-sdk"]], "<small> 2. Install Efficient-Transformers</small>": [[5, "install-efficient-transformers"]], "Sanity Check": [[5, "sanity-check"]], "Introduction Qualcomm efficient-transformers library": [[6, "introduction-qualcomm-efficient-transformers-library"]], "Low Level API": [[7, "low-level-api"]], "convert_to_cloud_kvstyle": [[7, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "convert_to_cloud_bertstyle": [[7, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "utils": [[7, "module-QEfficient.utils.device_utils"]], "ApiRunner class is responsible for running:": [[7, "apirunner-class-is-responsible-for-running"]], "Transformed models and QPC storage": [[8, "transformed-models-and-qpc-storage"]], "Command Line Interface": [[8, "command-line-interface"]], "Multi-Qranium Inference": [[8, "multi-qranium-inference"]], "Continuous Batching": [[8, "continuous-batching"]], "1.  Model download and Optimize for Cloud AI 100": [[8, "model-download-and-optimize-for-cloud-ai-100"]], "2. Export and Compile with one API": [[8, "export-and-compile-with-one-api"]], "3. Execute": [[8, "execute"]], "Qualcomm Cloud AI home": [[9, "qualcomm-cloud-ai-home"]], "Qualcomm Cloud AI SDK download": [[9, "qualcomm-cloud-ai-sdk-download"]], "Qualcomm Cloud AI API reference": [[9, "qualcomm-cloud-ai-api-reference"]], "User Guide": [[9, "user-guide"]], "OCP Microscaling Formats (MX) Specification": [[9, "ocp-microscaling-formats-mx-specification"]], "Using GitHub Repository": [[10, "using-github-repository"]], "Validated Models": [[11, "validated-models"]], "Models Coming Soon": [[11, "models-coming-soon"]]}, "indexentries": {"qefficient.cloud.execute.main": [[3, "module-QEfficient.cloud.execute.main"]], "qefficient.cloud.export.main": [[3, "module-QEfficient.cloud.export.main"]], "qefficient.cloud.infer.main": [[3, "module-QEfficient.cloud.infer.main"]], "qefficient.compile.compile_helper.compile": [[3, "module-QEfficient.compile.compile_helper.compile"]], "module": [[3, "module-QEfficient.cloud.execute.main"], [3, "module-QEfficient.cloud.export.main"], [3, "module-QEfficient.cloud.infer.main"], [3, "module-QEfficient.compile.compile_helper.compile"], [4, "module-QEfficient.compile.compile_helper"], [4, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"], [4, "module-QEfficient.generation.text_generation_inference"], [7, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"], [7, "module-QEfficient.utils.device_utils"], [7, "module-QEfficient.utils.generate_inputs"], [7, "module-QEfficient.utils.run_utils"]], "cloudai100execinfo (class in qefficient.generation.text_generation_inference)": [[4, "QEfficient.generation.text_generation_inference.CloudAI100ExecInfo"]], "qeffautomodelforcausallm (class in qefficient.transformers.models.modeling_auto)": [[4, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM"]], "qeffautopeftmodelforcausallm (class in qefficient.peft.auto)": [[4, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM"]], "qefficient.compile.compile_helper": [[4, "module-QEfficient.compile.compile_helper"]], "qefficient.exporter.export_hf_to_cloud_ai_100": [[4, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"], [7, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "qefficient.generation.text_generation_inference": [[4, "module-QEfficient.generation.text_generation_inference"]], "active_adapter (qefficient.peft.auto.qeffautopeftmodelforcausallm property)": [[4, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.active_adapter"]], "cloud_ai_100_exec_kv() (in module qefficient.generation.text_generation_inference)": [[4, "QEfficient.generation.text_generation_inference.cloud_ai_100_exec_kv"]], "compile() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[4, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.compile"]], "compile() (qefficient.transformers.models.modeling_auto.qeffautomodelforcausallm method)": [[4, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.compile"]], "compile() (in module qefficient.compile.compile_helper)": [[4, "QEfficient.compile.compile_helper.compile"]], "export() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[4, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.export"]], "export() (qefficient.transformers.models.modeling_auto.qeffautomodelforcausallm method)": [[4, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.export"]], "fix_prompts() (in module qefficient.generation.text_generation_inference)": [[4, "QEfficient.generation.text_generation_inference.fix_prompts"]], "from_pretrained() (qefficient.peft.auto.qeffautopeftmodelforcausallm class method)": [[4, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.from_pretrained"]], "from_pretrained() (qefficient.transformers.models.modeling_auto.qeffautomodelforcausallm class method)": [[4, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.from_pretrained"]], "generate() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[4, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.generate"]], "generate() (qefficient.transformers.models.modeling_auto.qeffautomodelforcausallm method)": [[4, "QEfficient.transformers.models.modeling_auto.QEFFAutoModelForCausalLM.generate"]], "load_adapter() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[4, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.load_adapter"]], "qualcomm_efficient_converter() (in module qefficient.exporter.export_hf_to_cloud_ai_100)": [[4, "QEfficient.exporter.export_hf_to_cloud_ai_100.qualcomm_efficient_converter"]], "set_adapter() (qefficient.peft.auto.qeffautopeftmodelforcausallm method)": [[4, "QEfficient.peft.auto.QEffAutoPeftModelForCausalLM.set_adapter"]], "apirunner (class in qefficient.utils.run_utils)": [[7, "QEfficient.utils.run_utils.ApiRunner"]], "inputhandler (class in qefficient.utils.generate_inputs)": [[7, "QEfficient.utils.generate_inputs.InputHandler"]], "qefficient.utils.device_utils": [[7, "module-QEfficient.utils.device_utils"]], "qefficient.utils.generate_inputs": [[7, "module-QEfficient.utils.generate_inputs"]], "qefficient.utils.run_utils": [[7, "module-QEfficient.utils.run_utils"]], "convert_to_cloud_bertstyle() (in module qefficient.exporter.export_hf_to_cloud_ai_100)": [[7, "QEfficient.exporter.export_hf_to_cloud_ai_100.convert_to_cloud_bertstyle"]], "convert_to_cloud_kvstyle() (in module qefficient.exporter.export_hf_to_cloud_ai_100)": [[7, "QEfficient.exporter.export_hf_to_cloud_ai_100.convert_to_cloud_kvstyle"]], "get_available_device_id() (in module qefficient.utils.device_utils)": [[7, "QEfficient.utils.device_utils.get_available_device_id"]], "prepare_ort_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[7, "QEfficient.utils.generate_inputs.InputHandler.prepare_ort_inputs"]], "prepare_pytorch_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[7, "QEfficient.utils.generate_inputs.InputHandler.prepare_pytorch_inputs"]], "run_hf_model_on_pytorch() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_hf_model_on_pytorch"]], "run_hf_model_on_pytorch_cb() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_hf_model_on_pytorch_CB"]], "run_kv_model_on_cloud_ai_100() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_kv_model_on_cloud_ai_100"]], "run_kv_model_on_ort() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_kv_model_on_ort"]], "run_kv_model_on_pytorch() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_kv_model_on_pytorch"]], "run_ort_session() (qefficient.utils.run_utils.apirunner method)": [[7, "QEfficient.utils.run_utils.ApiRunner.run_ort_session"]], "update_ort_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[7, "QEfficient.utils.generate_inputs.InputHandler.update_ort_inputs"]], "update_ort_outputs() (qefficient.utils.generate_inputs.inputhandler method)": [[7, "QEfficient.utils.generate_inputs.InputHandler.update_ort_outputs"]], "update_pytorch_inputs() (qefficient.utils.generate_inputs.inputhandler method)": [[7, "QEfficient.utils.generate_inputs.InputHandler.update_pytorch_inputs"]]}})